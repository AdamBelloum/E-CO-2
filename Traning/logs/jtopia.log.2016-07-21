2016-07-12 16:35:22 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 16:35:23 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 16:35:23 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 16:35:23 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:35:23 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:35:24 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 16:35:24 JobSubmitter [INFO] number of splits:1
2016-07-12 16:35:24 JobSubmitter [INFO] Submitting tokens for job: job_local452797804_0001
2016-07-12 16:35:24 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:35:24 Job [INFO] Running job: job_local452797804_0001
2016-07-12 16:35:24 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:35:24 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:35:24 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:35:24 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:35:24 LocalJobRunner [INFO] Starting task: attempt_local452797804_0001_m_000000_0
2016-07-12 16:35:24 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:35:25 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:35:25 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 16:35:25 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:35:25 LocalJobRunner [WARN] job_local452797804_0001
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyInputFormat.createRecordReader(AvroKeyInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.<init>(MapTask.java:515)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:758)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:35:25 Job [INFO] Job job_local452797804_0001 running in uber mode : false
2016-07-12 16:35:25 Job [INFO]  map 0% reduce 0%
2016-07-12 16:35:25 Job [INFO] Job job_local452797804_0001 failed with state FAILED due to: NA
2016-07-12 16:35:25 Job [INFO] Counters: 0
2016-07-12 16:35:25 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:35:25 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:35:25 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:35:25 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:35:25 JobSubmitter [INFO] number of splits:0
2016-07-12 16:35:25 JobSubmitter [INFO] Submitting tokens for job: job_local2104613926_0002
2016-07-12 16:35:25 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:35:25 Job [INFO] Running job: job_local2104613926_0002
2016-07-12 16:35:25 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:35:25 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:35:25 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:35:25 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:35:25 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:35:25 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:35:25 LocalJobRunner [INFO] Starting task: attempt_local2104613926_0002_r_000000_0
2016-07-12 16:35:25 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:35:25 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:35:25 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@49a267b
2016-07-12 16:35:25 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:35:25 EventFetcher [INFO] attempt_local2104613926_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:35:26 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:35:26 LocalJobRunner [INFO] 
2016-07-12 16:35:26 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:35:26 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:35:26 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:35:26 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:35:26 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:35:26 LocalJobRunner [INFO] 
2016-07-12 16:35:26 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:35:26 LocalJobRunner [WARN] job_local2104613926_0002
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:35:26 Job [INFO] Job job_local2104613926_0002 running in uber mode : false
2016-07-12 16:35:26 Job [INFO]  map 0% reduce 0%
2016-07-12 16:35:26 Job [INFO] Job job_local2104613926_0002 failed with state FAILED due to: NA
2016-07-12 16:35:26 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:35:27 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:35:27 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:35:27 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:35:27 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:35:27 JobSubmitter [INFO] number of splits:0
2016-07-12 16:35:27 JobSubmitter [INFO] Submitting tokens for job: job_local1433057880_0003
2016-07-12 16:35:27 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:35:27 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:35:27 Job [INFO] Running job: job_local1433057880_0003
2016-07-12 16:35:27 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:35:27 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:35:27 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:35:27 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:35:27 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:35:27 LocalJobRunner [INFO] Starting task: attempt_local1433057880_0003_r_000000_0
2016-07-12 16:35:27 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:35:27 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:35:27 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5ee81e6b
2016-07-12 16:35:27 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:35:27 EventFetcher [INFO] attempt_local1433057880_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:35:27 LocalJobRunner [INFO] 
2016-07-12 16:35:27 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:35:27 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:35:27 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:35:27 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:35:27 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:35:27 LocalJobRunner [INFO] 
2016-07-12 16:35:27 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:35:27 LocalJobRunner [WARN] job_local1433057880_0003
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:35:28 Job [INFO] Job job_local1433057880_0003 running in uber mode : false
2016-07-12 16:35:28 Job [INFO]  map 0% reduce 0%
2016-07-12 16:35:28 Job [INFO] Job job_local1433057880_0003 failed with state FAILED due to: NA
2016-07-12 16:35:28 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:35:28 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:35:28 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:35:28 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:35:28 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:35:28 JobSubmitter [INFO] number of splits:0
2016-07-12 16:35:28 JobSubmitter [INFO] Submitting tokens for job: job_local874504964_0004
2016-07-12 16:35:28 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:35:28 Job [INFO] Running job: job_local874504964_0004
2016-07-12 16:35:28 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:35:28 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:35:28 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:35:28 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:35:28 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:35:28 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:35:28 LocalJobRunner [INFO] Starting task: attempt_local874504964_0004_r_000000_0
2016-07-12 16:35:28 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:35:28 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:35:28 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2e6a4c71
2016-07-12 16:35:28 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:35:28 EventFetcher [INFO] attempt_local874504964_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:35:28 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:35:28 LocalJobRunner [INFO] 
2016-07-12 16:35:28 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:35:28 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:35:28 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:35:28 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:35:28 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:35:28 LocalJobRunner [INFO] 
2016-07-12 16:35:28 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:35:28 LocalJobRunner [WARN] job_local874504964_0004
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:35:29 Job [INFO] Job job_local874504964_0004 running in uber mode : false
2016-07-12 16:35:29 Job [INFO]  map 0% reduce 0%
2016-07-12 16:35:29 Job [INFO] Job job_local874504964_0004 failed with state FAILED due to: NA
2016-07-12 16:35:29 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:35:58 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 16:35:59 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 16:35:59 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 16:35:59 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:35:59 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:35:59 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 16:35:59 JobSubmitter [INFO] number of splits:1
2016-07-12 16:35:59 JobSubmitter [INFO] Submitting tokens for job: job_local163916204_0001
2016-07-12 16:35:59 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:35:59 Job [INFO] Running job: job_local163916204_0001
2016-07-12 16:35:59 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:35:59 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:35:59 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:35:59 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:35:59 LocalJobRunner [INFO] Starting task: attempt_local163916204_0001_m_000000_0
2016-07-12 16:35:59 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:35:59 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:35:59 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 16:35:59 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:35:59 LocalJobRunner [WARN] job_local163916204_0001
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyInputFormat.createRecordReader(AvroKeyInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.<init>(MapTask.java:515)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:758)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:36:00 Job [INFO] Job job_local163916204_0001 running in uber mode : false
2016-07-12 16:36:00 Job [INFO]  map 0% reduce 0%
2016-07-12 16:36:00 Job [INFO] Job job_local163916204_0001 failed with state FAILED due to: NA
2016-07-12 16:36:00 Job [INFO] Counters: 0
2016-07-12 16:36:00 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:36:00 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:36:00 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:36:00 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:36:00 JobSubmitter [INFO] number of splits:0
2016-07-12 16:36:00 JobSubmitter [INFO] Submitting tokens for job: job_local290188690_0002
2016-07-12 16:36:00 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:36:00 Job [INFO] Running job: job_local290188690_0002
2016-07-12 16:36:00 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:36:00 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:36:00 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:36:00 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:36:00 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:36:00 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:36:00 LocalJobRunner [INFO] Starting task: attempt_local290188690_0002_r_000000_0
2016-07-12 16:36:00 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:36:00 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:36:00 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@985ee04
2016-07-12 16:36:00 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:36:00 EventFetcher [INFO] attempt_local290188690_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:36:00 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:36:00 LocalJobRunner [INFO] 
2016-07-12 16:36:00 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:36:00 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:36:00 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:36:00 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:36:00 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:36:00 LocalJobRunner [INFO] 
2016-07-12 16:36:00 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:36:00 LocalJobRunner [WARN] job_local290188690_0002
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:36:01 Job [INFO] Job job_local290188690_0002 running in uber mode : false
2016-07-12 16:36:01 Job [INFO]  map 0% reduce 0%
2016-07-12 16:36:01 Job [INFO] Job job_local290188690_0002 failed with state FAILED due to: NA
2016-07-12 16:36:01 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:36:02 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:36:02 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:36:02 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:36:02 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:36:02 JobSubmitter [INFO] number of splits:0
2016-07-12 16:36:02 JobSubmitter [INFO] Submitting tokens for job: job_local773584877_0003
2016-07-12 16:36:02 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:36:02 Job [INFO] Running job: job_local773584877_0003
2016-07-12 16:36:02 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:36:02 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:36:02 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:36:02 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:36:02 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:36:02 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:36:02 LocalJobRunner [INFO] Starting task: attempt_local773584877_0003_r_000000_0
2016-07-12 16:36:02 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:36:02 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:36:02 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6fe59db7
2016-07-12 16:36:02 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:36:02 EventFetcher [INFO] attempt_local773584877_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:36:02 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:36:02 LocalJobRunner [INFO] 
2016-07-12 16:36:02 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:36:02 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:36:02 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:36:02 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:36:02 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:36:02 LocalJobRunner [INFO] 
2016-07-12 16:36:02 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:36:02 LocalJobRunner [WARN] job_local773584877_0003
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:36:03 Job [INFO] Job job_local773584877_0003 running in uber mode : false
2016-07-12 16:36:03 Job [INFO]  map 0% reduce 0%
2016-07-12 16:36:03 Job [INFO] Job job_local773584877_0003 failed with state FAILED due to: NA
2016-07-12 16:36:03 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:36:03 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:36:03 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:36:03 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:36:03 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:36:03 JobSubmitter [INFO] number of splits:0
2016-07-12 16:36:03 JobSubmitter [INFO] Submitting tokens for job: job_local1709469144_0004
2016-07-12 16:36:03 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:36:03 Job [INFO] Running job: job_local1709469144_0004
2016-07-12 16:36:03 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:36:03 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:36:03 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:36:03 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:36:03 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:36:03 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:36:03 LocalJobRunner [INFO] Starting task: attempt_local1709469144_0004_r_000000_0
2016-07-12 16:36:03 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:36:03 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:36:03 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1701b716
2016-07-12 16:36:03 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:36:03 EventFetcher [INFO] attempt_local1709469144_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:36:03 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:36:03 LocalJobRunner [INFO] 
2016-07-12 16:36:03 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:36:03 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:36:03 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:36:03 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:36:03 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:36:03 LocalJobRunner [INFO] 
2016-07-12 16:36:03 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:36:03 LocalJobRunner [WARN] job_local1709469144_0004
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:36:04 Job [INFO] Job job_local1709469144_0004 running in uber mode : false
2016-07-12 16:36:04 Job [INFO]  map 0% reduce 0%
2016-07-12 16:36:04 Job [INFO] Job job_local1709469144_0004 failed with state FAILED due to: NA
2016-07-12 16:36:04 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:38:45 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 16:38:45 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 16:38:45 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 16:38:46 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:38:46 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:38:46 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 16:38:46 JobSubmitter [INFO] number of splits:1
2016-07-12 16:38:46 JobSubmitter [INFO] Submitting tokens for job: job_local762676345_0001
2016-07-12 16:38:46 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:38:46 Job [INFO] Running job: job_local762676345_0001
2016-07-12 16:38:46 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:38:46 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:38:46 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:38:46 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:38:46 LocalJobRunner [INFO] Starting task: attempt_local762676345_0001_m_000000_0
2016-07-12 16:38:46 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:38:46 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:38:46 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 16:38:46 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:38:46 LocalJobRunner [WARN] job_local762676345_0001
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyInputFormat.createRecordReader(AvroKeyInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.<init>(MapTask.java:515)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:758)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:38:47 Job [INFO] Job job_local762676345_0001 running in uber mode : false
2016-07-12 16:38:47 Job [INFO]  map 0% reduce 0%
2016-07-12 16:38:47 Job [INFO] Job job_local762676345_0001 failed with state FAILED due to: NA
2016-07-12 16:38:47 Job [INFO] Counters: 0
2016-07-12 16:38:47 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:38:47 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:38:47 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:38:47 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:38:47 JobSubmitter [INFO] number of splits:0
2016-07-12 16:38:47 JobSubmitter [INFO] Submitting tokens for job: job_local1893626941_0002
2016-07-12 16:38:47 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:38:47 Job [INFO] Running job: job_local1893626941_0002
2016-07-12 16:38:47 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:38:47 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:38:47 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:38:47 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:38:47 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:38:47 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:38:47 LocalJobRunner [INFO] Starting task: attempt_local1893626941_0002_r_000000_0
2016-07-12 16:38:47 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:38:47 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:38:47 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5b1caadc
2016-07-12 16:38:47 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:38:47 EventFetcher [INFO] attempt_local1893626941_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:38:47 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:38:47 LocalJobRunner [INFO] 
2016-07-12 16:38:47 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:38:47 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:38:47 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:38:47 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:38:47 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:38:47 LocalJobRunner [INFO] 
2016-07-12 16:38:47 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:38:47 LocalJobRunner [WARN] job_local1893626941_0002
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:38:48 Job [INFO] Job job_local1893626941_0002 running in uber mode : false
2016-07-12 16:38:48 Job [INFO]  map 0% reduce 0%
2016-07-12 16:38:48 Job [INFO] Job job_local1893626941_0002 failed with state FAILED due to: NA
2016-07-12 16:38:48 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:38:48 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:38:48 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:38:48 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:38:48 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:38:48 JobSubmitter [INFO] number of splits:0
2016-07-12 16:38:48 JobSubmitter [INFO] Submitting tokens for job: job_local455157916_0003
2016-07-12 16:38:49 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:38:49 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:38:49 Job [INFO] Running job: job_local455157916_0003
2016-07-12 16:38:49 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:38:49 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:38:49 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:38:49 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:38:49 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:38:49 LocalJobRunner [INFO] Starting task: attempt_local455157916_0003_r_000000_0
2016-07-12 16:38:49 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:38:49 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:38:49 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@195e634a
2016-07-12 16:38:49 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:38:49 EventFetcher [INFO] attempt_local455157916_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:38:49 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:38:49 LocalJobRunner [INFO] 
2016-07-12 16:38:49 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:38:49 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:38:49 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:38:49 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:38:49 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:38:49 LocalJobRunner [INFO] 
2016-07-12 16:38:49 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:38:49 LocalJobRunner [WARN] job_local455157916_0003
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:38:50 Job [INFO] Job job_local455157916_0003 running in uber mode : false
2016-07-12 16:38:50 Job [INFO]  map 0% reduce 0%
2016-07-12 16:38:50 Job [INFO] Job job_local455157916_0003 failed with state FAILED due to: NA
2016-07-12 16:38:50 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:38:50 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:38:50 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:38:50 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:38:50 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:38:50 JobSubmitter [INFO] number of splits:0
2016-07-12 16:38:50 JobSubmitter [INFO] Submitting tokens for job: job_local356189976_0004
2016-07-12 16:38:50 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:38:50 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:38:50 Job [INFO] Running job: job_local356189976_0004
2016-07-12 16:38:50 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:38:50 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:38:50 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:38:50 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:38:50 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:38:50 LocalJobRunner [INFO] Starting task: attempt_local356189976_0004_r_000000_0
2016-07-12 16:38:50 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:38:50 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:38:50 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@17e65de0
2016-07-12 16:38:50 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:38:50 EventFetcher [INFO] attempt_local356189976_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:38:50 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:38:50 LocalJobRunner [INFO] 
2016-07-12 16:38:50 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:38:50 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:38:50 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:38:50 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:38:50 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:38:50 LocalJobRunner [INFO] 
2016-07-12 16:38:50 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:38:50 LocalJobRunner [WARN] job_local356189976_0004
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:38:51 Job [INFO] Job job_local356189976_0004 running in uber mode : false
2016-07-12 16:38:51 Job [INFO]  map 0% reduce 0%
2016-07-12 16:38:51 Job [INFO] Job job_local356189976_0004 failed with state FAILED due to: NA
2016-07-12 16:38:51 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:43:57 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 16:43:57 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 16:43:57 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 16:43:58 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:43:58 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:43:58 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 16:43:58 JobSubmitter [INFO] number of splits:1
2016-07-12 16:43:58 JobSubmitter [INFO] Submitting tokens for job: job_local419581132_0001
2016-07-12 16:43:58 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:43:58 Job [INFO] Running job: job_local419581132_0001
2016-07-12 16:43:58 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:43:58 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:43:58 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:43:58 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:43:58 LocalJobRunner [INFO] Starting task: attempt_local419581132_0001_m_000000_0
2016-07-12 16:43:58 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:43:58 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:43:58 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 16:43:58 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:43:58 LocalJobRunner [WARN] job_local419581132_0001
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyInputFormat.createRecordReader(AvroKeyInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.<init>(MapTask.java:515)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:758)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:43:59 Job [INFO] Job job_local419581132_0001 running in uber mode : false
2016-07-12 16:43:59 Job [INFO]  map 0% reduce 0%
2016-07-12 16:43:59 Job [INFO] Job job_local419581132_0001 failed with state FAILED due to: NA
2016-07-12 16:43:59 Job [INFO] Counters: 0
2016-07-12 16:43:59 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:43:59 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:43:59 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:43:59 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:43:59 JobSubmitter [INFO] number of splits:0
2016-07-12 16:43:59 JobSubmitter [INFO] Submitting tokens for job: job_local1464942162_0002
2016-07-12 16:43:59 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:43:59 Job [INFO] Running job: job_local1464942162_0002
2016-07-12 16:43:59 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:43:59 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:43:59 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:43:59 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:43:59 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:43:59 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:43:59 LocalJobRunner [INFO] Starting task: attempt_local1464942162_0002_r_000000_0
2016-07-12 16:43:59 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:43:59 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:43:59 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5b8e4e73
2016-07-12 16:43:59 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:43:59 EventFetcher [INFO] attempt_local1464942162_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:43:59 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:43:59 LocalJobRunner [INFO] 
2016-07-12 16:43:59 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:43:59 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:43:59 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:43:59 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:43:59 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:43:59 LocalJobRunner [INFO] 
2016-07-12 16:43:59 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:43:59 LocalJobRunner [WARN] job_local1464942162_0002
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:44:00 Job [INFO] Job job_local1464942162_0002 running in uber mode : false
2016-07-12 16:44:00 Job [INFO]  map 0% reduce 0%
2016-07-12 16:44:00 Job [INFO] Job job_local1464942162_0002 failed with state FAILED due to: NA
2016-07-12 16:44:00 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:44:00 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:44:00 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:44:00 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:44:00 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:44:00 JobSubmitter [INFO] number of splits:0
2016-07-12 16:44:00 JobSubmitter [INFO] Submitting tokens for job: job_local62421195_0003
2016-07-12 16:44:01 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:44:01 Job [INFO] Running job: job_local62421195_0003
2016-07-12 16:44:01 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:44:01 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:44:01 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:44:01 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:44:01 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:44:01 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:44:01 LocalJobRunner [INFO] Starting task: attempt_local62421195_0003_r_000000_0
2016-07-12 16:44:01 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:44:01 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:44:01 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@aed7129
2016-07-12 16:44:01 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:44:01 EventFetcher [INFO] attempt_local62421195_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:44:01 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:44:01 LocalJobRunner [INFO] 
2016-07-12 16:44:01 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:44:01 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:44:01 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:44:01 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:44:01 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:44:01 LocalJobRunner [INFO] 
2016-07-12 16:44:01 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:44:01 LocalJobRunner [WARN] job_local62421195_0003
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:44:02 Job [INFO] Job job_local62421195_0003 running in uber mode : false
2016-07-12 16:44:02 Job [INFO]  map 0% reduce 0%
2016-07-12 16:44:02 Job [INFO] Job job_local62421195_0003 failed with state FAILED due to: NA
2016-07-12 16:44:02 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:44:02 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:44:02 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:44:02 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:44:02 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:44:02 JobSubmitter [INFO] number of splits:0
2016-07-12 16:44:02 JobSubmitter [INFO] Submitting tokens for job: job_local2083794042_0004
2016-07-12 16:44:02 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:44:02 Job [INFO] Running job: job_local2083794042_0004
2016-07-12 16:44:02 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:44:02 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:44:02 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:44:02 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:44:02 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:44:02 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:44:02 LocalJobRunner [INFO] Starting task: attempt_local2083794042_0004_r_000000_0
2016-07-12 16:44:02 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:44:02 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:44:02 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1b2686e7
2016-07-12 16:44:02 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:44:02 EventFetcher [INFO] attempt_local2083794042_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:44:02 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:44:02 LocalJobRunner [INFO] 
2016-07-12 16:44:02 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:44:02 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:44:02 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:44:02 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:44:02 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:44:02 LocalJobRunner [INFO] 
2016-07-12 16:44:02 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:44:02 LocalJobRunner [WARN] job_local2083794042_0004
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:44:03 Job [INFO] Job job_local2083794042_0004 running in uber mode : false
2016-07-12 16:44:03 Job [INFO]  map 0% reduce 0%
2016-07-12 16:44:03 Job [INFO] Job job_local2083794042_0004 failed with state FAILED due to: NA
2016-07-12 16:44:03 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:45:54 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 16:45:54 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 16:45:54 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 16:45:54 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:45:54 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:45:54 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 16:45:54 JobSubmitter [INFO] number of splits:1
2016-07-12 16:45:54 JobSubmitter [INFO] Submitting tokens for job: job_local1082511703_0001
2016-07-12 16:45:55 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:45:55 Job [INFO] Running job: job_local1082511703_0001
2016-07-12 16:45:55 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:45:55 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:45:55 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:45:55 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:45:55 LocalJobRunner [INFO] Starting task: attempt_local1082511703_0001_m_000000_0
2016-07-12 16:45:55 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:45:55 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:45:55 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 16:45:55 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:45:55 LocalJobRunner [WARN] job_local1082511703_0001
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyInputFormat.createRecordReader(AvroKeyInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.<init>(MapTask.java:515)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:758)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:45:56 Job [INFO] Job job_local1082511703_0001 running in uber mode : false
2016-07-12 16:45:56 Job [INFO]  map 0% reduce 0%
2016-07-12 16:45:56 Job [INFO] Job job_local1082511703_0001 failed with state FAILED due to: NA
2016-07-12 16:45:56 Job [INFO] Counters: 0
2016-07-12 16:45:56 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:45:56 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:45:56 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:45:56 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:45:56 JobSubmitter [INFO] number of splits:0
2016-07-12 16:45:56 JobSubmitter [INFO] Submitting tokens for job: job_local360433394_0002
2016-07-12 16:45:56 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:45:56 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:45:56 Job [INFO] Running job: job_local360433394_0002
2016-07-12 16:45:56 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:45:56 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:45:56 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:45:56 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:45:56 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:45:56 LocalJobRunner [INFO] Starting task: attempt_local360433394_0002_r_000000_0
2016-07-12 16:45:56 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:45:56 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:45:56 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@14be6077
2016-07-12 16:45:56 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:45:56 EventFetcher [INFO] attempt_local360433394_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:45:56 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:45:56 LocalJobRunner [INFO] 
2016-07-12 16:45:56 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:45:56 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:45:56 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:45:56 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:45:56 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:45:56 LocalJobRunner [INFO] 
2016-07-12 16:45:56 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:45:56 LocalJobRunner [WARN] job_local360433394_0002
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:45:57 Job [INFO] Job job_local360433394_0002 running in uber mode : false
2016-07-12 16:45:57 Job [INFO]  map 0% reduce 0%
2016-07-12 16:45:57 Job [INFO] Job job_local360433394_0002 failed with state FAILED due to: NA
2016-07-12 16:45:57 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:45:57 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:45:57 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:45:57 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:45:57 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:45:57 JobSubmitter [INFO] number of splits:0
2016-07-12 16:45:57 JobSubmitter [INFO] Submitting tokens for job: job_local1596495146_0003
2016-07-12 16:45:58 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:45:58 Job [INFO] Running job: job_local1596495146_0003
2016-07-12 16:45:58 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:45:58 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:45:58 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:45:58 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:45:58 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:45:58 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:45:58 LocalJobRunner [INFO] Starting task: attempt_local1596495146_0003_r_000000_0
2016-07-12 16:45:58 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:45:58 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:45:58 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2caf7cab
2016-07-12 16:45:58 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:45:58 EventFetcher [INFO] attempt_local1596495146_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:45:58 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:45:58 LocalJobRunner [INFO] 
2016-07-12 16:45:58 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:45:58 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:45:58 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:45:58 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:45:58 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:45:58 LocalJobRunner [INFO] 
2016-07-12 16:45:58 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:45:58 LocalJobRunner [WARN] job_local1596495146_0003
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:45:59 Job [INFO] Job job_local1596495146_0003 running in uber mode : false
2016-07-12 16:45:59 Job [INFO]  map 0% reduce 0%
2016-07-12 16:45:59 Job [INFO] Job job_local1596495146_0003 failed with state FAILED due to: NA
2016-07-12 16:45:59 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:45:59 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:45:59 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:45:59 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:45:59 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:45:59 JobSubmitter [INFO] number of splits:0
2016-07-12 16:45:59 JobSubmitter [INFO] Submitting tokens for job: job_local1961393593_0004
2016-07-12 16:45:59 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:45:59 Job [INFO] Running job: job_local1961393593_0004
2016-07-12 16:45:59 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:45:59 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:45:59 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:45:59 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:45:59 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:45:59 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:45:59 LocalJobRunner [INFO] Starting task: attempt_local1961393593_0004_r_000000_0
2016-07-12 16:45:59 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:45:59 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:45:59 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@bf6867f
2016-07-12 16:45:59 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:45:59 EventFetcher [INFO] attempt_local1961393593_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:45:59 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:45:59 LocalJobRunner [INFO] 
2016-07-12 16:45:59 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:45:59 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:45:59 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:45:59 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:45:59 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:45:59 LocalJobRunner [INFO] 
2016-07-12 16:45:59 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:45:59 LocalJobRunner [WARN] job_local1961393593_0004
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:46:00 Job [INFO] Job job_local1961393593_0004 running in uber mode : false
2016-07-12 16:46:00 Job [INFO]  map 0% reduce 0%
2016-07-12 16:46:00 Job [INFO] Job job_local1961393593_0004 failed with state FAILED due to: NA
2016-07-12 16:46:00 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:50:17 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 16:50:17 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 16:50:17 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 16:50:18 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:50:18 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 16:50:18 JobSubmitter [INFO] number of splits:1
2016-07-12 16:50:18 JobSubmitter [INFO] Submitting tokens for job: job_local372333552_0001
2016-07-12 16:50:18 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:50:18 Job [INFO] Running job: job_local372333552_0001
2016-07-12 16:50:18 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:50:18 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:50:18 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:50:18 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:50:18 LocalJobRunner [INFO] Starting task: attempt_local372333552_0001_m_000000_0
2016-07-12 16:50:18 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:50:18 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:50:18 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 16:50:18 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:50:18 LocalJobRunner [WARN] job_local372333552_0001
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyInputFormat.createRecordReader(AvroKeyInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.<init>(MapTask.java:515)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:758)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:50:19 Job [INFO] Job job_local372333552_0001 running in uber mode : false
2016-07-12 16:50:19 Job [INFO]  map 0% reduce 0%
2016-07-12 16:50:19 Job [INFO] Job job_local372333552_0001 failed with state FAILED due to: NA
2016-07-12 16:50:19 Job [INFO] Counters: 0
2016-07-12 16:50:19 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:50:19 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:50:19 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:50:19 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:50:19 JobSubmitter [INFO] number of splits:0
2016-07-12 16:50:19 JobSubmitter [INFO] Submitting tokens for job: job_local1625393427_0002
2016-07-12 16:50:19 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:50:19 Job [INFO] Running job: job_local1625393427_0002
2016-07-12 16:50:19 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:50:19 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:50:19 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:50:19 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:50:19 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:50:19 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:50:19 LocalJobRunner [INFO] Starting task: attempt_local1625393427_0002_r_000000_0
2016-07-12 16:50:19 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:50:19 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:50:19 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@110216a0
2016-07-12 16:50:19 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:50:19 EventFetcher [INFO] attempt_local1625393427_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:50:19 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:50:19 LocalJobRunner [INFO] 
2016-07-12 16:50:19 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:50:19 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:50:19 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:50:19 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:50:19 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:50:19 LocalJobRunner [INFO] 
2016-07-12 16:50:19 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:50:19 LocalJobRunner [WARN] job_local1625393427_0002
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:50:20 Job [INFO] Job job_local1625393427_0002 running in uber mode : false
2016-07-12 16:50:20 Job [INFO]  map 0% reduce 0%
2016-07-12 16:50:20 Job [INFO] Job job_local1625393427_0002 failed with state FAILED due to: NA
2016-07-12 16:50:20 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:50:20 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:50:20 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:50:20 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:50:20 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:50:20 JobSubmitter [INFO] number of splits:0
2016-07-12 16:50:20 JobSubmitter [INFO] Submitting tokens for job: job_local2048944323_0003
2016-07-12 16:50:21 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:50:21 Job [INFO] Running job: job_local2048944323_0003
2016-07-12 16:50:21 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:50:21 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:50:21 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:50:21 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:50:21 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:50:21 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:50:21 LocalJobRunner [INFO] Starting task: attempt_local2048944323_0003_r_000000_0
2016-07-12 16:50:21 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:50:21 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:50:21 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@56ed27c5
2016-07-12 16:50:21 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:50:21 EventFetcher [INFO] attempt_local2048944323_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:50:21 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:50:21 LocalJobRunner [INFO] 
2016-07-12 16:50:21 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:50:21 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:50:21 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:50:21 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:50:21 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:50:21 LocalJobRunner [INFO] 
2016-07-12 16:50:21 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:50:21 LocalJobRunner [WARN] job_local2048944323_0003
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:50:22 Job [INFO] Job job_local2048944323_0003 running in uber mode : false
2016-07-12 16:50:22 Job [INFO]  map 0% reduce 0%
2016-07-12 16:50:22 Job [INFO] Job job_local2048944323_0003 failed with state FAILED due to: NA
2016-07-12 16:50:22 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:50:22 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:50:22 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:50:22 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:50:22 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:50:22 JobSubmitter [INFO] number of splits:0
2016-07-12 16:50:22 JobSubmitter [INFO] Submitting tokens for job: job_local1693233417_0004
2016-07-12 16:50:22 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:50:22 Job [INFO] Running job: job_local1693233417_0004
2016-07-12 16:50:22 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:50:22 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:50:22 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:50:22 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:50:22 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:50:22 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:50:22 LocalJobRunner [INFO] Starting task: attempt_local1693233417_0004_r_000000_0
2016-07-12 16:50:22 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:50:23 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:50:23 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@12c8a42d
2016-07-12 16:50:23 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:50:23 EventFetcher [INFO] attempt_local1693233417_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:50:23 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:50:23 LocalJobRunner [INFO] 
2016-07-12 16:50:23 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:50:23 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:50:23 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:50:23 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:50:23 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:50:23 LocalJobRunner [INFO] 
2016-07-12 16:50:23 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:50:23 LocalJobRunner [WARN] job_local1693233417_0004
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:50:23 Job [INFO] Job job_local1693233417_0004 running in uber mode : false
2016-07-12 16:50:23 Job [INFO]  map 0% reduce 0%
2016-07-12 16:50:23 Job [INFO] Job job_local1693233417_0004 failed with state FAILED due to: NA
2016-07-12 16:50:23 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:52:06 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 16:52:06 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 16:52:06 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 16:52:07 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:52:07 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 16:52:07 JobSubmitter [INFO] number of splits:1
2016-07-12 16:52:07 JobSubmitter [INFO] Submitting tokens for job: job_local1694978435_0001
2016-07-12 16:52:07 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:52:07 Job [INFO] Running job: job_local1694978435_0001
2016-07-12 16:52:07 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:52:07 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:52:07 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:52:07 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:52:07 LocalJobRunner [INFO] Starting task: attempt_local1694978435_0001_m_000000_0
2016-07-12 16:52:07 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:52:07 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:52:07 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 16:52:07 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:52:07 LocalJobRunner [WARN] job_local1694978435_0001
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyInputFormat.createRecordReader(AvroKeyInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.<init>(MapTask.java:515)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:758)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:52:08 Job [INFO] Job job_local1694978435_0001 running in uber mode : false
2016-07-12 16:52:08 Job [INFO]  map 0% reduce 0%
2016-07-12 16:52:08 Job [INFO] Job job_local1694978435_0001 failed with state FAILED due to: NA
2016-07-12 16:52:08 Job [INFO] Counters: 0
2016-07-12 16:52:08 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:52:08 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:52:08 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:52:08 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:52:08 JobSubmitter [INFO] number of splits:0
2016-07-12 16:52:08 JobSubmitter [INFO] Submitting tokens for job: job_local2100228546_0002
2016-07-12 16:52:08 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:52:08 Job [INFO] Running job: job_local2100228546_0002
2016-07-12 16:52:08 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:52:08 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:52:08 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:52:08 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:52:08 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:52:08 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:52:08 LocalJobRunner [INFO] Starting task: attempt_local2100228546_0002_r_000000_0
2016-07-12 16:52:08 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:52:08 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:52:08 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@56c26d1d
2016-07-12 16:52:08 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:52:08 EventFetcher [INFO] attempt_local2100228546_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:52:08 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:52:08 LocalJobRunner [INFO] 
2016-07-12 16:52:08 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:52:08 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:52:08 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:52:08 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:52:08 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:52:08 LocalJobRunner [INFO] 
2016-07-12 16:52:08 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:52:08 LocalJobRunner [WARN] job_local2100228546_0002
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:52:09 Job [INFO] Job job_local2100228546_0002 running in uber mode : false
2016-07-12 16:52:09 Job [INFO]  map 0% reduce 0%
2016-07-12 16:52:09 Job [INFO] Job job_local2100228546_0002 failed with state FAILED due to: NA
2016-07-12 16:52:09 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:52:09 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:52:09 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:52:09 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:52:09 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:52:09 JobSubmitter [INFO] number of splits:0
2016-07-12 16:52:09 JobSubmitter [INFO] Submitting tokens for job: job_local1129108401_0003
2016-07-12 16:52:09 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:52:09 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:52:09 Job [INFO] Running job: job_local1129108401_0003
2016-07-12 16:52:09 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:52:09 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:52:09 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:52:09 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:52:09 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:52:09 LocalJobRunner [INFO] Starting task: attempt_local1129108401_0003_r_000000_0
2016-07-12 16:52:09 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:52:09 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:52:09 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4fee8bd0
2016-07-12 16:52:09 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:52:09 EventFetcher [INFO] attempt_local1129108401_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:52:09 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:52:09 LocalJobRunner [INFO] 
2016-07-12 16:52:09 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:52:09 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:52:09 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:52:09 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:52:09 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:52:09 LocalJobRunner [INFO] 
2016-07-12 16:52:09 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:52:09 LocalJobRunner [WARN] job_local1129108401_0003
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:52:10 Job [INFO] Job job_local1129108401_0003 running in uber mode : false
2016-07-12 16:52:10 Job [INFO]  map 0% reduce 0%
2016-07-12 16:52:10 Job [INFO] Job job_local1129108401_0003 failed with state FAILED due to: NA
2016-07-12 16:52:10 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:52:10 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:52:11 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:52:11 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:52:11 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:52:11 JobSubmitter [INFO] number of splits:0
2016-07-12 16:52:11 JobSubmitter [INFO] Submitting tokens for job: job_local1750048410_0004
2016-07-12 16:52:11 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:52:11 Job [INFO] Running job: job_local1750048410_0004
2016-07-12 16:52:11 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:52:11 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:52:11 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:52:11 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:52:11 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:52:11 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:52:11 LocalJobRunner [INFO] Starting task: attempt_local1750048410_0004_r_000000_0
2016-07-12 16:52:11 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:52:11 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:52:11 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@544b0308
2016-07-12 16:52:11 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:52:11 EventFetcher [INFO] attempt_local1750048410_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:52:11 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:52:11 LocalJobRunner [INFO] 
2016-07-12 16:52:11 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:52:11 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:52:11 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:52:11 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:52:11 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:52:11 LocalJobRunner [INFO] 
2016-07-12 16:52:11 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:52:11 LocalJobRunner [WARN] job_local1750048410_0004
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:52:12 Job [INFO] Job job_local1750048410_0004 running in uber mode : false
2016-07-12 16:52:12 Job [INFO]  map 0% reduce 0%
2016-07-12 16:52:12 Job [INFO] Job job_local1750048410_0004 failed with state FAILED due to: NA
2016-07-12 16:52:12 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:53:43 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 16:53:43 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 16:53:43 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 16:53:43 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:53:43 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 16:53:43 JobSubmitter [INFO] number of splits:1
2016-07-12 16:53:44 JobSubmitter [INFO] Submitting tokens for job: job_local19043832_0001
2016-07-12 16:53:44 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:53:44 Job [INFO] Running job: job_local19043832_0001
2016-07-12 16:53:44 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:53:44 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:53:44 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:53:44 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:53:44 LocalJobRunner [INFO] Starting task: attempt_local19043832_0001_m_000000_0
2016-07-12 16:53:44 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:53:44 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:53:44 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 16:53:44 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:53:44 LocalJobRunner [WARN] job_local19043832_0001
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyInputFormat.createRecordReader(AvroKeyInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.<init>(MapTask.java:515)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:758)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:53:45 Job [INFO] Job job_local19043832_0001 running in uber mode : false
2016-07-12 16:53:45 Job [INFO]  map 0% reduce 0%
2016-07-12 16:53:45 Job [INFO] Job job_local19043832_0001 failed with state FAILED due to: NA
2016-07-12 16:53:45 Job [INFO] Counters: 0
2016-07-12 16:53:45 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:53:45 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:53:45 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:53:45 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:53:45 JobSubmitter [INFO] number of splits:0
2016-07-12 16:53:45 JobSubmitter [INFO] Submitting tokens for job: job_local970225281_0002
2016-07-12 16:53:45 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:53:45 Job [INFO] Running job: job_local970225281_0002
2016-07-12 16:53:45 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:53:45 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:53:45 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:53:45 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:53:45 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:53:45 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:53:45 LocalJobRunner [INFO] Starting task: attempt_local970225281_0002_r_000000_0
2016-07-12 16:53:45 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:53:45 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:53:45 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@52815160
2016-07-12 16:53:45 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:53:45 EventFetcher [INFO] attempt_local970225281_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:53:45 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:53:45 LocalJobRunner [INFO] 
2016-07-12 16:53:45 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:53:45 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:53:45 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:53:45 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:53:45 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:53:45 LocalJobRunner [INFO] 
2016-07-12 16:53:45 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:53:45 LocalJobRunner [WARN] job_local970225281_0002
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:53:46 Job [INFO] Job job_local970225281_0002 running in uber mode : false
2016-07-12 16:53:46 Job [INFO]  map 0% reduce 0%
2016-07-12 16:53:46 Job [INFO] Job job_local970225281_0002 failed with state FAILED due to: NA
2016-07-12 16:53:46 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:53:46 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:53:46 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:53:46 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:53:46 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:53:46 JobSubmitter [INFO] number of splits:0
2016-07-12 16:53:46 JobSubmitter [INFO] Submitting tokens for job: job_local1972229415_0003
2016-07-12 16:53:47 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:53:47 Job [INFO] Running job: job_local1972229415_0003
2016-07-12 16:53:47 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:53:47 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:53:47 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:53:47 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:53:47 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:53:47 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:53:47 LocalJobRunner [INFO] Starting task: attempt_local1972229415_0003_r_000000_0
2016-07-12 16:53:47 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:53:47 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:53:47 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@29bde953
2016-07-12 16:53:47 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:53:47 EventFetcher [INFO] attempt_local1972229415_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:53:47 LocalJobRunner [INFO] 
2016-07-12 16:53:47 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:53:47 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:53:47 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:53:47 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:53:47 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:53:47 LocalJobRunner [INFO] 
2016-07-12 16:53:47 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:53:47 LocalJobRunner [WARN] job_local1972229415_0003
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:53:48 Job [INFO] Job job_local1972229415_0003 running in uber mode : false
2016-07-12 16:53:48 Job [INFO]  map 0% reduce 0%
2016-07-12 16:53:48 Job [INFO] Job job_local1972229415_0003 failed with state FAILED due to: NA
2016-07-12 16:53:48 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:53:48 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:53:48 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:53:48 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:53:48 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:53:48 JobSubmitter [INFO] number of splits:0
2016-07-12 16:53:48 JobSubmitter [INFO] Submitting tokens for job: job_local2035792479_0004
2016-07-12 16:53:48 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:53:48 Job [INFO] Running job: job_local2035792479_0004
2016-07-12 16:53:48 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:53:48 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:53:48 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:53:48 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:53:48 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:53:48 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:53:48 LocalJobRunner [INFO] Starting task: attempt_local2035792479_0004_r_000000_0
2016-07-12 16:53:48 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:53:48 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:53:48 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3072067e
2016-07-12 16:53:48 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:53:48 EventFetcher [INFO] attempt_local2035792479_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:53:48 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:53:48 LocalJobRunner [INFO] 
2016-07-12 16:53:48 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:53:48 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:53:48 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:53:48 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:53:48 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:53:48 LocalJobRunner [INFO] 
2016-07-12 16:53:48 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:53:48 LocalJobRunner [WARN] job_local2035792479_0004
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:53:49 Job [INFO] Job job_local2035792479_0004 running in uber mode : false
2016-07-12 16:53:49 Job [INFO]  map 0% reduce 0%
2016-07-12 16:53:49 Job [INFO] Job job_local2035792479_0004 failed with state FAILED due to: NA
2016-07-12 16:53:49 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:55:46 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 16:55:46 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 16:55:46 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 16:55:47 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:55:47 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 16:55:47 JobSubmitter [INFO] number of splits:1
2016-07-12 16:55:47 JobSubmitter [INFO] Submitting tokens for job: job_local344937607_0001
2016-07-12 16:55:47 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:55:47 Job [INFO] Running job: job_local344937607_0001
2016-07-12 16:55:47 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:55:47 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:55:47 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:55:47 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:55:47 LocalJobRunner [INFO] Starting task: attempt_local344937607_0001_m_000000_0
2016-07-12 16:55:47 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:55:47 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:55:47 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 16:55:47 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:55:47 LocalJobRunner [WARN] job_local344937607_0001
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyInputFormat.createRecordReader(AvroKeyInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.<init>(MapTask.java:515)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:758)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:55:48 Job [INFO] Job job_local344937607_0001 running in uber mode : false
2016-07-12 16:55:48 Job [INFO]  map 0% reduce 0%
2016-07-12 16:55:48 Job [INFO] Job job_local344937607_0001 failed with state FAILED due to: NA
2016-07-12 16:55:48 Job [INFO] Counters: 0
2016-07-12 16:55:48 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:55:48 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:55:48 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:55:48 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:55:48 JobSubmitter [INFO] number of splits:0
2016-07-12 16:55:48 JobSubmitter [INFO] Submitting tokens for job: job_local1565919374_0002
2016-07-12 16:55:48 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:55:48 Job [INFO] Running job: job_local1565919374_0002
2016-07-12 16:55:48 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:55:48 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:55:48 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:55:48 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:55:48 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:55:48 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:55:48 LocalJobRunner [INFO] Starting task: attempt_local1565919374_0002_r_000000_0
2016-07-12 16:55:48 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:55:48 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:55:48 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4823705
2016-07-12 16:55:48 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:55:48 EventFetcher [INFO] attempt_local1565919374_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:55:48 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:55:48 LocalJobRunner [INFO] 
2016-07-12 16:55:48 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:55:48 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:55:48 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:55:48 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:55:48 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:55:48 LocalJobRunner [INFO] 
2016-07-12 16:55:48 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:55:48 LocalJobRunner [WARN] job_local1565919374_0002
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:55:49 Job [INFO] Job job_local1565919374_0002 running in uber mode : false
2016-07-12 16:55:49 Job [INFO]  map 0% reduce 0%
2016-07-12 16:55:49 Job [INFO] Job job_local1565919374_0002 failed with state FAILED due to: NA
2016-07-12 16:55:49 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:55:49 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:55:49 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:55:49 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:55:49 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:55:49 JobSubmitter [INFO] number of splits:0
2016-07-12 16:55:49 JobSubmitter [INFO] Submitting tokens for job: job_local1641603943_0003
2016-07-12 16:55:49 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:55:49 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:55:49 Job [INFO] Running job: job_local1641603943_0003
2016-07-12 16:55:49 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:55:49 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:55:49 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:55:49 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:55:49 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:55:49 LocalJobRunner [INFO] Starting task: attempt_local1641603943_0003_r_000000_0
2016-07-12 16:55:49 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:55:49 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:55:49 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@611c03e4
2016-07-12 16:55:49 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:55:49 EventFetcher [INFO] attempt_local1641603943_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:55:49 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:55:49 LocalJobRunner [INFO] 
2016-07-12 16:55:49 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:55:49 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:55:49 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:55:49 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:55:49 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:55:49 LocalJobRunner [INFO] 
2016-07-12 16:55:49 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:55:49 LocalJobRunner [WARN] job_local1641603943_0003
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:55:50 Job [INFO] Job job_local1641603943_0003 running in uber mode : false
2016-07-12 16:55:50 Job [INFO]  map 0% reduce 0%
2016-07-12 16:55:50 Job [INFO] Job job_local1641603943_0003 failed with state FAILED due to: NA
2016-07-12 16:55:50 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:55:50 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:55:50 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:55:50 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:55:50 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:55:51 JobSubmitter [INFO] number of splits:0
2016-07-12 16:55:51 JobSubmitter [INFO] Submitting tokens for job: job_local662508340_0004
2016-07-12 16:55:51 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:55:51 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:55:51 Job [INFO] Running job: job_local662508340_0004
2016-07-12 16:55:51 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:55:51 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:55:51 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:55:51 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:55:51 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:55:51 LocalJobRunner [INFO] Starting task: attempt_local662508340_0004_r_000000_0
2016-07-12 16:55:51 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:55:51 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:55:51 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@30e9b2f8
2016-07-12 16:55:51 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:55:51 EventFetcher [INFO] attempt_local662508340_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:55:51 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:55:51 LocalJobRunner [INFO] 
2016-07-12 16:55:51 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:55:51 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:55:51 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:55:51 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:55:51 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:55:51 LocalJobRunner [INFO] 
2016-07-12 16:55:51 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:55:51 LocalJobRunner [WARN] job_local662508340_0004
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:55:52 Job [INFO] Job job_local662508340_0004 running in uber mode : false
2016-07-12 16:55:52 Job [INFO]  map 0% reduce 0%
2016-07-12 16:55:52 Job [INFO] Job job_local662508340_0004 failed with state FAILED due to: NA
2016-07-12 16:55:52 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:58:14 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 16:58:14 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 16:58:14 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 16:58:15 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:58:15 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 16:58:15 JobSubmitter [INFO] number of splits:1
2016-07-12 16:58:15 JobSubmitter [INFO] Submitting tokens for job: job_local135000881_0001
2016-07-12 16:58:15 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:58:15 Job [INFO] Running job: job_local135000881_0001
2016-07-12 16:58:15 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:58:15 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:58:15 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:58:15 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:58:15 LocalJobRunner [INFO] Starting task: attempt_local135000881_0001_m_000000_0
2016-07-12 16:58:15 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:58:15 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:58:15 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 16:58:15 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:58:15 LocalJobRunner [WARN] job_local135000881_0001
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyInputFormat.createRecordReader(AvroKeyInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.<init>(MapTask.java:515)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:758)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:58:16 Job [INFO] Job job_local135000881_0001 running in uber mode : false
2016-07-12 16:58:16 Job [INFO]  map 0% reduce 0%
2016-07-12 16:58:16 Job [INFO] Job job_local135000881_0001 failed with state FAILED due to: NA
2016-07-12 16:58:16 Job [INFO] Counters: 0
2016-07-12 16:58:16 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:58:16 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:58:16 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:58:16 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:58:16 JobSubmitter [INFO] number of splits:0
2016-07-12 16:58:16 JobSubmitter [INFO] Submitting tokens for job: job_local114077838_0002
2016-07-12 16:58:16 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:58:16 Job [INFO] Running job: job_local114077838_0002
2016-07-12 16:58:16 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:58:16 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:58:16 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:58:16 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:58:16 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:58:16 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:58:16 LocalJobRunner [INFO] Starting task: attempt_local114077838_0002_r_000000_0
2016-07-12 16:58:16 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:58:16 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:58:16 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6da5821a
2016-07-12 16:58:16 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:58:16 EventFetcher [INFO] attempt_local114077838_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:58:16 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:58:16 LocalJobRunner [INFO] 
2016-07-12 16:58:16 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:58:16 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:58:16 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:58:16 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:58:16 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:58:16 LocalJobRunner [INFO] 
2016-07-12 16:58:16 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:58:16 LocalJobRunner [WARN] job_local114077838_0002
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:58:17 Job [INFO] Job job_local114077838_0002 running in uber mode : false
2016-07-12 16:58:17 Job [INFO]  map 0% reduce 0%
2016-07-12 16:58:17 Job [INFO] Job job_local114077838_0002 failed with state FAILED due to: NA
2016-07-12 16:58:17 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:58:17 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:58:17 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:58:17 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:58:17 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:58:17 JobSubmitter [INFO] number of splits:0
2016-07-12 16:58:17 JobSubmitter [INFO] Submitting tokens for job: job_local1819167401_0003
2016-07-12 16:58:18 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:58:18 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:58:18 Job [INFO] Running job: job_local1819167401_0003
2016-07-12 16:58:18 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:58:18 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:58:18 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:58:18 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:58:18 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:58:18 LocalJobRunner [INFO] Starting task: attempt_local1819167401_0003_r_000000_0
2016-07-12 16:58:18 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:58:18 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:58:18 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@32a85832
2016-07-12 16:58:18 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:58:18 EventFetcher [INFO] attempt_local1819167401_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:58:18 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:58:18 LocalJobRunner [INFO] 
2016-07-12 16:58:18 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:58:18 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:58:18 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:58:18 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:58:18 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:58:18 LocalJobRunner [INFO] 
2016-07-12 16:58:18 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:58:18 LocalJobRunner [WARN] job_local1819167401_0003
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:58:19 Job [INFO] Job job_local1819167401_0003 running in uber mode : false
2016-07-12 16:58:19 Job [INFO]  map 0% reduce 0%
2016-07-12 16:58:19 Job [INFO] Job job_local1819167401_0003 failed with state FAILED due to: NA
2016-07-12 16:58:19 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 16:58:20 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 16:58:20 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 16:58:20 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 16:58:20 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 16:58:20 JobSubmitter [INFO] number of splits:0
2016-07-12 16:58:20 JobSubmitter [INFO] Submitting tokens for job: job_local936957035_0004
2016-07-12 16:58:20 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 16:58:20 Job [INFO] Running job: job_local936957035_0004
2016-07-12 16:58:20 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 16:58:20 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:58:20 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 16:58:20 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 16:58:20 LocalJobRunner [INFO] map task executor complete.
2016-07-12 16:58:20 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 16:58:20 LocalJobRunner [INFO] Starting task: attempt_local936957035_0004_r_000000_0
2016-07-12 16:58:20 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 16:58:20 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 16:58:20 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@c6a2c33
2016-07-12 16:58:20 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 16:58:20 EventFetcher [INFO] attempt_local936957035_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 16:58:20 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 16:58:20 LocalJobRunner [INFO] 
2016-07-12 16:58:20 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 16:58:20 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 16:58:20 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 16:58:20 Merger [INFO] Merging 0 sorted segments
2016-07-12 16:58:20 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 16:58:20 LocalJobRunner [INFO] 
2016-07-12 16:58:20 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 16:58:20 LocalJobRunner [WARN] job_local936957035_0004
java.lang.Exception: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
	at org.apache.avro.mapreduce.AvroKeyValueOutputFormat.getRecordWriter(AvroKeyValueOutputFormat.java:51)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:541)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 16:58:21 Job [INFO] Job job_local936957035_0004 running in uber mode : false
2016-07-12 16:58:21 Job [INFO]  map 0% reduce 0%
2016-07-12 16:58:21 Job [INFO] Job job_local936957035_0004 failed with state FAILED due to: NA
2016-07-12 16:58:21 Job [INFO] Counters: 17
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2016-07-12 17:06:10 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 17:06:10 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 17:06:10 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 17:06:10 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:06:10 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:06:10 JobSubmitter [INFO] number of splits:1
2016-07-12 17:06:10 JobSubmitter [INFO] Submitting tokens for job: job_local622409865_0001
2016-07-12 17:06:10 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:06:10 Job [INFO] Running job: job_local622409865_0001
2016-07-12 17:06:10 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:06:10 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:06:10 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:06:11 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:06:11 LocalJobRunner [INFO] Starting task: attempt_local622409865_0001_m_000000_0
2016-07-12 17:06:11 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:06:11 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:06:11 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 17:06:11 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:06:11 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:06:11 MapTask [INFO] soft limit at 83886080
2016-07-12 17:06:11 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:06:11 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:06:11 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:06:11 MapTask [INFO] Starting flush of map output
2016-07-12 17:06:11 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:06:11 LocalJobRunner [WARN] job_local622409865_0001
java.lang.Exception: java.lang.ClassCastException: term.avro.Term cannot be cast to eu.edisonproject.training.utility.term.avro.Term
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ClassCastException: term.avro.Term cannot be cast to eu.edisonproject.training.utility.term.avro.Term
	at eu.edisonproject.training.tfidf.mapreduce.WordFrequencyInDocDriver$WordFrequencyInDocMapper.map(WordFrequencyInDocDriver.java:75)
	at eu.edisonproject.training.tfidf.mapreduce.WordFrequencyInDocDriver$WordFrequencyInDocMapper.map(WordFrequencyInDocDriver.java:68)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 17:06:11 Job [INFO] Job job_local622409865_0001 running in uber mode : false
2016-07-12 17:06:11 Job [INFO]  map 0% reduce 0%
2016-07-12 17:06:11 Job [INFO] Job job_local622409865_0001 failed with state FAILED due to: NA
2016-07-12 17:06:11 Job [INFO] Counters: 0
2016-07-12 17:06:12 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:06:12 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:06:12 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:06:12 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 17:06:12 JobSubmitter [INFO] number of splits:0
2016-07-12 17:06:12 JobSubmitter [INFO] Submitting tokens for job: job_local1831694610_0002
2016-07-12 17:06:12 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:06:12 Job [INFO] Running job: job_local1831694610_0002
2016-07-12 17:06:12 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:06:12 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:06:12 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:06:12 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:06:12 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:06:12 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:06:12 LocalJobRunner [INFO] Starting task: attempt_local1831694610_0002_r_000000_0
2016-07-12 17:06:12 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:06:12 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:06:12 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27407307
2016-07-12 17:06:12 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:06:12 EventFetcher [INFO] attempt_local1831694610_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:06:12 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:06:12 LocalJobRunner [INFO] 
2016-07-12 17:06:12 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:06:12 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 17:06:12 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:06:12 Merger [INFO] Merging 0 sorted segments
2016-07-12 17:06:12 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 17:06:12 LocalJobRunner [INFO] 
2016-07-12 17:06:12 deprecation [INFO] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-07-12 17:06:12 Task [INFO] Task:attempt_local1831694610_0002_r_000000_0 is done. And is in the process of committing
2016-07-12 17:06:12 LocalJobRunner [INFO] 
2016-07-12 17:06:12 Task [INFO] Task attempt_local1831694610_0002_r_000000_0 is allowed to commit now
2016-07-12 17:06:12 FileOutputCommitter [INFO] Saved output of task 'attempt_local1831694610_0002_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/2-word-counts/_temporary/0/task_local1831694610_0002_r_000000
2016-07-12 17:06:12 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:06:12 Task [INFO] Task 'attempt_local1831694610_0002_r_000000_0' done.
2016-07-12 17:06:12 LocalJobRunner [INFO] Finishing task: attempt_local1831694610_0002_r_000000_0
2016-07-12 17:06:12 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:06:13 Job [INFO] Job job_local1831694610_0002 running in uber mode : false
2016-07-12 17:06:13 Job [INFO]  map 0% reduce 100%
2016-07-12 17:06:13 Job [INFO] Job job_local1831694610_0002 completed successfully
2016-07-12 17:06:13 Job [INFO] Counters: 24
	File System Counters
		FILE: Number of bytes read=7040
		FILE: Number of bytes written=568434
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=428343296
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=277
2016-07-12 17:06:13 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:06:13 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:06:13 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:06:13 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:06:14 JobSubmitter [INFO] number of splits:1
2016-07-12 17:06:14 JobSubmitter [INFO] Submitting tokens for job: job_local664813448_0003
2016-07-12 17:06:14 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:06:14 Job [INFO] Running job: job_local664813448_0003
2016-07-12 17:06:14 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:06:14 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:06:14 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:06:14 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:06:14 LocalJobRunner [INFO] Starting task: attempt_local664813448_0003_m_000000_0
2016-07-12 17:06:14 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:06:14 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:06:14 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/2-word-counts/part-r-00000.avro:0+265
2016-07-12 17:06:14 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:06:14 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:06:14 MapTask [INFO] soft limit at 83886080
2016-07-12 17:06:14 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:06:14 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:06:14 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:06:14 LocalJobRunner [INFO] 
2016-07-12 17:06:14 MapTask [INFO] Starting flush of map output
2016-07-12 17:06:14 Task [INFO] Task:attempt_local664813448_0003_m_000000_0 is done. And is in the process of committing
2016-07-12 17:06:14 LocalJobRunner [INFO] map
2016-07-12 17:06:14 Task [INFO] Task 'attempt_local664813448_0003_m_000000_0' done.
2016-07-12 17:06:14 LocalJobRunner [INFO] Finishing task: attempt_local664813448_0003_m_000000_0
2016-07-12 17:06:14 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:06:14 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:06:14 LocalJobRunner [INFO] Starting task: attempt_local664813448_0003_r_000000_0
2016-07-12 17:06:14 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:06:14 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:06:14 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@38814eab
2016-07-12 17:06:14 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:06:14 EventFetcher [INFO] attempt_local664813448_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:06:14 LocalFetcher [INFO] localfetcher#2 about to shuffle output of map attempt_local664813448_0003_m_000000_0 decomp: 2 len: 6 to MEMORY
2016-07-12 17:06:14 InMemoryMapOutput [INFO] Read 2 bytes from map-output for attempt_local664813448_0003_m_000000_0
2016-07-12 17:06:14 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2016-07-12 17:06:14 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:06:14 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:06:14 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:06:14 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:06:14 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 17:06:14 MergeManagerImpl [INFO] Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2016-07-12 17:06:14 MergeManagerImpl [INFO] Merging 1 files, 6 bytes from disk
2016-07-12 17:06:14 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:06:14 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:06:14 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 17:06:14 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:06:14 Task [INFO] Task:attempt_local664813448_0003_r_000000_0 is done. And is in the process of committing
2016-07-12 17:06:14 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:06:14 Task [INFO] Task attempt_local664813448_0003_r_000000_0 is allowed to commit now
2016-07-12 17:06:14 FileOutputCommitter [INFO] Saved output of task 'attempt_local664813448_0003_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/3-tf-idf/_temporary/0/task_local664813448_0003_r_000000
2016-07-12 17:06:14 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:06:14 Task [INFO] Task 'attempt_local664813448_0003_r_000000_0' done.
2016-07-12 17:06:14 LocalJobRunner [INFO] Finishing task: attempt_local664813448_0003_r_000000_0
2016-07-12 17:06:14 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:06:15 Job [INFO] Job job_local664813448_0003 running in uber mode : false
2016-07-12 17:06:15 Job [INFO]  map 100% reduce 100%
2016-07-12 17:06:15 Job [INFO] Job job_local664813448_0003 completed successfully
2016-07-12 17:06:15 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=15638
		FILE: Number of bytes written=1704772
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=143
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=872415232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=558
	File Output Format Counters 
		Bytes Written=440
2016-07-12 17:06:15 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:06:15 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:06:15 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:06:15 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:06:15 JobSubmitter [INFO] number of splits:1
2016-07-12 17:06:15 JobSubmitter [INFO] Submitting tokens for job: job_local1305836265_0004
2016-07-12 17:06:15 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:06:15 Job [INFO] Running job: job_local1305836265_0004
2016-07-12 17:06:15 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:06:15 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:06:15 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:06:15 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:06:15 LocalJobRunner [INFO] Starting task: attempt_local1305836265_0004_m_000000_0
2016-07-12 17:06:15 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:06:15 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:06:15 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/3-tf-idf/part-r-00000.avro:0+428
2016-07-12 17:06:15 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:06:15 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:06:15 MapTask [INFO] soft limit at 83886080
2016-07-12 17:06:15 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:06:15 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:06:15 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:06:15 LocalJobRunner [INFO] 
2016-07-12 17:06:15 MapTask [INFO] Starting flush of map output
2016-07-12 17:06:15 Task [INFO] Task:attempt_local1305836265_0004_m_000000_0 is done. And is in the process of committing
2016-07-12 17:06:15 LocalJobRunner [INFO] map
2016-07-12 17:06:15 Task [INFO] Task 'attempt_local1305836265_0004_m_000000_0' done.
2016-07-12 17:06:15 LocalJobRunner [INFO] Finishing task: attempt_local1305836265_0004_m_000000_0
2016-07-12 17:06:15 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:06:15 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:06:15 LocalJobRunner [INFO] Starting task: attempt_local1305836265_0004_r_000000_0
2016-07-12 17:06:15 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:06:15 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:06:15 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@12139101
2016-07-12 17:06:15 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:06:15 EventFetcher [INFO] attempt_local1305836265_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:06:15 LocalFetcher [INFO] localfetcher#3 about to shuffle output of map attempt_local1305836265_0004_m_000000_0 decomp: 2 len: 6 to MEMORY
2016-07-12 17:06:15 InMemoryMapOutput [INFO] Read 2 bytes from map-output for attempt_local1305836265_0004_m_000000_0
2016-07-12 17:06:15 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2016-07-12 17:06:15 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:06:15 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:06:15 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:06:15 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:06:15 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 17:06:15 MergeManagerImpl [INFO] Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2016-07-12 17:06:15 MergeManagerImpl [INFO] Merging 1 files, 6 bytes from disk
2016-07-12 17:06:15 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:06:15 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:06:15 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 17:06:15 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:06:15 Task [INFO] Task:attempt_local1305836265_0004_r_000000_0 is done. And is in the process of committing
2016-07-12 17:06:15 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:06:15 Task [INFO] Task attempt_local1305836265_0004_r_000000_0 is allowed to commit now
2016-07-12 17:06:15 FileOutputCommitter [INFO] Saved output of task 'attempt_local1305836265_0004_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/4-tf-idf-document/_temporary/0/task_local1305836265_0004_r_000000
2016-07-12 17:06:15 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:06:15 Task [INFO] Task 'attempt_local1305836265_0004_r_000000_0' done.
2016-07-12 17:06:15 LocalJobRunner [INFO] Finishing task: attempt_local1305836265_0004_r_000000_0
2016-07-12 17:06:15 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:06:16 Job [INFO] Job job_local1305836265_0004 running in uber mode : false
2016-07-12 17:06:16 Job [INFO]  map 100% reduce 100%
2016-07-12 17:06:16 Job [INFO] Job job_local1305836265_0004 completed successfully
2016-07-12 17:06:16 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=17882
		FILE: Number of bytes written=2277236
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=138
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=882900992
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=884
	File Output Format Counters 
		Bytes Written=508
2016-07-12 17:08:12 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 17:08:13 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 17:08:13 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 17:08:13 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:08:13 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:08:13 JobSubmitter [INFO] number of splits:1
2016-07-12 17:08:13 JobSubmitter [INFO] Submitting tokens for job: job_local594265810_0001
2016-07-12 17:08:13 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:08:13 Job [INFO] Running job: job_local594265810_0001
2016-07-12 17:08:13 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:08:13 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:08:13 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:08:13 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:08:13 LocalJobRunner [INFO] Starting task: attempt_local594265810_0001_m_000000_0
2016-07-12 17:08:13 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:08:13 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:08:13 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 17:08:13 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:08:13 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:08:13 MapTask [INFO] soft limit at 83886080
2016-07-12 17:08:13 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:08:13 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:08:13 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:08:14 Job [INFO] Job job_local594265810_0001 running in uber mode : false
2016-07-12 17:08:14 Job [INFO]  map 0% reduce 0%
2016-07-12 17:08:14 LocalJobRunner [INFO] 
2016-07-12 17:08:14 MapTask [INFO] Starting flush of map output
2016-07-12 17:08:14 MapTask [INFO] Spilling map output
2016-07-12 17:08:14 MapTask [INFO] bufstart = 0; bufend = 1545; bufvoid = 104857600
2016-07-12 17:08:14 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214068(104856272); length = 329/6553600
2016-07-12 17:08:14 MapTask [INFO] Finished spill 0
2016-07-12 17:08:14 Task [INFO] Task:attempt_local594265810_0001_m_000000_0 is done. And is in the process of committing
2016-07-12 17:08:14 LocalJobRunner [INFO] map
2016-07-12 17:08:14 Task [INFO] Task 'attempt_local594265810_0001_m_000000_0' done.
2016-07-12 17:08:14 LocalJobRunner [INFO] Finishing task: attempt_local594265810_0001_m_000000_0
2016-07-12 17:08:14 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:08:14 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:08:14 LocalJobRunner [INFO] Starting task: attempt_local594265810_0001_r_000000_0
2016-07-12 17:08:14 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:08:14 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:08:14 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@726e4ab2
2016-07-12 17:08:15 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:08:15 EventFetcher [INFO] attempt_local594265810_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:08:15 LocalFetcher [INFO] localfetcher#1 about to shuffle output of map attempt_local594265810_0001_m_000000_0 decomp: 1713 len: 1717 to MEMORY
2016-07-12 17:08:15 InMemoryMapOutput [INFO] Read 1713 bytes from map-output for attempt_local594265810_0001_m_000000_0
2016-07-12 17:08:15 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1713, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1713
2016-07-12 17:08:15 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:08:15 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:08:15 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:08:15 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:08:15 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:08:15 MergeManagerImpl [INFO] Merged 1 segments, 1713 bytes to disk to satisfy reduce memory limit
2016-07-12 17:08:15 MergeManagerImpl [INFO] Merging 1 files, 1717 bytes from disk
2016-07-12 17:08:15 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:08:15 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:08:15 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:08:15 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:08:15 deprecation [INFO] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-07-12 17:08:15 Task [INFO] Task:attempt_local594265810_0001_r_000000_0 is done. And is in the process of committing
2016-07-12 17:08:15 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:08:15 Task [INFO] Task attempt_local594265810_0001_r_000000_0 is allowed to commit now
2016-07-12 17:08:15 FileOutputCommitter [INFO] Saved output of task 'attempt_local594265810_0001_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/1-word-freq/_temporary/0/task_local594265810_0001_r_000000
2016-07-12 17:08:15 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:08:15 Task [INFO] Task 'attempt_local594265810_0001_r_000000_0' done.
2016-07-12 17:08:15 LocalJobRunner [INFO] Finishing task: attempt_local594265810_0001_r_000000_0
2016-07-12 17:08:15 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:08:15 Job [INFO]  map 100% reduce 100%
2016-07-12 17:08:15 Job [INFO] Job job_local594265810_0001 completed successfully
2016-07-12 17:08:15 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=17502
		FILE: Number of bytes written=573318
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=83
		Map output bytes=1545
		Map output materialized bytes=1717
		Input split bytes=144
		Combine input records=0
		Combine output records=0
		Reduce input groups=81
		Reduce shuffle bytes=1717
		Reduce input records=83
		Reduce output records=81
		Spilled Records=166
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=133
		Total committed heap usage (bytes)=850395136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6818
	File Output Format Counters 
		Bytes Written=1371
2016-07-12 17:08:15 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:08:15 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:08:15 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:08:15 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:08:15 JobSubmitter [INFO] number of splits:1
2016-07-12 17:08:15 JobSubmitter [INFO] Submitting tokens for job: job_local1366265257_0002
2016-07-12 17:08:15 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:08:15 Job [INFO] Running job: job_local1366265257_0002
2016-07-12 17:08:15 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:08:15 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:08:15 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:08:15 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:08:15 LocalJobRunner [INFO] Starting task: attempt_local1366265257_0002_m_000000_0
2016-07-12 17:08:15 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:08:15 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:08:15 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/1-word-freq/part-r-00000:0+1351
2016-07-12 17:08:16 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:08:16 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:08:16 MapTask [INFO] soft limit at 83886080
2016-07-12 17:08:16 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:08:16 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:08:16 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:08:16 MapTask [INFO] Starting flush of map output
2016-07-12 17:08:16 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:08:16 LocalJobRunner [WARN] job_local1366265257_0002
java.lang.Exception: java.io.IOException: Not a data file.
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Not a data file.
	at org.apache.avro.file.DataFileStream.initialize(DataFileStream.java:105)
	at org.apache.avro.file.DataFileReader.<init>(DataFileReader.java:97)
	at org.apache.avro.mapreduce.AvroRecordReaderBase.createAvroFileReader(AvroRecordReaderBase.java:183)
	at org.apache.avro.mapreduce.AvroRecordReaderBase.initialize(AvroRecordReaderBase.java:94)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 17:08:16 Job [INFO] Job job_local1366265257_0002 running in uber mode : false
2016-07-12 17:08:16 Job [INFO]  map 0% reduce 0%
2016-07-12 17:08:16 Job [INFO] Job job_local1366265257_0002 failed with state FAILED due to: NA
2016-07-12 17:08:16 Job [INFO] Counters: 0
2016-07-12 17:08:17 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:08:17 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:08:17 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:08:17 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 17:08:17 JobSubmitter [INFO] number of splits:0
2016-07-12 17:08:17 JobSubmitter [INFO] Submitting tokens for job: job_local223200383_0003
2016-07-12 17:08:17 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:08:17 Job [INFO] Running job: job_local223200383_0003
2016-07-12 17:08:17 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:08:17 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:08:17 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:08:17 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:08:17 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:08:17 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:08:17 LocalJobRunner [INFO] Starting task: attempt_local223200383_0003_r_000000_0
2016-07-12 17:08:17 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:08:17 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:08:17 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@742066bc
2016-07-12 17:08:17 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:08:17 EventFetcher [INFO] attempt_local223200383_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:08:17 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:08:17 LocalJobRunner [INFO] 
2016-07-12 17:08:17 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:08:18 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 17:08:18 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:08:18 Merger [INFO] Merging 0 sorted segments
2016-07-12 17:08:18 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 17:08:18 LocalJobRunner [INFO] 
2016-07-12 17:08:18 Task [INFO] Task:attempt_local223200383_0003_r_000000_0 is done. And is in the process of committing
2016-07-12 17:08:18 LocalJobRunner [INFO] 
2016-07-12 17:08:18 Task [INFO] Task attempt_local223200383_0003_r_000000_0 is allowed to commit now
2016-07-12 17:08:18 FileOutputCommitter [INFO] Saved output of task 'attempt_local223200383_0003_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/3-tf-idf/_temporary/0/task_local223200383_0003_r_000000
2016-07-12 17:08:18 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:08:18 Task [INFO] Task 'attempt_local223200383_0003_r_000000_0' done.
2016-07-12 17:08:18 LocalJobRunner [INFO] Finishing task: attempt_local223200383_0003_r_000000_0
2016-07-12 17:08:18 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:08:18 Job [INFO] Job job_local223200383_0003 running in uber mode : false
2016-07-12 17:08:18 Job [INFO]  map 0% reduce 100%
2016-07-12 17:08:18 Job [INFO] Job job_local223200383_0003 completed successfully
2016-07-12 17:08:18 Job [INFO] Counters: 24
	File System Counters
		FILE: Number of bytes read=12069
		FILE: Number of bytes written=857118
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=834
		Total committed heap usage (bytes)=433061888
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=440
2016-07-12 17:08:18 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:08:18 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:08:18 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:08:18 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:08:18 JobSubmitter [INFO] number of splits:1
2016-07-12 17:08:18 JobSubmitter [INFO] Submitting tokens for job: job_local467218456_0004
2016-07-12 17:08:18 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:08:18 Job [INFO] Running job: job_local467218456_0004
2016-07-12 17:08:18 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:08:18 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:08:18 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:08:18 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:08:18 LocalJobRunner [INFO] Starting task: attempt_local467218456_0004_m_000000_0
2016-07-12 17:08:18 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:08:18 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:08:18 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/3-tf-idf/part-r-00000.avro:0+428
2016-07-12 17:08:18 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:08:18 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:08:18 MapTask [INFO] soft limit at 83886080
2016-07-12 17:08:18 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:08:18 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:08:18 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:08:18 LocalJobRunner [INFO] 
2016-07-12 17:08:18 MapTask [INFO] Starting flush of map output
2016-07-12 17:08:18 Task [INFO] Task:attempt_local467218456_0004_m_000000_0 is done. And is in the process of committing
2016-07-12 17:08:18 LocalJobRunner [INFO] map
2016-07-12 17:08:18 Task [INFO] Task 'attempt_local467218456_0004_m_000000_0' done.
2016-07-12 17:08:18 LocalJobRunner [INFO] Finishing task: attempt_local467218456_0004_m_000000_0
2016-07-12 17:08:18 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:08:18 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:08:18 LocalJobRunner [INFO] Starting task: attempt_local467218456_0004_r_000000_0
2016-07-12 17:08:18 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:08:18 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:08:18 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2d8070ec
2016-07-12 17:08:18 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:08:18 EventFetcher [INFO] attempt_local467218456_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:08:18 LocalFetcher [INFO] localfetcher#3 about to shuffle output of map attempt_local467218456_0004_m_000000_0 decomp: 2 len: 6 to MEMORY
2016-07-12 17:08:18 InMemoryMapOutput [INFO] Read 2 bytes from map-output for attempt_local467218456_0004_m_000000_0
2016-07-12 17:08:18 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2016-07-12 17:08:18 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:08:18 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:08:18 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:08:18 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:08:18 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 17:08:18 MergeManagerImpl [INFO] Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2016-07-12 17:08:18 MergeManagerImpl [INFO] Merging 1 files, 6 bytes from disk
2016-07-12 17:08:18 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:08:18 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:08:18 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 17:08:18 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:08:18 Task [INFO] Task:attempt_local467218456_0004_r_000000_0 is done. And is in the process of committing
2016-07-12 17:08:18 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:08:18 Task [INFO] Task attempt_local467218456_0004_r_000000_0 is allowed to commit now
2016-07-12 17:08:18 FileOutputCommitter [INFO] Saved output of task 'attempt_local467218456_0004_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/4-tf-idf-document/_temporary/0/task_local467218456_0004_r_000000
2016-07-12 17:08:18 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:08:18 Task [INFO] Task 'attempt_local467218456_0004_r_000000_0' done.
2016-07-12 17:08:18 LocalJobRunner [INFO] Finishing task: attempt_local467218456_0004_r_000000_0
2016-07-12 17:08:18 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:08:19 Job [INFO] Job job_local467218456_0004 running in uber mode : false
2016-07-12 17:08:19 Job [INFO]  map 100% reduce 100%
2016-07-12 17:08:19 Job [INFO] Job job_local467218456_0004 completed successfully
2016-07-12 17:08:19 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=26338
		FILE: Number of bytes written=2283230
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=138
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=871890944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=884
	File Output Format Counters 
		Bytes Written=508
2016-07-12 17:17:15 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 17:17:15 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 17:17:15 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 17:17:16 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:17:16 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:17:16 JobSubmitter [INFO] number of splits:1
2016-07-12 17:17:16 JobSubmitter [INFO] Submitting tokens for job: job_local256364406_0001
2016-07-12 17:17:16 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:17:16 Job [INFO] Running job: job_local256364406_0001
2016-07-12 17:17:16 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:17:16 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:17:16 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:17:16 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:17:16 LocalJobRunner [INFO] Starting task: attempt_local256364406_0001_m_000000_0
2016-07-12 17:17:16 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:17:16 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:17:16 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 17:17:16 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:17:16 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:17:16 MapTask [INFO] soft limit at 83886080
2016-07-12 17:17:16 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:17:16 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:17:16 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:17:17 Job [INFO] Job job_local256364406_0001 running in uber mode : false
2016-07-12 17:17:17 Job [INFO]  map 0% reduce 0%
2016-07-12 17:17:17 LocalJobRunner [INFO] 
2016-07-12 17:17:17 MapTask [INFO] Starting flush of map output
2016-07-12 17:17:17 MapTask [INFO] Spilling map output
2016-07-12 17:17:17 MapTask [INFO] bufstart = 0; bufend = 1545; bufvoid = 104857600
2016-07-12 17:17:17 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214068(104856272); length = 329/6553600
2016-07-12 17:17:17 MapTask [INFO] Finished spill 0
2016-07-12 17:17:17 Task [INFO] Task:attempt_local256364406_0001_m_000000_0 is done. And is in the process of committing
2016-07-12 17:17:17 LocalJobRunner [INFO] map
2016-07-12 17:17:17 Task [INFO] Task 'attempt_local256364406_0001_m_000000_0' done.
2016-07-12 17:17:17 LocalJobRunner [INFO] Finishing task: attempt_local256364406_0001_m_000000_0
2016-07-12 17:17:17 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:17:17 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:17:17 LocalJobRunner [INFO] Starting task: attempt_local256364406_0001_r_000000_0
2016-07-12 17:17:17 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:17:17 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:17:17 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@20603fb4
2016-07-12 17:17:17 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:17:17 EventFetcher [INFO] attempt_local256364406_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:17:17 LocalFetcher [INFO] localfetcher#1 about to shuffle output of map attempt_local256364406_0001_m_000000_0 decomp: 1713 len: 1717 to MEMORY
2016-07-12 17:17:17 InMemoryMapOutput [INFO] Read 1713 bytes from map-output for attempt_local256364406_0001_m_000000_0
2016-07-12 17:17:17 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1713, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1713
2016-07-12 17:17:17 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:17:17 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:17:17 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:17:17 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:17:17 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:17:17 MergeManagerImpl [INFO] Merged 1 segments, 1713 bytes to disk to satisfy reduce memory limit
2016-07-12 17:17:17 MergeManagerImpl [INFO] Merging 1 files, 1717 bytes from disk
2016-07-12 17:17:17 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:17:17 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:17:17 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:17:17 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:17:17 deprecation [INFO] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-07-12 17:17:17 Task [INFO] Task:attempt_local256364406_0001_r_000000_0 is done. And is in the process of committing
2016-07-12 17:17:17 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:17:17 Task [INFO] Task attempt_local256364406_0001_r_000000_0 is allowed to commit now
2016-07-12 17:17:17 FileOutputCommitter [INFO] Saved output of task 'attempt_local256364406_0001_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/1-word-freq/_temporary/0/task_local256364406_0001_r_000000
2016-07-12 17:17:17 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:17:17 Task [INFO] Task 'attempt_local256364406_0001_r_000000_0' done.
2016-07-12 17:17:17 LocalJobRunner [INFO] Finishing task: attempt_local256364406_0001_r_000000_0
2016-07-12 17:17:17 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:17:18 Job [INFO]  map 100% reduce 100%
2016-07-12 17:17:18 Job [INFO] Job job_local256364406_0001 completed successfully
2016-07-12 17:17:18 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=17502
		FILE: Number of bytes written=573318
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=83
		Map output bytes=1545
		Map output materialized bytes=1717
		Input split bytes=144
		Combine input records=0
		Combine output records=0
		Reduce input groups=81
		Reduce shuffle bytes=1717
		Reduce input records=83
		Reduce output records=81
		Spilled Records=166
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=147
		Total committed heap usage (bytes)=693108736
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6818
	File Output Format Counters 
		Bytes Written=1371
2016-07-12 17:17:18 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:17:18 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:17:18 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:17:18 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:17:18 JobSubmitter [INFO] number of splits:1
2016-07-12 17:17:18 JobSubmitter [INFO] Submitting tokens for job: job_local791125553_0002
2016-07-12 17:17:18 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:17:18 Job [INFO] Running job: job_local791125553_0002
2016-07-12 17:17:18 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:17:18 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:17:18 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:17:18 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:17:18 LocalJobRunner [INFO] Starting task: attempt_local791125553_0002_m_000000_0
2016-07-12 17:17:18 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:17:18 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:17:18 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/1-word-freq/part-r-00000:0+1351
2016-07-12 17:17:18 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:17:18 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:17:18 MapTask [INFO] soft limit at 83886080
2016-07-12 17:17:18 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:17:18 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:17:18 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:17:18 MapTask [INFO] Starting flush of map output
2016-07-12 17:17:18 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:17:18 LocalJobRunner [WARN] job_local791125553_0002
java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at eu.edisonproject.training.tfidf.mapreduce.WordCountsForDocsDriver$WordCountsForDocsMapper.map(WordCountsForDocsDriver.java:59)
	at eu.edisonproject.training.tfidf.mapreduce.WordCountsForDocsDriver$WordCountsForDocsMapper.map(WordCountsForDocsDriver.java:50)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 17:17:19 Job [INFO] Job job_local791125553_0002 running in uber mode : false
2016-07-12 17:17:19 Job [INFO]  map 0% reduce 0%
2016-07-12 17:17:19 Job [INFO] Job job_local791125553_0002 failed with state FAILED due to: NA
2016-07-12 17:17:19 Job [INFO] Counters: 0
2016-07-12 17:17:19 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:17:19 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:17:19 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:17:19 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 17:17:19 JobSubmitter [INFO] number of splits:0
2016-07-12 17:17:19 JobSubmitter [INFO] Submitting tokens for job: job_local1988253524_0003
2016-07-12 17:17:20 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:17:20 Job [INFO] Running job: job_local1988253524_0003
2016-07-12 17:17:20 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:17:20 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:17:20 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:17:20 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:17:20 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:17:20 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:17:20 LocalJobRunner [INFO] Starting task: attempt_local1988253524_0003_r_000000_0
2016-07-12 17:17:20 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:17:20 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:17:20 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@239bc32f
2016-07-12 17:17:20 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:17:20 EventFetcher [INFO] attempt_local1988253524_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:17:20 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:17:20 LocalJobRunner [INFO] 
2016-07-12 17:17:20 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:17:20 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 17:17:20 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:17:20 Merger [INFO] Merging 0 sorted segments
2016-07-12 17:17:20 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 17:17:20 LocalJobRunner [INFO] 
2016-07-12 17:17:20 Task [INFO] Task:attempt_local1988253524_0003_r_000000_0 is done. And is in the process of committing
2016-07-12 17:17:20 LocalJobRunner [INFO] 
2016-07-12 17:17:20 Task [INFO] Task attempt_local1988253524_0003_r_000000_0 is allowed to commit now
2016-07-12 17:17:20 FileOutputCommitter [INFO] Saved output of task 'attempt_local1988253524_0003_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/3-tf-idf/_temporary/0/task_local1988253524_0003_r_000000
2016-07-12 17:17:20 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:17:20 Task [INFO] Task 'attempt_local1988253524_0003_r_000000_0' done.
2016-07-12 17:17:20 LocalJobRunner [INFO] Finishing task: attempt_local1988253524_0003_r_000000_0
2016-07-12 17:17:20 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:17:21 Job [INFO] Job job_local1988253524_0003 running in uber mode : false
2016-07-12 17:17:21 Job [INFO]  map 0% reduce 100%
2016-07-12 17:17:21 Job [INFO] Job job_local1988253524_0003 completed successfully
2016-07-12 17:17:21 Job [INFO] Counters: 24
	File System Counters
		FILE: Number of bytes read=12069
		FILE: Number of bytes written=850222
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=85
		Total committed heap usage (bytes)=394788864
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=8
2016-07-12 17:17:21 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:17:21 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:17:21 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:17:21 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:17:21 JobSubmitter [INFO] number of splits:1
2016-07-12 17:17:21 JobSubmitter [INFO] Submitting tokens for job: job_local2051214917_0004
2016-07-12 17:17:21 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:17:21 Job [INFO] Running job: job_local2051214917_0004
2016-07-12 17:17:21 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:17:21 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:17:21 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:17:21 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:17:21 LocalJobRunner [INFO] Starting task: attempt_local2051214917_0004_m_000000_0
2016-07-12 17:17:21 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:17:21 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:17:21 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/3-tf-idf/part-r-00000:0+0
2016-07-12 17:17:21 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:17:21 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:17:21 MapTask [INFO] soft limit at 83886080
2016-07-12 17:17:21 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:17:21 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:17:21 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:17:21 MapTask [INFO] Starting flush of map output
2016-07-12 17:17:21 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:17:21 LocalJobRunner [WARN] job_local2051214917_0004
java.lang.Exception: java.io.IOException: Not a data file.
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Not a data file.
	at org.apache.avro.file.DataFileStream.initialize(DataFileStream.java:102)
	at org.apache.avro.file.DataFileReader.<init>(DataFileReader.java:97)
	at org.apache.avro.mapreduce.AvroRecordReaderBase.createAvroFileReader(AvroRecordReaderBase.java:183)
	at org.apache.avro.mapreduce.AvroRecordReaderBase.initialize(AvroRecordReaderBase.java:94)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 17:17:22 Job [INFO] Job job_local2051214917_0004 running in uber mode : false
2016-07-12 17:17:22 Job [INFO]  map 0% reduce 0%
2016-07-12 17:17:22 Job [INFO] Job job_local2051214917_0004 failed with state FAILED due to: NA
2016-07-12 17:17:22 Job [INFO] Counters: 0
2016-07-12 17:19:41 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 17:19:41 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 17:19:41 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 17:19:42 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:19:42 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:19:42 JobSubmitter [INFO] number of splits:1
2016-07-12 17:19:42 JobSubmitter [INFO] Submitting tokens for job: job_local478630197_0001
2016-07-12 17:19:42 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:19:42 Job [INFO] Running job: job_local478630197_0001
2016-07-12 17:19:42 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:19:42 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:19:42 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:19:42 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:19:42 LocalJobRunner [INFO] Starting task: attempt_local478630197_0001_m_000000_0
2016-07-12 17:19:42 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:19:42 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:19:42 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 17:19:42 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:19:42 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:19:42 MapTask [INFO] soft limit at 83886080
2016-07-12 17:19:42 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:19:42 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:19:42 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:19:43 Job [INFO] Job job_local478630197_0001 running in uber mode : false
2016-07-12 17:19:43 Job [INFO]  map 0% reduce 0%
2016-07-12 17:19:43 LocalJobRunner [INFO] 
2016-07-12 17:19:43 MapTask [INFO] Starting flush of map output
2016-07-12 17:19:43 MapTask [INFO] Spilling map output
2016-07-12 17:19:43 MapTask [INFO] bufstart = 0; bufend = 1545; bufvoid = 104857600
2016-07-12 17:19:43 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214068(104856272); length = 329/6553600
2016-07-12 17:19:43 MapTask [INFO] Finished spill 0
2016-07-12 17:19:43 Task [INFO] Task:attempt_local478630197_0001_m_000000_0 is done. And is in the process of committing
2016-07-12 17:19:43 LocalJobRunner [INFO] map
2016-07-12 17:19:43 Task [INFO] Task 'attempt_local478630197_0001_m_000000_0' done.
2016-07-12 17:19:43 LocalJobRunner [INFO] Finishing task: attempt_local478630197_0001_m_000000_0
2016-07-12 17:19:43 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:19:43 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:19:43 LocalJobRunner [INFO] Starting task: attempt_local478630197_0001_r_000000_0
2016-07-12 17:19:43 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:19:43 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:19:43 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@36731837
2016-07-12 17:19:43 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:19:43 EventFetcher [INFO] attempt_local478630197_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:19:43 LocalFetcher [INFO] localfetcher#1 about to shuffle output of map attempt_local478630197_0001_m_000000_0 decomp: 1713 len: 1717 to MEMORY
2016-07-12 17:19:43 InMemoryMapOutput [INFO] Read 1713 bytes from map-output for attempt_local478630197_0001_m_000000_0
2016-07-12 17:19:43 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1713, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1713
2016-07-12 17:19:43 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:19:43 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:19:43 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:19:43 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:19:43 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:19:43 MergeManagerImpl [INFO] Merged 1 segments, 1713 bytes to disk to satisfy reduce memory limit
2016-07-12 17:19:43 MergeManagerImpl [INFO] Merging 1 files, 1717 bytes from disk
2016-07-12 17:19:43 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:19:43 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:19:43 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:19:43 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:19:43 deprecation [INFO] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-07-12 17:19:43 Task [INFO] Task:attempt_local478630197_0001_r_000000_0 is done. And is in the process of committing
2016-07-12 17:19:43 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:19:43 Task [INFO] Task attempt_local478630197_0001_r_000000_0 is allowed to commit now
2016-07-12 17:19:43 FileOutputCommitter [INFO] Saved output of task 'attempt_local478630197_0001_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/1-word-freq/_temporary/0/task_local478630197_0001_r_000000
2016-07-12 17:19:43 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:19:43 Task [INFO] Task 'attempt_local478630197_0001_r_000000_0' done.
2016-07-12 17:19:43 LocalJobRunner [INFO] Finishing task: attempt_local478630197_0001_r_000000_0
2016-07-12 17:19:43 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:19:44 Job [INFO]  map 100% reduce 100%
2016-07-12 17:19:44 Job [INFO] Job job_local478630197_0001 completed successfully
2016-07-12 17:19:44 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=17502
		FILE: Number of bytes written=573318
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=83
		Map output bytes=1545
		Map output materialized bytes=1717
		Input split bytes=144
		Combine input records=0
		Combine output records=0
		Reduce input groups=81
		Reduce shuffle bytes=1717
		Reduce input records=83
		Reduce output records=81
		Spilled Records=166
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=129
		Total committed heap usage (bytes)=848297984
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6818
	File Output Format Counters 
		Bytes Written=1371
2016-07-12 17:19:44 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:19:44 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:19:44 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:19:44 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:19:44 JobSubmitter [INFO] number of splits:1
2016-07-12 17:19:44 JobSubmitter [INFO] Submitting tokens for job: job_local837402248_0002
2016-07-12 17:19:44 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:19:44 Job [INFO] Running job: job_local837402248_0002
2016-07-12 17:19:44 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:19:44 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:19:44 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:19:44 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:19:44 LocalJobRunner [INFO] Starting task: attempt_local837402248_0002_m_000000_0
2016-07-12 17:19:44 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:19:44 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:19:44 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/1-word-freq/part-r-00000:0+1351
2016-07-12 17:19:44 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:19:44 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:19:44 MapTask [INFO] soft limit at 83886080
2016-07-12 17:19:44 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:19:44 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:19:44 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:19:44 LocalJobRunner [INFO] 
2016-07-12 17:19:44 MapTask [INFO] Starting flush of map output
2016-07-12 17:19:44 MapTask [INFO] Spilling map output
2016-07-12 17:19:44 MapTask [INFO] bufstart = 0; bufend = 1351; bufvoid = 104857600
2016-07-12 17:19:44 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 17:19:44 MapTask [INFO] Finished spill 0
2016-07-12 17:19:44 Task [INFO] Task:attempt_local837402248_0002_m_000000_0 is done. And is in the process of committing
2016-07-12 17:19:44 LocalJobRunner [INFO] map
2016-07-12 17:19:44 Task [INFO] Task 'attempt_local837402248_0002_m_000000_0' done.
2016-07-12 17:19:44 LocalJobRunner [INFO] Finishing task: attempt_local837402248_0002_m_000000_0
2016-07-12 17:19:44 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:19:44 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:19:44 LocalJobRunner [INFO] Starting task: attempt_local837402248_0002_r_000000_0
2016-07-12 17:19:44 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:19:44 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:19:44 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@41f284d7
2016-07-12 17:19:44 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:19:44 EventFetcher [INFO] attempt_local837402248_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:19:44 LocalFetcher [INFO] localfetcher#2 about to shuffle output of map attempt_local837402248_0002_m_000000_0 decomp: 1515 len: 1519 to MEMORY
2016-07-12 17:19:44 InMemoryMapOutput [INFO] Read 1515 bytes from map-output for attempt_local837402248_0002_m_000000_0
2016-07-12 17:19:44 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1515, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1515
2016-07-12 17:19:44 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:19:44 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:19:44 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:19:44 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:19:44 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 17:19:44 MergeManagerImpl [INFO] Merged 1 segments, 1515 bytes to disk to satisfy reduce memory limit
2016-07-12 17:19:44 MergeManagerImpl [INFO] Merging 1 files, 1519 bytes from disk
2016-07-12 17:19:44 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:19:44 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:19:44 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 17:19:44 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:19:44 Task [INFO] Task:attempt_local837402248_0002_r_000000_0 is done. And is in the process of committing
2016-07-12 17:19:44 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:19:44 Task [INFO] Task attempt_local837402248_0002_r_000000_0 is allowed to commit now
2016-07-12 17:19:44 FileOutputCommitter [INFO] Saved output of task 'attempt_local837402248_0002_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/2-word-counts/_temporary/0/task_local837402248_0002_r_000000
2016-07-12 17:19:44 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:19:44 Task [INFO] Task 'attempt_local837402248_0002_r_000000_0' done.
2016-07-12 17:19:44 LocalJobRunner [INFO] Finishing task: attempt_local837402248_0002_r_000000_0
2016-07-12 17:19:44 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:19:45 Job [INFO] Job job_local837402248_0002 running in uber mode : false
2016-07-12 17:19:45 Job [INFO]  map 100% reduce 100%
2016-07-12 17:19:45 Job [INFO] Job job_local837402248_0002 completed successfully
2016-07-12 17:19:45 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=27172
		FILE: Number of bytes written=1143244
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1351
		Map output materialized bytes=1519
		Input split bytes=136
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=1519
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1065353216
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1375
	File Output Format Counters 
		Bytes Written=1533
2016-07-12 17:19:45 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:19:45 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:19:45 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:19:45 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:19:45 JobSubmitter [INFO] number of splits:1
2016-07-12 17:19:45 JobSubmitter [INFO] Submitting tokens for job: job_local794596764_0003
2016-07-12 17:19:46 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:19:46 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:19:46 Job [INFO] Running job: job_local794596764_0003
2016-07-12 17:19:46 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:19:46 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:19:46 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:19:46 LocalJobRunner [INFO] Starting task: attempt_local794596764_0003_m_000000_0
2016-07-12 17:19:46 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:19:46 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:19:46 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/2-word-counts/part-r-00000:0+1513
2016-07-12 17:19:46 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:19:46 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:19:46 MapTask [INFO] soft limit at 83886080
2016-07-12 17:19:46 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:19:46 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:19:46 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:19:46 LocalJobRunner [INFO] 
2016-07-12 17:19:46 MapTask [INFO] Starting flush of map output
2016-07-12 17:19:46 MapTask [INFO] Spilling map output
2016-07-12 17:19:46 MapTask [INFO] bufstart = 0; bufend = 1513; bufvoid = 104857600
2016-07-12 17:19:46 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 17:19:46 MapTask [INFO] Finished spill 0
2016-07-12 17:19:46 Task [INFO] Task:attempt_local794596764_0003_m_000000_0 is done. And is in the process of committing
2016-07-12 17:19:46 LocalJobRunner [INFO] map
2016-07-12 17:19:46 Task [INFO] Task 'attempt_local794596764_0003_m_000000_0' done.
2016-07-12 17:19:46 LocalJobRunner [INFO] Finishing task: attempt_local794596764_0003_m_000000_0
2016-07-12 17:19:46 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:19:46 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:19:46 LocalJobRunner [INFO] Starting task: attempt_local794596764_0003_r_000000_0
2016-07-12 17:19:46 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:19:46 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:19:46 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4e229729
2016-07-12 17:19:46 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:19:46 EventFetcher [INFO] attempt_local794596764_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:19:46 LocalFetcher [INFO] localfetcher#3 about to shuffle output of map attempt_local794596764_0003_m_000000_0 decomp: 1677 len: 1681 to MEMORY
2016-07-12 17:19:46 InMemoryMapOutput [INFO] Read 1677 bytes from map-output for attempt_local794596764_0003_m_000000_0
2016-07-12 17:19:46 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1677, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1677
2016-07-12 17:19:46 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:19:46 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:19:46 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:19:46 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:19:46 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 17:19:46 MergeManagerImpl [INFO] Merged 1 segments, 1677 bytes to disk to satisfy reduce memory limit
2016-07-12 17:19:46 MergeManagerImpl [INFO] Merging 1 files, 1681 bytes from disk
2016-07-12 17:19:46 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:19:46 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:19:46 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 17:19:46 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:19:46 Task [INFO] Task:attempt_local794596764_0003_r_000000_0 is done. And is in the process of committing
2016-07-12 17:19:46 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:19:46 Task [INFO] Task attempt_local794596764_0003_r_000000_0 is allowed to commit now
2016-07-12 17:19:46 FileOutputCommitter [INFO] Saved output of task 'attempt_local794596764_0003_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/3-tf-idf/_temporary/0/task_local794596764_0003_r_000000
2016-07-12 17:19:46 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:19:46 Task [INFO] Task 'attempt_local794596764_0003_r_000000_0' done.
2016-07-12 17:19:46 LocalJobRunner [INFO] Finishing task: attempt_local794596764_0003_r_000000_0
2016-07-12 17:19:46 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:19:47 Job [INFO] Job job_local794596764_0003 running in uber mode : false
2016-07-12 17:19:47 Job [INFO]  map 100% reduce 100%
2016-07-12 17:19:47 Job [INFO] Job job_local794596764_0003 completed successfully
2016-07-12 17:19:47 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=37098
		FILE: Number of bytes written=1717581
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1513
		Map output materialized bytes=1681
		Input split bytes=138
		Combine input records=0
		Combine output records=0
		Reduce input groups=59
		Reduce shuffle bytes=1681
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=870318080
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1537
	File Output Format Counters 
		Bytes Written=5586
2016-07-12 17:19:47 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:19:47 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:19:47 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:19:47 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:19:47 JobSubmitter [INFO] number of splits:1
2016-07-12 17:19:47 JobSubmitter [INFO] Submitting tokens for job: job_local1933827533_0004
2016-07-12 17:19:48 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:19:48 Job [INFO] Running job: job_local1933827533_0004
2016-07-12 17:19:48 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:19:48 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:19:48 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:19:48 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:19:48 LocalJobRunner [INFO] Starting task: attempt_local1933827533_0004_m_000000_0
2016-07-12 17:19:48 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:19:48 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:19:48 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/3-tf-idf/part-r-00000:0+5534
2016-07-12 17:19:48 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:19:48 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:19:48 MapTask [INFO] soft limit at 83886080
2016-07-12 17:19:48 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:19:48 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:19:48 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:19:48 MapTask [INFO] Starting flush of map output
2016-07-12 17:19:48 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:19:48 LocalJobRunner [WARN] job_local1933827533_0004
java.lang.Exception: java.io.IOException: Not a data file.
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Not a data file.
	at org.apache.avro.file.DataFileStream.initialize(DataFileStream.java:105)
	at org.apache.avro.file.DataFileReader.<init>(DataFileReader.java:97)
	at org.apache.avro.mapreduce.AvroRecordReaderBase.createAvroFileReader(AvroRecordReaderBase.java:183)
	at org.apache.avro.mapreduce.AvroRecordReaderBase.initialize(AvroRecordReaderBase.java:94)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 17:19:49 Job [INFO] Job job_local1933827533_0004 running in uber mode : false
2016-07-12 17:19:49 Job [INFO]  map 0% reduce 0%
2016-07-12 17:19:49 Job [INFO] Job job_local1933827533_0004 failed with state FAILED due to: NA
2016-07-12 17:19:49 Job [INFO] Counters: 0
2016-07-12 17:23:57 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 17:23:57 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 17:23:57 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 17:23:58 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:23:58 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:23:58 JobSubmitter [INFO] number of splits:1
2016-07-12 17:23:58 JobSubmitter [INFO] Submitting tokens for job: job_local510381893_0001
2016-07-12 17:23:58 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:23:58 Job [INFO] Running job: job_local510381893_0001
2016-07-12 17:23:58 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:23:58 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:23:58 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:23:58 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:23:58 LocalJobRunner [INFO] Starting task: attempt_local510381893_0001_m_000000_0
2016-07-12 17:23:58 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:23:58 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:23:58 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 17:23:58 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:23:58 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:23:58 MapTask [INFO] soft limit at 83886080
2016-07-12 17:23:58 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:23:58 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:23:58 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:23:58 MapTask [INFO] Starting flush of map output
2016-07-12 17:23:58 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:23:58 LocalJobRunner [WARN] job_local510381893_0001
java.lang.Exception: java.lang.ClassCastException: term.avro.Term cannot be cast to eu.edisonproject.training.utility.term.avro.Term
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ClassCastException: term.avro.Term cannot be cast to eu.edisonproject.training.utility.term.avro.Term
	at eu.edisonproject.training.tfidf.mapreduce.WordFrequencyInDocDriver$WordFrequencyInDocMapper.map(WordFrequencyInDocDriver.java:75)
	at eu.edisonproject.training.tfidf.mapreduce.WordFrequencyInDocDriver$WordFrequencyInDocMapper.map(WordFrequencyInDocDriver.java:68)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 17:23:59 Job [INFO] Job job_local510381893_0001 running in uber mode : false
2016-07-12 17:23:59 Job [INFO]  map 0% reduce 0%
2016-07-12 17:23:59 Job [INFO] Job job_local510381893_0001 failed with state FAILED due to: NA
2016-07-12 17:23:59 Job [INFO] Counters: 0
2016-07-12 17:23:59 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:23:59 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:23:59 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:23:59 FileInputFormat [INFO] Total input paths to process : 0
2016-07-12 17:23:59 JobSubmitter [INFO] number of splits:0
2016-07-12 17:23:59 JobSubmitter [INFO] Submitting tokens for job: job_local2128434207_0002
2016-07-12 17:23:59 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:23:59 Job [INFO] Running job: job_local2128434207_0002
2016-07-12 17:23:59 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:23:59 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:23:59 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:23:59 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:23:59 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:23:59 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:23:59 LocalJobRunner [INFO] Starting task: attempt_local2128434207_0002_r_000000_0
2016-07-12 17:23:59 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:23:59 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:23:59 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@24d326b4
2016-07-12 17:23:59 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:23:59 EventFetcher [INFO] attempt_local2128434207_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:23:59 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:23:59 LocalJobRunner [INFO] 
2016-07-12 17:23:59 MergeManagerImpl [INFO] finalMerge called with 0 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:23:59 MergeManagerImpl [INFO] Merging 0 files, 0 bytes from disk
2016-07-12 17:23:59 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:23:59 Merger [INFO] Merging 0 sorted segments
2016-07-12 17:23:59 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 17:23:59 LocalJobRunner [INFO] 
2016-07-12 17:23:59 deprecation [INFO] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-07-12 17:23:59 Task [INFO] Task:attempt_local2128434207_0002_r_000000_0 is done. And is in the process of committing
2016-07-12 17:23:59 LocalJobRunner [INFO] 
2016-07-12 17:23:59 Task [INFO] Task attempt_local2128434207_0002_r_000000_0 is allowed to commit now
2016-07-12 17:23:59 FileOutputCommitter [INFO] Saved output of task 'attempt_local2128434207_0002_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/2-word-counts/_temporary/0/task_local2128434207_0002_r_000000
2016-07-12 17:23:59 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:23:59 Task [INFO] Task 'attempt_local2128434207_0002_r_000000_0' done.
2016-07-12 17:23:59 LocalJobRunner [INFO] Finishing task: attempt_local2128434207_0002_r_000000_0
2016-07-12 17:23:59 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:24:00 Job [INFO] Job job_local2128434207_0002 running in uber mode : false
2016-07-12 17:24:00 Job [INFO]  map 0% reduce 100%
2016-07-12 17:24:00 Job [INFO] Job job_local2128434207_0002 completed successfully
2016-07-12 17:24:00 Job [INFO] Counters: 24
	File System Counters
		FILE: Number of bytes read=7040
		FILE: Number of bytes written=565091
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=390594560
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=8
2016-07-12 17:24:01 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:24:01 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:24:01 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:24:01 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:24:01 JobSubmitter [INFO] number of splits:1
2016-07-12 17:24:01 JobSubmitter [INFO] Submitting tokens for job: job_local564065445_0003
2016-07-12 17:24:01 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:24:01 Job [INFO] Running job: job_local564065445_0003
2016-07-12 17:24:01 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:24:01 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:24:01 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:24:01 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:24:01 LocalJobRunner [INFO] Starting task: attempt_local564065445_0003_m_000000_0
2016-07-12 17:24:01 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:24:01 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:24:01 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/2-word-counts/part-r-00000:0+0
2016-07-12 17:24:01 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:24:01 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:24:01 MapTask [INFO] soft limit at 83886080
2016-07-12 17:24:01 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:24:01 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:24:01 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:24:01 LocalJobRunner [INFO] 
2016-07-12 17:24:01 MapTask [INFO] Starting flush of map output
2016-07-12 17:24:01 Task [INFO] Task:attempt_local564065445_0003_m_000000_0 is done. And is in the process of committing
2016-07-12 17:24:01 LocalJobRunner [INFO] map
2016-07-12 17:24:01 Task [INFO] Task 'attempt_local564065445_0003_m_000000_0' done.
2016-07-12 17:24:01 LocalJobRunner [INFO] Finishing task: attempt_local564065445_0003_m_000000_0
2016-07-12 17:24:01 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:24:01 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:24:01 LocalJobRunner [INFO] Starting task: attempt_local564065445_0003_r_000000_0
2016-07-12 17:24:01 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:24:01 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:24:01 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@50c4fba8
2016-07-12 17:24:01 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:24:01 EventFetcher [INFO] attempt_local564065445_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:24:01 LocalFetcher [INFO] localfetcher#2 about to shuffle output of map attempt_local564065445_0003_m_000000_0 decomp: 2 len: 6 to MEMORY
2016-07-12 17:24:01 InMemoryMapOutput [INFO] Read 2 bytes from map-output for attempt_local564065445_0003_m_000000_0
2016-07-12 17:24:01 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2016-07-12 17:24:01 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:24:01 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:24:01 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:24:01 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:24:01 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 17:24:01 MergeManagerImpl [INFO] Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2016-07-12 17:24:01 MergeManagerImpl [INFO] Merging 1 files, 6 bytes from disk
2016-07-12 17:24:01 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:24:01 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:24:01 Merger [INFO] Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-07-12 17:24:01 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:24:01 Task [INFO] Task:attempt_local564065445_0003_r_000000_0 is done. And is in the process of committing
2016-07-12 17:24:01 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:24:01 Task [INFO] Task attempt_local564065445_0003_r_000000_0 is allowed to commit now
2016-07-12 17:24:01 FileOutputCommitter [INFO] Saved output of task 'attempt_local564065445_0003_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/3-tf-idf/_temporary/0/task_local564065445_0003_r_000000
2016-07-12 17:24:01 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:24:01 Task [INFO] Task 'attempt_local564065445_0003_r_000000_0' done.
2016-07-12 17:24:01 LocalJobRunner [INFO] Finishing task: attempt_local564065445_0003_r_000000_0
2016-07-12 17:24:01 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:24:02 Job [INFO] Job job_local564065445_0003 running in uber mode : false
2016-07-12 17:24:02 Job [INFO]  map 100% reduce 100%
2016-07-12 17:24:02 Job [INFO] Job job_local564065445_0003 completed successfully
2016-07-12 17:24:02 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=14504
		FILE: Number of bytes written=1690840
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=138
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=991952896
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=8
	File Output Format Counters 
		Bytes Written=8
2016-07-12 17:24:02 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:24:02 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:24:02 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:24:02 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:24:02 JobSubmitter [INFO] number of splits:1
2016-07-12 17:24:02 JobSubmitter [INFO] Submitting tokens for job: job_local1036343813_0004
2016-07-12 17:24:02 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:24:02 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:24:02 Job [INFO] Running job: job_local1036343813_0004
2016-07-12 17:24:02 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:24:02 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:24:02 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:24:02 LocalJobRunner [INFO] Starting task: attempt_local1036343813_0004_m_000000_0
2016-07-12 17:24:02 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:24:02 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:24:02 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/3-tf-idf/part-r-00000:0+0
2016-07-12 17:24:02 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:24:02 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:24:02 MapTask [INFO] soft limit at 83886080
2016-07-12 17:24:02 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:24:02 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:24:02 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:24:02 MapTask [INFO] Starting flush of map output
2016-07-12 17:24:02 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:24:02 LocalJobRunner [WARN] job_local1036343813_0004
java.lang.Exception: java.io.IOException: Not a data file.
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Not a data file.
	at org.apache.avro.file.DataFileStream.initialize(DataFileStream.java:102)
	at org.apache.avro.file.DataFileReader.<init>(DataFileReader.java:97)
	at org.apache.avro.mapreduce.AvroRecordReaderBase.createAvroFileReader(AvroRecordReaderBase.java:183)
	at org.apache.avro.mapreduce.AvroRecordReaderBase.initialize(AvroRecordReaderBase.java:94)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 17:24:03 Job [INFO] Job job_local1036343813_0004 running in uber mode : false
2016-07-12 17:24:03 Job [INFO]  map 0% reduce 0%
2016-07-12 17:24:03 Job [INFO] Job job_local1036343813_0004 failed with state FAILED due to: NA
2016-07-12 17:24:03 Job [INFO] Counters: 0
2016-07-12 17:24:42 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 17:24:42 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 17:24:42 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 17:24:42 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:24:42 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:24:42 JobSubmitter [INFO] number of splits:1
2016-07-12 17:24:42 JobSubmitter [INFO] Submitting tokens for job: job_local1130514487_0001
2016-07-12 17:24:43 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:24:43 Job [INFO] Running job: job_local1130514487_0001
2016-07-12 17:24:43 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:24:43 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:24:43 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:24:43 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:24:43 LocalJobRunner [INFO] Starting task: attempt_local1130514487_0001_m_000000_0
2016-07-12 17:24:43 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:24:43 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:24:43 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 17:24:43 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:24:43 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:24:43 MapTask [INFO] soft limit at 83886080
2016-07-12 17:24:43 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:24:43 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:24:43 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:24:44 Job [INFO] Job job_local1130514487_0001 running in uber mode : false
2016-07-12 17:24:44 Job [INFO]  map 0% reduce 0%
2016-07-12 17:24:44 LocalJobRunner [INFO] 
2016-07-12 17:24:44 MapTask [INFO] Starting flush of map output
2016-07-12 17:24:44 MapTask [INFO] Spilling map output
2016-07-12 17:24:44 MapTask [INFO] bufstart = 0; bufend = 1545; bufvoid = 104857600
2016-07-12 17:24:44 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214068(104856272); length = 329/6553600
2016-07-12 17:24:44 MapTask [INFO] Finished spill 0
2016-07-12 17:24:44 Task [INFO] Task:attempt_local1130514487_0001_m_000000_0 is done. And is in the process of committing
2016-07-12 17:24:44 LocalJobRunner [INFO] map
2016-07-12 17:24:44 Task [INFO] Task 'attempt_local1130514487_0001_m_000000_0' done.
2016-07-12 17:24:44 LocalJobRunner [INFO] Finishing task: attempt_local1130514487_0001_m_000000_0
2016-07-12 17:24:44 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:24:44 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:24:44 LocalJobRunner [INFO] Starting task: attempt_local1130514487_0001_r_000000_0
2016-07-12 17:24:44 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:24:44 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:24:44 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@f379bef
2016-07-12 17:24:44 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:24:44 EventFetcher [INFO] attempt_local1130514487_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:24:44 LocalFetcher [INFO] localfetcher#1 about to shuffle output of map attempt_local1130514487_0001_m_000000_0 decomp: 1713 len: 1717 to MEMORY
2016-07-12 17:24:44 InMemoryMapOutput [INFO] Read 1713 bytes from map-output for attempt_local1130514487_0001_m_000000_0
2016-07-12 17:24:44 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1713, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1713
2016-07-12 17:24:44 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:24:44 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:24:44 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:24:44 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:24:44 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:24:44 MergeManagerImpl [INFO] Merged 1 segments, 1713 bytes to disk to satisfy reduce memory limit
2016-07-12 17:24:44 MergeManagerImpl [INFO] Merging 1 files, 1717 bytes from disk
2016-07-12 17:24:44 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:24:44 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:24:44 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:24:44 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:24:44 deprecation [INFO] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-07-12 17:24:44 Task [INFO] Task:attempt_local1130514487_0001_r_000000_0 is done. And is in the process of committing
2016-07-12 17:24:44 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:24:44 Task [INFO] Task attempt_local1130514487_0001_r_000000_0 is allowed to commit now
2016-07-12 17:24:44 FileOutputCommitter [INFO] Saved output of task 'attempt_local1130514487_0001_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/1-word-freq/_temporary/0/task_local1130514487_0001_r_000000
2016-07-12 17:24:44 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:24:44 Task [INFO] Task 'attempt_local1130514487_0001_r_000000_0' done.
2016-07-12 17:24:44 LocalJobRunner [INFO] Finishing task: attempt_local1130514487_0001_r_000000_0
2016-07-12 17:24:44 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:24:45 Job [INFO]  map 100% reduce 100%
2016-07-12 17:24:45 Job [INFO] Job job_local1130514487_0001 completed successfully
2016-07-12 17:24:45 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=17502
		FILE: Number of bytes written=576330
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=83
		Map output bytes=1545
		Map output materialized bytes=1717
		Input split bytes=144
		Combine input records=0
		Combine output records=0
		Reduce input groups=81
		Reduce shuffle bytes=1717
		Reduce input records=83
		Reduce output records=81
		Spilled Records=166
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=147
		Total committed heap usage (bytes)=694157312
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6818
	File Output Format Counters 
		Bytes Written=1371
2016-07-12 17:24:45 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:24:45 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:24:45 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:24:45 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:24:45 JobSubmitter [INFO] number of splits:1
2016-07-12 17:24:45 JobSubmitter [INFO] Submitting tokens for job: job_local1529800455_0002
2016-07-12 17:24:45 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:24:45 Job [INFO] Running job: job_local1529800455_0002
2016-07-12 17:24:45 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:24:45 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:24:45 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:24:45 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:24:45 LocalJobRunner [INFO] Starting task: attempt_local1529800455_0002_m_000000_0
2016-07-12 17:24:45 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:24:45 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:24:45 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/1-word-freq/part-r-00000:0+1351
2016-07-12 17:24:45 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:24:45 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:24:45 MapTask [INFO] soft limit at 83886080
2016-07-12 17:24:45 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:24:45 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:24:45 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:24:45 LocalJobRunner [INFO] 
2016-07-12 17:24:45 MapTask [INFO] Starting flush of map output
2016-07-12 17:24:45 MapTask [INFO] Spilling map output
2016-07-12 17:24:45 MapTask [INFO] bufstart = 0; bufend = 1351; bufvoid = 104857600
2016-07-12 17:24:45 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 17:24:45 MapTask [INFO] Finished spill 0
2016-07-12 17:24:45 Task [INFO] Task:attempt_local1529800455_0002_m_000000_0 is done. And is in the process of committing
2016-07-12 17:24:45 LocalJobRunner [INFO] map
2016-07-12 17:24:45 Task [INFO] Task 'attempt_local1529800455_0002_m_000000_0' done.
2016-07-12 17:24:45 LocalJobRunner [INFO] Finishing task: attempt_local1529800455_0002_m_000000_0
2016-07-12 17:24:45 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:24:45 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:24:45 LocalJobRunner [INFO] Starting task: attempt_local1529800455_0002_r_000000_0
2016-07-12 17:24:45 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:24:45 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:24:45 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@56469054
2016-07-12 17:24:45 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:24:45 EventFetcher [INFO] attempt_local1529800455_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:24:45 LocalFetcher [INFO] localfetcher#2 about to shuffle output of map attempt_local1529800455_0002_m_000000_0 decomp: 1515 len: 1519 to MEMORY
2016-07-12 17:24:45 InMemoryMapOutput [INFO] Read 1515 bytes from map-output for attempt_local1529800455_0002_m_000000_0
2016-07-12 17:24:45 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1515, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1515
2016-07-12 17:24:45 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:24:45 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:24:45 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:24:45 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:24:45 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 17:24:45 MergeManagerImpl [INFO] Merged 1 segments, 1515 bytes to disk to satisfy reduce memory limit
2016-07-12 17:24:45 MergeManagerImpl [INFO] Merging 1 files, 1519 bytes from disk
2016-07-12 17:24:45 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:24:45 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:24:45 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 17:24:45 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:24:45 Task [INFO] Task:attempt_local1529800455_0002_r_000000_0 is done. And is in the process of committing
2016-07-12 17:24:45 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:24:45 Task [INFO] Task attempt_local1529800455_0002_r_000000_0 is allowed to commit now
2016-07-12 17:24:45 FileOutputCommitter [INFO] Saved output of task 'attempt_local1529800455_0002_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/2-word-counts/_temporary/0/task_local1529800455_0002_r_000000
2016-07-12 17:24:45 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:24:45 Task [INFO] Task 'attempt_local1529800455_0002_r_000000_0' done.
2016-07-12 17:24:45 LocalJobRunner [INFO] Finishing task: attempt_local1529800455_0002_r_000000_0
2016-07-12 17:24:45 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:24:46 Job [INFO] Job job_local1529800455_0002 running in uber mode : false
2016-07-12 17:24:46 Job [INFO]  map 100% reduce 100%
2016-07-12 17:24:46 Job [INFO] Job job_local1529800455_0002 completed successfully
2016-07-12 17:24:46 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=27172
		FILE: Number of bytes written=1149248
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1351
		Map output materialized bytes=1519
		Input split bytes=136
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=1519
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=778043392
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1375
	File Output Format Counters 
		Bytes Written=1533
2016-07-12 17:24:46 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:24:46 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:24:46 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:24:46 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:24:46 JobSubmitter [INFO] number of splits:1
2016-07-12 17:24:46 JobSubmitter [INFO] Submitting tokens for job: job_local1778261477_0003
2016-07-12 17:24:46 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:24:46 Job [INFO] Running job: job_local1778261477_0003
2016-07-12 17:24:46 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:24:46 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:24:46 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:24:46 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:24:46 LocalJobRunner [INFO] Starting task: attempt_local1778261477_0003_m_000000_0
2016-07-12 17:24:46 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:24:46 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:24:46 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/2-word-counts/part-r-00000:0+1513
2016-07-12 17:24:46 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:24:46 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:24:46 MapTask [INFO] soft limit at 83886080
2016-07-12 17:24:46 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:24:46 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:24:46 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:24:46 LocalJobRunner [INFO] 
2016-07-12 17:24:46 MapTask [INFO] Starting flush of map output
2016-07-12 17:24:46 MapTask [INFO] Spilling map output
2016-07-12 17:24:46 MapTask [INFO] bufstart = 0; bufend = 1513; bufvoid = 104857600
2016-07-12 17:24:46 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 17:24:46 MapTask [INFO] Finished spill 0
2016-07-12 17:24:46 Task [INFO] Task:attempt_local1778261477_0003_m_000000_0 is done. And is in the process of committing
2016-07-12 17:24:46 LocalJobRunner [INFO] map
2016-07-12 17:24:46 Task [INFO] Task 'attempt_local1778261477_0003_m_000000_0' done.
2016-07-12 17:24:46 LocalJobRunner [INFO] Finishing task: attempt_local1778261477_0003_m_000000_0
2016-07-12 17:24:46 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:24:46 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:24:46 LocalJobRunner [INFO] Starting task: attempt_local1778261477_0003_r_000000_0
2016-07-12 17:24:46 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:24:46 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:24:46 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@79173b18
2016-07-12 17:24:46 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:24:46 EventFetcher [INFO] attempt_local1778261477_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:24:46 LocalFetcher [INFO] localfetcher#3 about to shuffle output of map attempt_local1778261477_0003_m_000000_0 decomp: 1677 len: 1681 to MEMORY
2016-07-12 17:24:46 InMemoryMapOutput [INFO] Read 1677 bytes from map-output for attempt_local1778261477_0003_m_000000_0
2016-07-12 17:24:46 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1677, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1677
2016-07-12 17:24:46 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:24:46 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:24:46 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:24:46 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:24:46 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 17:24:46 MergeManagerImpl [INFO] Merged 1 segments, 1677 bytes to disk to satisfy reduce memory limit
2016-07-12 17:24:46 MergeManagerImpl [INFO] Merging 1 files, 1681 bytes from disk
2016-07-12 17:24:46 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:24:46 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:24:46 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 17:24:46 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:24:46 Task [INFO] Task:attempt_local1778261477_0003_r_000000_0 is done. And is in the process of committing
2016-07-12 17:24:46 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:24:46 Task [INFO] Task attempt_local1778261477_0003_r_000000_0 is allowed to commit now
2016-07-12 17:24:46 FileOutputCommitter [INFO] Saved output of task 'attempt_local1778261477_0003_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/3-tf-idf/_temporary/0/task_local1778261477_0003_r_000000
2016-07-12 17:24:46 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:24:46 Task [INFO] Task 'attempt_local1778261477_0003_r_000000_0' done.
2016-07-12 17:24:46 LocalJobRunner [INFO] Finishing task: attempt_local1778261477_0003_r_000000_0
2016-07-12 17:24:46 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:24:47 Job [INFO] Job job_local1778261477_0003 running in uber mode : false
2016-07-12 17:24:47 Job [INFO]  map 100% reduce 100%
2016-07-12 17:24:47 Job [INFO] Job job_local1778261477_0003 completed successfully
2016-07-12 17:24:47 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=37098
		FILE: Number of bytes written=1726577
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1513
		Map output materialized bytes=1681
		Input split bytes=138
		Combine input records=0
		Combine output records=0
		Reduce input groups=59
		Reduce shuffle bytes=1681
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=789577728
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1537
	File Output Format Counters 
		Bytes Written=5586
2016-07-12 17:24:47 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:24:47 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:24:47 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:24:47 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:24:47 JobSubmitter [INFO] number of splits:1
2016-07-12 17:24:47 JobSubmitter [INFO] Submitting tokens for job: job_local629241488_0004
2016-07-12 17:24:47 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:24:47 Job [INFO] Running job: job_local629241488_0004
2016-07-12 17:24:47 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:24:47 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:24:47 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:24:47 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:24:47 LocalJobRunner [INFO] Starting task: attempt_local629241488_0004_m_000000_0
2016-07-12 17:24:47 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:24:47 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:24:47 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/3-tf-idf/part-r-00000:0+5534
2016-07-12 17:24:48 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:24:48 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:24:48 MapTask [INFO] soft limit at 83886080
2016-07-12 17:24:48 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:24:48 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:24:48 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:24:48 MapTask [INFO] Starting flush of map output
2016-07-12 17:24:48 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:24:48 LocalJobRunner [WARN] job_local629241488_0004
java.lang.Exception: java.io.IOException: Not a data file.
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Not a data file.
	at org.apache.avro.file.DataFileStream.initialize(DataFileStream.java:105)
	at org.apache.avro.file.DataFileReader.<init>(DataFileReader.java:97)
	at org.apache.avro.mapreduce.AvroRecordReaderBase.createAvroFileReader(AvroRecordReaderBase.java:183)
	at org.apache.avro.mapreduce.AvroRecordReaderBase.initialize(AvroRecordReaderBase.java:94)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 17:24:48 Job [INFO] Job job_local629241488_0004 running in uber mode : false
2016-07-12 17:24:48 Job [INFO]  map 0% reduce 0%
2016-07-12 17:24:48 Job [INFO] Job job_local629241488_0004 failed with state FAILED due to: NA
2016-07-12 17:24:48 Job [INFO] Counters: 0
2016-07-12 17:29:02 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 17:29:02 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 17:29:02 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 17:29:02 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:29:02 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:29:02 JobSubmitter [INFO] number of splits:1
2016-07-12 17:29:02 JobSubmitter [INFO] Submitting tokens for job: job_local1404713393_0001
2016-07-12 17:29:02 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:29:02 Job [INFO] Running job: job_local1404713393_0001
2016-07-12 17:29:02 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:29:02 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:29:02 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:29:02 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:29:02 LocalJobRunner [INFO] Starting task: attempt_local1404713393_0001_m_000000_0
2016-07-12 17:29:03 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:29:03 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:29:03 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 17:29:03 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:29:03 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:29:03 MapTask [INFO] soft limit at 83886080
2016-07-12 17:29:03 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:29:03 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:29:03 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:29:03 Job [INFO] Job job_local1404713393_0001 running in uber mode : false
2016-07-12 17:29:03 Job [INFO]  map 0% reduce 0%
2016-07-12 17:29:04 LocalJobRunner [INFO] 
2016-07-12 17:29:04 MapTask [INFO] Starting flush of map output
2016-07-12 17:29:04 MapTask [INFO] Spilling map output
2016-07-12 17:29:04 MapTask [INFO] bufstart = 0; bufend = 1545; bufvoid = 104857600
2016-07-12 17:29:04 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214068(104856272); length = 329/6553600
2016-07-12 17:29:04 MapTask [INFO] Finished spill 0
2016-07-12 17:29:04 Task [INFO] Task:attempt_local1404713393_0001_m_000000_0 is done. And is in the process of committing
2016-07-12 17:29:04 LocalJobRunner [INFO] map
2016-07-12 17:29:04 Task [INFO] Task 'attempt_local1404713393_0001_m_000000_0' done.
2016-07-12 17:29:04 LocalJobRunner [INFO] Finishing task: attempt_local1404713393_0001_m_000000_0
2016-07-12 17:29:04 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:29:04 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:29:04 LocalJobRunner [INFO] Starting task: attempt_local1404713393_0001_r_000000_0
2016-07-12 17:29:04 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:29:04 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:29:04 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5714d016
2016-07-12 17:29:04 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:29:04 EventFetcher [INFO] attempt_local1404713393_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:29:04 LocalFetcher [INFO] localfetcher#1 about to shuffle output of map attempt_local1404713393_0001_m_000000_0 decomp: 1713 len: 1717 to MEMORY
2016-07-12 17:29:04 InMemoryMapOutput [INFO] Read 1713 bytes from map-output for attempt_local1404713393_0001_m_000000_0
2016-07-12 17:29:04 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1713, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1713
2016-07-12 17:29:04 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:29:04 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:29:04 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:29:04 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:29:04 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:29:04 MergeManagerImpl [INFO] Merged 1 segments, 1713 bytes to disk to satisfy reduce memory limit
2016-07-12 17:29:04 MergeManagerImpl [INFO] Merging 1 files, 1717 bytes from disk
2016-07-12 17:29:04 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:29:04 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:29:04 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:29:04 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:29:04 deprecation [INFO] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-07-12 17:29:04 Task [INFO] Task:attempt_local1404713393_0001_r_000000_0 is done. And is in the process of committing
2016-07-12 17:29:04 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:29:04 Task [INFO] Task attempt_local1404713393_0001_r_000000_0 is allowed to commit now
2016-07-12 17:29:04 FileOutputCommitter [INFO] Saved output of task 'attempt_local1404713393_0001_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/_temporary/0/task_local1404713393_0001_r_000000
2016-07-12 17:29:04 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:29:04 Task [INFO] Task 'attempt_local1404713393_0001_r_000000_0' done.
2016-07-12 17:29:04 LocalJobRunner [INFO] Finishing task: attempt_local1404713393_0001_r_000000_0
2016-07-12 17:29:04 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:29:04 Job [INFO]  map 100% reduce 100%
2016-07-12 17:29:04 Job [INFO] Job job_local1404713393_0001 completed successfully
2016-07-12 17:29:04 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=17502
		FILE: Number of bytes written=576366
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=83
		Map output bytes=1545
		Map output materialized bytes=1717
		Input split bytes=144
		Combine input records=0
		Combine output records=0
		Reduce input groups=81
		Reduce shuffle bytes=1717
		Reduce input records=83
		Reduce output records=81
		Spilled Records=166
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=845676544
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6818
	File Output Format Counters 
		Bytes Written=1371
2016-07-12 17:29:05 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:29:05 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:29:05 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:29:05 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:29:05 JobSubmitter [INFO] number of splits:1
2016-07-12 17:29:05 JobSubmitter [INFO] Submitting tokens for job: job_local1257926187_0002
2016-07-12 17:29:05 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:29:05 Job [INFO] Running job: job_local1257926187_0002
2016-07-12 17:29:05 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:29:05 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:29:05 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:29:05 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:29:05 LocalJobRunner [INFO] Starting task: attempt_local1257926187_0002_m_000000_0
2016-07-12 17:29:05 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:29:05 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:29:05 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/part-r-00000:0+1351
2016-07-12 17:29:05 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:29:05 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:29:05 MapTask [INFO] soft limit at 83886080
2016-07-12 17:29:05 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:29:05 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:29:05 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:29:05 LocalJobRunner [INFO] 
2016-07-12 17:29:05 MapTask [INFO] Starting flush of map output
2016-07-12 17:29:05 MapTask [INFO] Spilling map output
2016-07-12 17:29:05 MapTask [INFO] bufstart = 0; bufend = 1351; bufvoid = 104857600
2016-07-12 17:29:05 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 17:29:05 MapTask [INFO] Finished spill 0
2016-07-12 17:29:05 Task [INFO] Task:attempt_local1257926187_0002_m_000000_0 is done. And is in the process of committing
2016-07-12 17:29:05 LocalJobRunner [INFO] map
2016-07-12 17:29:05 Task [INFO] Task 'attempt_local1257926187_0002_m_000000_0' done.
2016-07-12 17:29:05 LocalJobRunner [INFO] Finishing task: attempt_local1257926187_0002_m_000000_0
2016-07-12 17:29:05 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:29:05 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:29:05 LocalJobRunner [INFO] Starting task: attempt_local1257926187_0002_r_000000_0
2016-07-12 17:29:05 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:29:05 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:29:05 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7ee595fb
2016-07-12 17:29:05 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:29:05 EventFetcher [INFO] attempt_local1257926187_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:29:05 LocalFetcher [INFO] localfetcher#2 about to shuffle output of map attempt_local1257926187_0002_m_000000_0 decomp: 1515 len: 1519 to MEMORY
2016-07-12 17:29:05 InMemoryMapOutput [INFO] Read 1515 bytes from map-output for attempt_local1257926187_0002_m_000000_0
2016-07-12 17:29:05 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1515, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1515
2016-07-12 17:29:05 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:29:05 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:29:05 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:29:05 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:29:05 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 17:29:05 MergeManagerImpl [INFO] Merged 1 segments, 1515 bytes to disk to satisfy reduce memory limit
2016-07-12 17:29:05 MergeManagerImpl [INFO] Merging 1 files, 1519 bytes from disk
2016-07-12 17:29:05 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:29:05 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:29:05 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 17:29:05 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:29:05 Task [INFO] Task:attempt_local1257926187_0002_r_000000_0 is done. And is in the process of committing
2016-07-12 17:29:05 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:29:05 Task [INFO] Task attempt_local1257926187_0002_r_000000_0 is allowed to commit now
2016-07-12 17:29:05 FileOutputCommitter [INFO] Saved output of task 'attempt_local1257926187_0002_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/_temporary/0/task_local1257926187_0002_r_000000
2016-07-12 17:29:05 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:29:05 Task [INFO] Task 'attempt_local1257926187_0002_r_000000_0' done.
2016-07-12 17:29:05 LocalJobRunner [INFO] Finishing task: attempt_local1257926187_0002_r_000000_0
2016-07-12 17:29:05 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:29:06 Job [INFO] Job job_local1257926187_0002 running in uber mode : false
2016-07-12 17:29:06 Job [INFO]  map 100% reduce 100%
2016-07-12 17:29:06 Job [INFO] Job job_local1257926187_0002 completed successfully
2016-07-12 17:29:06 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=27190
		FILE: Number of bytes written=1149374
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1351
		Map output materialized bytes=1519
		Input split bytes=145
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=1519
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1062207488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1375
	File Output Format Counters 
		Bytes Written=1533
2016-07-12 17:29:06 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:29:06 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:29:06 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:29:06 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:29:06 JobSubmitter [INFO] number of splits:1
2016-07-12 17:29:06 JobSubmitter [INFO] Submitting tokens for job: job_local1149614662_0003
2016-07-12 17:29:07 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:29:07 Job [INFO] Running job: job_local1149614662_0003
2016-07-12 17:29:07 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:29:07 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:29:07 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:29:07 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:29:07 LocalJobRunner [INFO] Starting task: attempt_local1149614662_0003_m_000000_0
2016-07-12 17:29:07 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:29:07 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:29:07 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/part-r-00000:0+1513
2016-07-12 17:29:07 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:29:07 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:29:07 MapTask [INFO] soft limit at 83886080
2016-07-12 17:29:07 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:29:07 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:29:07 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:29:07 LocalJobRunner [INFO] 
2016-07-12 17:29:07 MapTask [INFO] Starting flush of map output
2016-07-12 17:29:07 MapTask [INFO] Spilling map output
2016-07-12 17:29:07 MapTask [INFO] bufstart = 0; bufend = 1513; bufvoid = 104857600
2016-07-12 17:29:07 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 17:29:07 MapTask [INFO] Finished spill 0
2016-07-12 17:29:07 Task [INFO] Task:attempt_local1149614662_0003_m_000000_0 is done. And is in the process of committing
2016-07-12 17:29:07 LocalJobRunner [INFO] map
2016-07-12 17:29:07 Task [INFO] Task 'attempt_local1149614662_0003_m_000000_0' done.
2016-07-12 17:29:07 LocalJobRunner [INFO] Finishing task: attempt_local1149614662_0003_m_000000_0
2016-07-12 17:29:07 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:29:07 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:29:07 LocalJobRunner [INFO] Starting task: attempt_local1149614662_0003_r_000000_0
2016-07-12 17:29:07 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:29:07 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:29:07 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3917c4f2
2016-07-12 17:29:07 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:29:07 EventFetcher [INFO] attempt_local1149614662_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:29:07 LocalFetcher [INFO] localfetcher#3 about to shuffle output of map attempt_local1149614662_0003_m_000000_0 decomp: 1677 len: 1681 to MEMORY
2016-07-12 17:29:07 InMemoryMapOutput [INFO] Read 1677 bytes from map-output for attempt_local1149614662_0003_m_000000_0
2016-07-12 17:29:07 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1677, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1677
2016-07-12 17:29:07 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:29:07 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:29:07 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:29:07 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:29:07 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 17:29:07 MergeManagerImpl [INFO] Merged 1 segments, 1677 bytes to disk to satisfy reduce memory limit
2016-07-12 17:29:07 MergeManagerImpl [INFO] Merging 1 files, 1681 bytes from disk
2016-07-12 17:29:07 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:29:07 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:29:07 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 17:29:07 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:29:07 Task [INFO] Task:attempt_local1149614662_0003_r_000000_0 is done. And is in the process of committing
2016-07-12 17:29:07 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:29:07 Task [INFO] Task attempt_local1149614662_0003_r_000000_0 is allowed to commit now
2016-07-12 17:29:07 FileOutputCommitter [INFO] Saved output of task 'attempt_local1149614662_0003_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/_temporary/0/task_local1149614662_0003_r_000000
2016-07-12 17:29:07 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:29:07 Task [INFO] Task 'attempt_local1149614662_0003_r_000000_0' done.
2016-07-12 17:29:07 LocalJobRunner [INFO] Finishing task: attempt_local1149614662_0003_r_000000_0
2016-07-12 17:29:07 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:29:08 Job [INFO] Job job_local1149614662_0003 running in uber mode : false
2016-07-12 17:29:08 Job [INFO]  map 100% reduce 100%
2016-07-12 17:29:08 Job [INFO] Job job_local1149614662_0003 completed successfully
2016-07-12 17:29:08 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=37134
		FILE: Number of bytes written=1726793
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1513
		Map output materialized bytes=1681
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=59
		Reduce shuffle bytes=1681
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=865075200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1537
	File Output Format Counters 
		Bytes Written=5586
2016-07-12 17:29:08 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:29:08 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:29:08 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:29:08 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:29:08 JobSubmitter [INFO] number of splits:1
2016-07-12 17:29:08 JobSubmitter [INFO] Submitting tokens for job: job_local319056526_0004
2016-07-12 17:29:08 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:29:08 Job [INFO] Running job: job_local319056526_0004
2016-07-12 17:29:08 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:29:08 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:29:08 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:29:08 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:29:08 LocalJobRunner [INFO] Starting task: attempt_local319056526_0004_m_000000_0
2016-07-12 17:29:08 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:29:08 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:29:08 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/part-r-00000:0+5534
2016-07-12 17:29:08 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:29:08 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:29:08 MapTask [INFO] soft limit at 83886080
2016-07-12 17:29:08 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:29:08 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:29:08 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:29:08 MapTask [INFO] Starting flush of map output
2016-07-12 17:29:08 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:29:08 LocalJobRunner [WARN] job_local319056526_0004
java.lang.Exception: java.io.IOException: Not a data file.
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Not a data file.
	at org.apache.avro.file.DataFileStream.initialize(DataFileStream.java:105)
	at org.apache.avro.file.DataFileReader.<init>(DataFileReader.java:97)
	at org.apache.avro.mapreduce.AvroRecordReaderBase.createAvroFileReader(AvroRecordReaderBase.java:183)
	at org.apache.avro.mapreduce.AvroRecordReaderBase.initialize(AvroRecordReaderBase.java:94)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 17:29:09 Job [INFO] Job job_local319056526_0004 running in uber mode : false
2016-07-12 17:29:09 Job [INFO]  map 0% reduce 0%
2016-07-12 17:29:09 Job [INFO] Job job_local319056526_0004 failed with state FAILED due to: NA
2016-07-12 17:29:09 Job [INFO] Counters: 0
2016-07-12 17:33:58 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 17:33:59 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 17:33:59 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 17:33:59 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:33:59 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:33:59 JobSubmitter [INFO] number of splits:1
2016-07-12 17:33:59 JobSubmitter [INFO] Submitting tokens for job: job_local822018010_0001
2016-07-12 17:33:59 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:33:59 Job [INFO] Running job: job_local822018010_0001
2016-07-12 17:33:59 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:33:59 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:33:59 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:33:59 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:33:59 LocalJobRunner [INFO] Starting task: attempt_local822018010_0001_m_000000_0
2016-07-12 17:33:59 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:33:59 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:33:59 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 17:33:59 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:33:59 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:33:59 MapTask [INFO] soft limit at 83886080
2016-07-12 17:33:59 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:33:59 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:33:59 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:34:00 Job [INFO] Job job_local822018010_0001 running in uber mode : false
2016-07-12 17:34:00 Job [INFO]  map 0% reduce 0%
2016-07-12 17:34:00 LocalJobRunner [INFO] 
2016-07-12 17:34:00 MapTask [INFO] Starting flush of map output
2016-07-12 17:34:00 MapTask [INFO] Spilling map output
2016-07-12 17:34:00 MapTask [INFO] bufstart = 0; bufend = 1545; bufvoid = 104857600
2016-07-12 17:34:00 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214068(104856272); length = 329/6553600
2016-07-12 17:34:00 MapTask [INFO] Finished spill 0
2016-07-12 17:34:00 Task [INFO] Task:attempt_local822018010_0001_m_000000_0 is done. And is in the process of committing
2016-07-12 17:34:00 LocalJobRunner [INFO] map
2016-07-12 17:34:00 Task [INFO] Task 'attempt_local822018010_0001_m_000000_0' done.
2016-07-12 17:34:00 LocalJobRunner [INFO] Finishing task: attempt_local822018010_0001_m_000000_0
2016-07-12 17:34:00 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:34:00 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:34:01 LocalJobRunner [INFO] Starting task: attempt_local822018010_0001_r_000000_0
2016-07-12 17:34:01 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:34:01 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:34:01 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5e033565
2016-07-12 17:34:01 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:34:01 EventFetcher [INFO] attempt_local822018010_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:34:01 LocalFetcher [INFO] localfetcher#1 about to shuffle output of map attempt_local822018010_0001_m_000000_0 decomp: 1713 len: 1717 to MEMORY
2016-07-12 17:34:01 InMemoryMapOutput [INFO] Read 1713 bytes from map-output for attempt_local822018010_0001_m_000000_0
2016-07-12 17:34:01 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1713, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1713
2016-07-12 17:34:01 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:34:01 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:34:01 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:34:01 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:34:01 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:34:01 MergeManagerImpl [INFO] Merged 1 segments, 1713 bytes to disk to satisfy reduce memory limit
2016-07-12 17:34:01 MergeManagerImpl [INFO] Merging 1 files, 1717 bytes from disk
2016-07-12 17:34:01 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:34:01 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:34:01 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:34:01 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:34:01 deprecation [INFO] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-07-12 17:34:01 Task [INFO] Task:attempt_local822018010_0001_r_000000_0 is done. And is in the process of committing
2016-07-12 17:34:01 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:34:01 Task [INFO] Task attempt_local822018010_0001_r_000000_0 is allowed to commit now
2016-07-12 17:34:01 FileOutputCommitter [INFO] Saved output of task 'attempt_local822018010_0001_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/_temporary/0/task_local822018010_0001_r_000000
2016-07-12 17:34:01 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:34:01 Task [INFO] Task 'attempt_local822018010_0001_r_000000_0' done.
2016-07-12 17:34:01 LocalJobRunner [INFO] Finishing task: attempt_local822018010_0001_r_000000_0
2016-07-12 17:34:01 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:34:01 Job [INFO]  map 100% reduce 100%
2016-07-12 17:34:01 Job [INFO] Job job_local822018010_0001 completed successfully
2016-07-12 17:34:01 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=17502
		FILE: Number of bytes written=573354
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=83
		Map output bytes=1545
		Map output materialized bytes=1717
		Input split bytes=144
		Combine input records=0
		Combine output records=0
		Reduce input groups=81
		Reduce shuffle bytes=1717
		Reduce input records=83
		Reduce output records=81
		Spilled Records=166
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=845152256
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6818
	File Output Format Counters 
		Bytes Written=1371
2016-07-12 17:34:01 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:34:01 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:34:01 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:34:01 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:34:01 JobSubmitter [INFO] number of splits:1
2016-07-12 17:34:01 JobSubmitter [INFO] Submitting tokens for job: job_local423453653_0002
2016-07-12 17:34:01 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:34:01 Job [INFO] Running job: job_local423453653_0002
2016-07-12 17:34:01 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:34:01 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:34:01 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:34:01 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:34:01 LocalJobRunner [INFO] Starting task: attempt_local423453653_0002_m_000000_0
2016-07-12 17:34:01 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:34:01 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:34:01 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/part-r-00000:0+1351
2016-07-12 17:34:01 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:34:01 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:34:01 MapTask [INFO] soft limit at 83886080
2016-07-12 17:34:01 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:34:01 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:34:01 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:34:01 LocalJobRunner [INFO] 
2016-07-12 17:34:01 MapTask [INFO] Starting flush of map output
2016-07-12 17:34:01 MapTask [INFO] Spilling map output
2016-07-12 17:34:01 MapTask [INFO] bufstart = 0; bufend = 1351; bufvoid = 104857600
2016-07-12 17:34:01 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 17:34:01 MapTask [INFO] Finished spill 0
2016-07-12 17:34:01 Task [INFO] Task:attempt_local423453653_0002_m_000000_0 is done. And is in the process of committing
2016-07-12 17:34:01 LocalJobRunner [INFO] map
2016-07-12 17:34:01 Task [INFO] Task 'attempt_local423453653_0002_m_000000_0' done.
2016-07-12 17:34:01 LocalJobRunner [INFO] Finishing task: attempt_local423453653_0002_m_000000_0
2016-07-12 17:34:01 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:34:01 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:34:01 LocalJobRunner [INFO] Starting task: attempt_local423453653_0002_r_000000_0
2016-07-12 17:34:01 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:34:01 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:34:01 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3a28195
2016-07-12 17:34:01 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:34:01 EventFetcher [INFO] attempt_local423453653_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:34:01 LocalFetcher [INFO] localfetcher#2 about to shuffle output of map attempt_local423453653_0002_m_000000_0 decomp: 1515 len: 1519 to MEMORY
2016-07-12 17:34:01 InMemoryMapOutput [INFO] Read 1515 bytes from map-output for attempt_local423453653_0002_m_000000_0
2016-07-12 17:34:01 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1515, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1515
2016-07-12 17:34:01 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:34:01 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:34:01 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:34:01 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:34:01 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 17:34:01 MergeManagerImpl [INFO] Merged 1 segments, 1515 bytes to disk to satisfy reduce memory limit
2016-07-12 17:34:01 MergeManagerImpl [INFO] Merging 1 files, 1519 bytes from disk
2016-07-12 17:34:01 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:34:01 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:34:01 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 17:34:01 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:34:01 Task [INFO] Task:attempt_local423453653_0002_r_000000_0 is done. And is in the process of committing
2016-07-12 17:34:01 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:34:01 Task [INFO] Task attempt_local423453653_0002_r_000000_0 is allowed to commit now
2016-07-12 17:34:01 FileOutputCommitter [INFO] Saved output of task 'attempt_local423453653_0002_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/_temporary/0/task_local423453653_0002_r_000000
2016-07-12 17:34:01 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:34:01 Task [INFO] Task 'attempt_local423453653_0002_r_000000_0' done.
2016-07-12 17:34:01 LocalJobRunner [INFO] Finishing task: attempt_local423453653_0002_r_000000_0
2016-07-12 17:34:01 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:34:02 Job [INFO] Job job_local423453653_0002 running in uber mode : false
2016-07-12 17:34:02 Job [INFO]  map 100% reduce 100%
2016-07-12 17:34:02 Job [INFO] Job job_local423453653_0002 completed successfully
2016-07-12 17:34:02 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=27190
		FILE: Number of bytes written=1143370
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1351
		Map output materialized bytes=1519
		Input split bytes=145
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=1519
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1062207488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1375
	File Output Format Counters 
		Bytes Written=1533
2016-07-12 17:34:02 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:34:02 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:34:02 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:34:02 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:34:02 JobSubmitter [INFO] number of splits:1
2016-07-12 17:34:02 JobSubmitter [INFO] Submitting tokens for job: job_local1517516193_0003
2016-07-12 17:34:03 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:34:03 Job [INFO] Running job: job_local1517516193_0003
2016-07-12 17:34:03 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:34:03 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:34:03 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:34:03 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:34:03 LocalJobRunner [INFO] Starting task: attempt_local1517516193_0003_m_000000_0
2016-07-12 17:34:03 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:34:03 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:34:03 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/part-r-00000:0+1513
2016-07-12 17:34:03 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:34:03 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:34:03 MapTask [INFO] soft limit at 83886080
2016-07-12 17:34:03 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:34:03 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:34:03 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:34:03 LocalJobRunner [INFO] 
2016-07-12 17:34:03 MapTask [INFO] Starting flush of map output
2016-07-12 17:34:03 MapTask [INFO] Spilling map output
2016-07-12 17:34:03 MapTask [INFO] bufstart = 0; bufend = 1513; bufvoid = 104857600
2016-07-12 17:34:03 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 17:34:03 MapTask [INFO] Finished spill 0
2016-07-12 17:34:03 Task [INFO] Task:attempt_local1517516193_0003_m_000000_0 is done. And is in the process of committing
2016-07-12 17:34:03 LocalJobRunner [INFO] map
2016-07-12 17:34:03 Task [INFO] Task 'attempt_local1517516193_0003_m_000000_0' done.
2016-07-12 17:34:03 LocalJobRunner [INFO] Finishing task: attempt_local1517516193_0003_m_000000_0
2016-07-12 17:34:03 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:34:03 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:34:03 LocalJobRunner [INFO] Starting task: attempt_local1517516193_0003_r_000000_0
2016-07-12 17:34:03 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:34:03 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:34:03 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2711c490
2016-07-12 17:34:03 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:34:03 EventFetcher [INFO] attempt_local1517516193_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:34:03 LocalFetcher [INFO] localfetcher#3 about to shuffle output of map attempt_local1517516193_0003_m_000000_0 decomp: 1677 len: 1681 to MEMORY
2016-07-12 17:34:03 InMemoryMapOutput [INFO] Read 1677 bytes from map-output for attempt_local1517516193_0003_m_000000_0
2016-07-12 17:34:03 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1677, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1677
2016-07-12 17:34:03 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:34:03 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:34:03 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:34:03 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:34:03 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 17:34:03 MergeManagerImpl [INFO] Merged 1 segments, 1677 bytes to disk to satisfy reduce memory limit
2016-07-12 17:34:03 MergeManagerImpl [INFO] Merging 1 files, 1681 bytes from disk
2016-07-12 17:34:03 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:34:03 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:34:03 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 17:34:03 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:34:03 Task [INFO] Task:attempt_local1517516193_0003_r_000000_0 is done. And is in the process of committing
2016-07-12 17:34:03 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:34:03 Task [INFO] Task attempt_local1517516193_0003_r_000000_0 is allowed to commit now
2016-07-12 17:34:03 FileOutputCommitter [INFO] Saved output of task 'attempt_local1517516193_0003_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/_temporary/0/task_local1517516193_0003_r_000000
2016-07-12 17:34:03 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:34:03 Task [INFO] Task 'attempt_local1517516193_0003_r_000000_0' done.
2016-07-12 17:34:03 LocalJobRunner [INFO] Finishing task: attempt_local1517516193_0003_r_000000_0
2016-07-12 17:34:03 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:34:04 Job [INFO] Job job_local1517516193_0003 running in uber mode : false
2016-07-12 17:34:04 Job [INFO]  map 100% reduce 100%
2016-07-12 17:34:04 Job [INFO] Job job_local1517516193_0003 completed successfully
2016-07-12 17:34:04 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=37134
		FILE: Number of bytes written=1717282
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1513
		Map output materialized bytes=1681
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=59
		Reduce shuffle bytes=1681
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=867172352
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1537
	File Output Format Counters 
		Bytes Written=2079
2016-07-12 17:34:04 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:34:04 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:34:04 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:34:04 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:34:04 JobSubmitter [INFO] number of splits:1
2016-07-12 17:34:05 JobSubmitter [INFO] Submitting tokens for job: job_local1854768120_0004
2016-07-12 17:34:05 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:34:05 Job [INFO] Running job: job_local1854768120_0004
2016-07-12 17:34:05 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:34:05 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:34:05 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:34:05 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:34:05 LocalJobRunner [INFO] Starting task: attempt_local1854768120_0004_m_000000_0
2016-07-12 17:34:05 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:34:05 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:34:05 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/part-r-00000:0+2051
2016-07-12 17:34:05 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:34:05 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:34:05 MapTask [INFO] soft limit at 83886080
2016-07-12 17:34:05 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:34:05 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:34:05 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:34:05 MapTask [INFO] Starting flush of map output
2016-07-12 17:34:05 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:34:05 LocalJobRunner [WARN] job_local1854768120_0004
java.lang.Exception: java.lang.ClassCastException: org.apache.hadoop.io.LongWritable cannot be cast to org.apache.avro.mapred.AvroKey
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ClassCastException: org.apache.hadoop.io.LongWritable cannot be cast to org.apache.avro.mapred.AvroKey
	at eu.edisonproject.training.tfidf.mapreduce.WordsGroupByTitleDriver$WordsGroupByTitleMapper.map(WordsGroupByTitleDriver.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 17:34:06 Job [INFO] Job job_local1854768120_0004 running in uber mode : false
2016-07-12 17:34:06 Job [INFO]  map 0% reduce 0%
2016-07-12 17:34:06 Job [INFO] Job job_local1854768120_0004 failed with state FAILED due to: NA
2016-07-12 17:34:06 Job [INFO] Counters: 0
2016-07-12 17:37:20 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 17:37:20 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 17:37:20 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 17:37:21 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:37:21 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:37:21 JobSubmitter [INFO] number of splits:1
2016-07-12 17:37:21 JobSubmitter [INFO] Submitting tokens for job: job_local1738492385_0001
2016-07-12 17:37:21 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:37:21 Job [INFO] Running job: job_local1738492385_0001
2016-07-12 17:37:21 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:37:21 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:37:21 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:37:21 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:37:21 LocalJobRunner [INFO] Starting task: attempt_local1738492385_0001_m_000000_0
2016-07-12 17:37:21 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:37:21 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:37:21 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 17:37:21 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:37:21 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:37:21 MapTask [INFO] soft limit at 83886080
2016-07-12 17:37:21 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:37:21 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:37:21 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:37:22 Job [INFO] Job job_local1738492385_0001 running in uber mode : false
2016-07-12 17:37:22 Job [INFO]  map 0% reduce 0%
2016-07-12 17:37:22 LocalJobRunner [INFO] 
2016-07-12 17:37:22 MapTask [INFO] Starting flush of map output
2016-07-12 17:37:22 MapTask [INFO] Spilling map output
2016-07-12 17:37:22 MapTask [INFO] bufstart = 0; bufend = 1545; bufvoid = 104857600
2016-07-12 17:37:22 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214068(104856272); length = 329/6553600
2016-07-12 17:37:22 MapTask [INFO] Finished spill 0
2016-07-12 17:37:22 Task [INFO] Task:attempt_local1738492385_0001_m_000000_0 is done. And is in the process of committing
2016-07-12 17:37:22 LocalJobRunner [INFO] map
2016-07-12 17:37:22 Task [INFO] Task 'attempt_local1738492385_0001_m_000000_0' done.
2016-07-12 17:37:22 LocalJobRunner [INFO] Finishing task: attempt_local1738492385_0001_m_000000_0
2016-07-12 17:37:22 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:37:22 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:37:22 LocalJobRunner [INFO] Starting task: attempt_local1738492385_0001_r_000000_0
2016-07-12 17:37:22 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:37:22 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:37:22 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@28ce080b
2016-07-12 17:37:22 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:37:22 EventFetcher [INFO] attempt_local1738492385_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:37:22 LocalFetcher [INFO] localfetcher#1 about to shuffle output of map attempt_local1738492385_0001_m_000000_0 decomp: 1713 len: 1717 to MEMORY
2016-07-12 17:37:22 InMemoryMapOutput [INFO] Read 1713 bytes from map-output for attempt_local1738492385_0001_m_000000_0
2016-07-12 17:37:22 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1713, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1713
2016-07-12 17:37:22 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:37:22 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:37:22 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:37:22 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:37:22 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:37:22 MergeManagerImpl [INFO] Merged 1 segments, 1713 bytes to disk to satisfy reduce memory limit
2016-07-12 17:37:22 MergeManagerImpl [INFO] Merging 1 files, 1717 bytes from disk
2016-07-12 17:37:22 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:37:22 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:37:22 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:37:22 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:37:22 deprecation [INFO] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-07-12 17:37:22 Task [INFO] Task:attempt_local1738492385_0001_r_000000_0 is done. And is in the process of committing
2016-07-12 17:37:22 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:37:22 Task [INFO] Task attempt_local1738492385_0001_r_000000_0 is allowed to commit now
2016-07-12 17:37:22 FileOutputCommitter [INFO] Saved output of task 'attempt_local1738492385_0001_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/_temporary/0/task_local1738492385_0001_r_000000
2016-07-12 17:37:22 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:37:22 Task [INFO] Task 'attempt_local1738492385_0001_r_000000_0' done.
2016-07-12 17:37:22 LocalJobRunner [INFO] Finishing task: attempt_local1738492385_0001_r_000000_0
2016-07-12 17:37:22 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:37:23 Job [INFO]  map 100% reduce 100%
2016-07-12 17:37:23 Job [INFO] Job job_local1738492385_0001 completed successfully
2016-07-12 17:37:23 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=17502
		FILE: Number of bytes written=576366
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=83
		Map output bytes=1545
		Map output materialized bytes=1717
		Input split bytes=144
		Combine input records=0
		Combine output records=0
		Reduce input groups=81
		Reduce shuffle bytes=1717
		Reduce input records=83
		Reduce output records=81
		Spilled Records=166
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=144
		Total committed heap usage (bytes)=698351616
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6818
	File Output Format Counters 
		Bytes Written=1371
2016-07-12 17:37:23 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:37:23 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:37:23 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:37:23 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:37:23 JobSubmitter [INFO] number of splits:1
2016-07-12 17:37:23 JobSubmitter [INFO] Submitting tokens for job: job_local950818747_0002
2016-07-12 17:37:23 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:37:23 Job [INFO] Running job: job_local950818747_0002
2016-07-12 17:37:23 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:37:23 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:37:23 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:37:23 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:37:23 LocalJobRunner [INFO] Starting task: attempt_local950818747_0002_m_000000_0
2016-07-12 17:37:23 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:37:23 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:37:23 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/part-r-00000:0+1351
2016-07-12 17:37:23 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:37:23 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:37:23 MapTask [INFO] soft limit at 83886080
2016-07-12 17:37:23 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:37:23 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:37:23 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:37:23 LocalJobRunner [INFO] 
2016-07-12 17:37:23 MapTask [INFO] Starting flush of map output
2016-07-12 17:37:23 MapTask [INFO] Spilling map output
2016-07-12 17:37:23 MapTask [INFO] bufstart = 0; bufend = 1351; bufvoid = 104857600
2016-07-12 17:37:23 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 17:37:23 MapTask [INFO] Finished spill 0
2016-07-12 17:37:23 Task [INFO] Task:attempt_local950818747_0002_m_000000_0 is done. And is in the process of committing
2016-07-12 17:37:23 LocalJobRunner [INFO] map
2016-07-12 17:37:23 Task [INFO] Task 'attempt_local950818747_0002_m_000000_0' done.
2016-07-12 17:37:23 LocalJobRunner [INFO] Finishing task: attempt_local950818747_0002_m_000000_0
2016-07-12 17:37:23 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:37:23 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:37:23 LocalJobRunner [INFO] Starting task: attempt_local950818747_0002_r_000000_0
2016-07-12 17:37:23 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:37:23 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:37:23 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6ea6ed8e
2016-07-12 17:37:23 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:37:23 EventFetcher [INFO] attempt_local950818747_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:37:23 LocalFetcher [INFO] localfetcher#2 about to shuffle output of map attempt_local950818747_0002_m_000000_0 decomp: 1515 len: 1519 to MEMORY
2016-07-12 17:37:23 InMemoryMapOutput [INFO] Read 1515 bytes from map-output for attempt_local950818747_0002_m_000000_0
2016-07-12 17:37:23 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1515, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1515
2016-07-12 17:37:23 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:37:23 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:37:23 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:37:23 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:37:23 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 17:37:23 MergeManagerImpl [INFO] Merged 1 segments, 1515 bytes to disk to satisfy reduce memory limit
2016-07-12 17:37:23 MergeManagerImpl [INFO] Merging 1 files, 1519 bytes from disk
2016-07-12 17:37:23 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:37:23 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:37:23 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 17:37:23 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:37:23 Task [INFO] Task:attempt_local950818747_0002_r_000000_0 is done. And is in the process of committing
2016-07-12 17:37:23 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:37:23 Task [INFO] Task attempt_local950818747_0002_r_000000_0 is allowed to commit now
2016-07-12 17:37:23 FileOutputCommitter [INFO] Saved output of task 'attempt_local950818747_0002_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/_temporary/0/task_local950818747_0002_r_000000
2016-07-12 17:37:23 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:37:23 Task [INFO] Task 'attempt_local950818747_0002_r_000000_0' done.
2016-07-12 17:37:23 LocalJobRunner [INFO] Finishing task: attempt_local950818747_0002_r_000000_0
2016-07-12 17:37:23 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:37:24 Job [INFO] Job job_local950818747_0002 running in uber mode : false
2016-07-12 17:37:24 Job [INFO]  map 100% reduce 100%
2016-07-12 17:37:24 Job [INFO] Job job_local950818747_0002 completed successfully
2016-07-12 17:37:24 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=27190
		FILE: Number of bytes written=1146382
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1351
		Map output materialized bytes=1519
		Input split bytes=145
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=1519
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=786432000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1375
	File Output Format Counters 
		Bytes Written=1533
2016-07-12 17:37:24 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:37:24 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:37:24 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:37:24 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:37:25 JobSubmitter [INFO] number of splits:1
2016-07-12 17:37:25 JobSubmitter [INFO] Submitting tokens for job: job_local524354785_0003
2016-07-12 17:37:25 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:37:25 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:37:25 Job [INFO] Running job: job_local524354785_0003
2016-07-12 17:37:25 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:37:25 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:37:25 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:37:25 LocalJobRunner [INFO] Starting task: attempt_local524354785_0003_m_000000_0
2016-07-12 17:37:25 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:37:25 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:37:25 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/part-r-00000:0+1513
2016-07-12 17:37:25 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:37:25 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:37:25 MapTask [INFO] soft limit at 83886080
2016-07-12 17:37:25 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:37:25 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:37:25 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:37:25 LocalJobRunner [INFO] 
2016-07-12 17:37:25 MapTask [INFO] Starting flush of map output
2016-07-12 17:37:25 MapTask [INFO] Spilling map output
2016-07-12 17:37:25 MapTask [INFO] bufstart = 0; bufend = 1513; bufvoid = 104857600
2016-07-12 17:37:25 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 17:37:25 MapTask [INFO] Finished spill 0
2016-07-12 17:37:25 Task [INFO] Task:attempt_local524354785_0003_m_000000_0 is done. And is in the process of committing
2016-07-12 17:37:25 LocalJobRunner [INFO] map
2016-07-12 17:37:25 Task [INFO] Task 'attempt_local524354785_0003_m_000000_0' done.
2016-07-12 17:37:25 LocalJobRunner [INFO] Finishing task: attempt_local524354785_0003_m_000000_0
2016-07-12 17:37:25 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:37:25 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:37:25 LocalJobRunner [INFO] Starting task: attempt_local524354785_0003_r_000000_0
2016-07-12 17:37:25 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:37:25 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:37:25 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2c7ecc0a
2016-07-12 17:37:25 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:37:25 EventFetcher [INFO] attempt_local524354785_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:37:25 LocalFetcher [INFO] localfetcher#3 about to shuffle output of map attempt_local524354785_0003_m_000000_0 decomp: 1677 len: 1681 to MEMORY
2016-07-12 17:37:25 InMemoryMapOutput [INFO] Read 1677 bytes from map-output for attempt_local524354785_0003_m_000000_0
2016-07-12 17:37:25 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1677, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1677
2016-07-12 17:37:25 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:37:25 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:37:25 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:37:25 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:37:25 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 17:37:25 MergeManagerImpl [INFO] Merged 1 segments, 1677 bytes to disk to satisfy reduce memory limit
2016-07-12 17:37:25 MergeManagerImpl [INFO] Merging 1 files, 1681 bytes from disk
2016-07-12 17:37:25 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:37:25 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:37:25 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 17:37:25 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:37:25 Task [INFO] Task:attempt_local524354785_0003_r_000000_0 is done. And is in the process of committing
2016-07-12 17:37:25 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:37:25 Task [INFO] Task attempt_local524354785_0003_r_000000_0 is allowed to commit now
2016-07-12 17:37:25 FileOutputCommitter [INFO] Saved output of task 'attempt_local524354785_0003_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/_temporary/0/task_local524354785_0003_r_000000
2016-07-12 17:37:25 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:37:25 Task [INFO] Task 'attempt_local524354785_0003_r_000000_0' done.
2016-07-12 17:37:25 LocalJobRunner [INFO] Finishing task: attempt_local524354785_0003_r_000000_0
2016-07-12 17:37:25 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:37:26 Job [INFO] Job job_local524354785_0003 running in uber mode : false
2016-07-12 17:37:26 Job [INFO]  map 100% reduce 100%
2016-07-12 17:37:26 Job [INFO] Job job_local524354785_0003 completed successfully
2016-07-12 17:37:26 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=37134
		FILE: Number of bytes written=1717302
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1513
		Map output materialized bytes=1681
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=59
		Reduce shuffle bytes=1681
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=796917760
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1537
	File Output Format Counters 
		Bytes Written=2079
2016-07-12 17:37:26 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:37:26 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:37:26 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:37:26 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:37:26 JobSubmitter [INFO] number of splits:1
2016-07-12 17:37:26 JobSubmitter [INFO] Submitting tokens for job: job_local1497943421_0004
2016-07-12 17:37:26 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:37:26 Job [INFO] Running job: job_local1497943421_0004
2016-07-12 17:37:26 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:37:26 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:37:26 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:37:26 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:37:26 LocalJobRunner [INFO] Starting task: attempt_local1497943421_0004_m_000000_0
2016-07-12 17:37:26 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:37:26 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:37:26 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/part-r-00000:0+2051
2016-07-12 17:37:26 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:37:26 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:37:26 MapTask [INFO] soft limit at 83886080
2016-07-12 17:37:26 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:37:26 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:37:26 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:37:26 LocalJobRunner [INFO] 
2016-07-12 17:37:26 MapTask [INFO] Starting flush of map output
2016-07-12 17:37:26 MapTask [INFO] Spilling map output
2016-07-12 17:37:26 MapTask [INFO] bufstart = 0; bufend = 2051; bufvoid = 104857600
2016-07-12 17:37:26 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 17:37:26 MapTask [INFO] Finished spill 0
2016-07-12 17:37:26 Task [INFO] Task:attempt_local1497943421_0004_m_000000_0 is done. And is in the process of committing
2016-07-12 17:37:26 LocalJobRunner [INFO] map
2016-07-12 17:37:26 Task [INFO] Task 'attempt_local1497943421_0004_m_000000_0' done.
2016-07-12 17:37:26 LocalJobRunner [INFO] Finishing task: attempt_local1497943421_0004_m_000000_0
2016-07-12 17:37:26 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:37:26 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:37:26 LocalJobRunner [INFO] Starting task: attempt_local1497943421_0004_r_000000_0
2016-07-12 17:37:26 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:37:26 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:37:26 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@524f948
2016-07-12 17:37:26 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:37:26 EventFetcher [INFO] attempt_local1497943421_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:37:26 LocalFetcher [INFO] localfetcher#4 about to shuffle output of map attempt_local1497943421_0004_m_000000_0 decomp: 2215 len: 2219 to MEMORY
2016-07-12 17:37:26 InMemoryMapOutput [INFO] Read 2215 bytes from map-output for attempt_local1497943421_0004_m_000000_0
2016-07-12 17:37:26 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 2215, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2215
2016-07-12 17:37:26 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:37:26 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:37:26 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:37:26 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:37:26 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 2204 bytes
2016-07-12 17:37:26 MergeManagerImpl [INFO] Merged 1 segments, 2215 bytes to disk to satisfy reduce memory limit
2016-07-12 17:37:26 MergeManagerImpl [INFO] Merging 1 files, 2219 bytes from disk
2016-07-12 17:37:26 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:37:26 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:37:26 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 2204 bytes
2016-07-12 17:37:26 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:37:26 Task [INFO] Task:attempt_local1497943421_0004_r_000000_0 is done. And is in the process of committing
2016-07-12 17:37:26 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:37:26 Task [INFO] Task attempt_local1497943421_0004_r_000000_0 is allowed to commit now
2016-07-12 17:37:26 FileOutputCommitter [INFO] Saved output of task 'attempt_local1497943421_0004_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/4-tf-idf-document/_temporary/0/task_local1497943421_0004_r_000000
2016-07-12 17:37:26 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:37:26 Task [INFO] Task 'attempt_local1497943421_0004_r_000000_0' done.
2016-07-12 17:37:26 LocalJobRunner [INFO] Finishing task: attempt_local1497943421_0004_r_000000_0
2016-07-12 17:37:26 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:37:27 Job [INFO] Job job_local1497943421_0004 running in uber mode : false
2016-07-12 17:37:27 Job [INFO]  map 100% reduce 100%
2016-07-12 17:37:27 Job [INFO] Job job_local1497943421_0004 completed successfully
2016-07-12 17:37:27 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=49560
		FILE: Number of bytes written=2294375
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=2051
		Map output materialized bytes=2219
		Input split bytes=142
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=2219
		Reduce input records=81
		Reduce output records=19
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=801112064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2083
	File Output Format Counters 
		Bytes Written=2828
2016-07-12 17:51:20 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 17:51:20 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 17:51:20 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 17:51:20 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:51:20 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:51:20 JobSubmitter [INFO] number of splits:1
2016-07-12 17:51:21 JobSubmitter [INFO] Submitting tokens for job: job_local1136292888_0001
2016-07-12 17:51:21 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:51:21 Job [INFO] Running job: job_local1136292888_0001
2016-07-12 17:51:21 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:51:21 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:51:21 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:51:21 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:51:21 LocalJobRunner [INFO] Starting task: attempt_local1136292888_0001_m_000000_0
2016-07-12 17:51:21 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:51:21 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:51:21 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 17:51:21 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:51:21 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:51:21 MapTask [INFO] soft limit at 83886080
2016-07-12 17:51:21 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:51:21 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:51:21 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:51:22 Job [INFO] Job job_local1136292888_0001 running in uber mode : false
2016-07-12 17:51:22 Job [INFO]  map 0% reduce 0%
2016-07-12 17:51:22 LocalJobRunner [INFO] 
2016-07-12 17:51:22 MapTask [INFO] Starting flush of map output
2016-07-12 17:51:22 MapTask [INFO] Spilling map output
2016-07-12 17:51:22 MapTask [INFO] bufstart = 0; bufend = 1545; bufvoid = 104857600
2016-07-12 17:51:22 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214068(104856272); length = 329/6553600
2016-07-12 17:51:22 MapTask [INFO] Finished spill 0
2016-07-12 17:51:22 Task [INFO] Task:attempt_local1136292888_0001_m_000000_0 is done. And is in the process of committing
2016-07-12 17:51:22 LocalJobRunner [INFO] map
2016-07-12 17:51:22 Task [INFO] Task 'attempt_local1136292888_0001_m_000000_0' done.
2016-07-12 17:51:22 LocalJobRunner [INFO] Finishing task: attempt_local1136292888_0001_m_000000_0
2016-07-12 17:51:22 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:51:22 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:51:22 LocalJobRunner [INFO] Starting task: attempt_local1136292888_0001_r_000000_0
2016-07-12 17:51:22 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:51:22 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:51:22 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@20603fb4
2016-07-12 17:51:22 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:51:22 EventFetcher [INFO] attempt_local1136292888_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:51:22 LocalFetcher [INFO] localfetcher#1 about to shuffle output of map attempt_local1136292888_0001_m_000000_0 decomp: 1713 len: 1717 to MEMORY
2016-07-12 17:51:22 InMemoryMapOutput [INFO] Read 1713 bytes from map-output for attempt_local1136292888_0001_m_000000_0
2016-07-12 17:51:22 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1713, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1713
2016-07-12 17:51:22 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:51:22 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:51:22 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:51:22 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:51:22 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:51:22 MergeManagerImpl [INFO] Merged 1 segments, 1713 bytes to disk to satisfy reduce memory limit
2016-07-12 17:51:22 MergeManagerImpl [INFO] Merging 1 files, 1717 bytes from disk
2016-07-12 17:51:22 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:51:22 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:51:22 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:51:22 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:51:22 deprecation [INFO] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-07-12 17:51:22 Task [INFO] Task:attempt_local1136292888_0001_r_000000_0 is done. And is in the process of committing
2016-07-12 17:51:22 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:51:22 Task [INFO] Task attempt_local1136292888_0001_r_000000_0 is allowed to commit now
2016-07-12 17:51:22 FileOutputCommitter [INFO] Saved output of task 'attempt_local1136292888_0001_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/_temporary/0/task_local1136292888_0001_r_000000
2016-07-12 17:51:22 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:51:22 Task [INFO] Task 'attempt_local1136292888_0001_r_000000_0' done.
2016-07-12 17:51:22 LocalJobRunner [INFO] Finishing task: attempt_local1136292888_0001_r_000000_0
2016-07-12 17:51:22 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:51:23 Job [INFO]  map 100% reduce 100%
2016-07-12 17:51:23 Job [INFO] Job job_local1136292888_0001 completed successfully
2016-07-12 17:51:23 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=17502
		FILE: Number of bytes written=576366
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=83
		Map output bytes=1545
		Map output materialized bytes=1717
		Input split bytes=144
		Combine input records=0
		Combine output records=0
		Reduce input groups=81
		Reduce shuffle bytes=1717
		Reduce input records=83
		Reduce output records=81
		Spilled Records=166
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=693108736
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6818
	File Output Format Counters 
		Bytes Written=1371
2016-07-12 17:51:23 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:51:23 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:51:23 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:51:23 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:51:23 JobSubmitter [INFO] number of splits:1
2016-07-12 17:51:23 JobSubmitter [INFO] Submitting tokens for job: job_local2147008_0002
2016-07-12 17:51:23 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:51:23 Job [INFO] Running job: job_local2147008_0002
2016-07-12 17:51:23 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:51:23 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:51:23 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:51:23 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:51:23 LocalJobRunner [INFO] Starting task: attempt_local2147008_0002_m_000000_0
2016-07-12 17:51:23 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:51:23 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:51:23 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/part-r-00000:0+1351
2016-07-12 17:51:23 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:51:23 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:51:23 MapTask [INFO] soft limit at 83886080
2016-07-12 17:51:23 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:51:23 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:51:23 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:51:23 LocalJobRunner [INFO] 
2016-07-12 17:51:23 MapTask [INFO] Starting flush of map output
2016-07-12 17:51:23 MapTask [INFO] Spilling map output
2016-07-12 17:51:23 MapTask [INFO] bufstart = 0; bufend = 1351; bufvoid = 104857600
2016-07-12 17:51:23 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 17:51:23 MapTask [INFO] Finished spill 0
2016-07-12 17:51:23 Task [INFO] Task:attempt_local2147008_0002_m_000000_0 is done. And is in the process of committing
2016-07-12 17:51:23 LocalJobRunner [INFO] map
2016-07-12 17:51:23 Task [INFO] Task 'attempt_local2147008_0002_m_000000_0' done.
2016-07-12 17:51:23 LocalJobRunner [INFO] Finishing task: attempt_local2147008_0002_m_000000_0
2016-07-12 17:51:23 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:51:23 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:51:23 LocalJobRunner [INFO] Starting task: attempt_local2147008_0002_r_000000_0
2016-07-12 17:51:23 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:51:23 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:51:23 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3b1db405
2016-07-12 17:51:23 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:51:23 EventFetcher [INFO] attempt_local2147008_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:51:23 LocalFetcher [INFO] localfetcher#2 about to shuffle output of map attempt_local2147008_0002_m_000000_0 decomp: 1515 len: 1519 to MEMORY
2016-07-12 17:51:23 InMemoryMapOutput [INFO] Read 1515 bytes from map-output for attempt_local2147008_0002_m_000000_0
2016-07-12 17:51:23 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1515, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1515
2016-07-12 17:51:23 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:51:23 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:51:23 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:51:23 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:51:23 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 17:51:23 MergeManagerImpl [INFO] Merged 1 segments, 1515 bytes to disk to satisfy reduce memory limit
2016-07-12 17:51:23 MergeManagerImpl [INFO] Merging 1 files, 1519 bytes from disk
2016-07-12 17:51:23 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:51:23 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:51:23 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 17:51:23 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:51:23 Task [INFO] Task:attempt_local2147008_0002_r_000000_0 is done. And is in the process of committing
2016-07-12 17:51:23 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:51:23 Task [INFO] Task attempt_local2147008_0002_r_000000_0 is allowed to commit now
2016-07-12 17:51:23 FileOutputCommitter [INFO] Saved output of task 'attempt_local2147008_0002_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/_temporary/0/task_local2147008_0002_r_000000
2016-07-12 17:51:23 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:51:23 Task [INFO] Task 'attempt_local2147008_0002_r_000000_0' done.
2016-07-12 17:51:23 LocalJobRunner [INFO] Finishing task: attempt_local2147008_0002_r_000000_0
2016-07-12 17:51:23 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:51:24 Job [INFO] Job job_local2147008_0002 running in uber mode : false
2016-07-12 17:51:24 Job [INFO]  map 100% reduce 100%
2016-07-12 17:51:24 Job [INFO] Job job_local2147008_0002 completed successfully
2016-07-12 17:51:24 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=27190
		FILE: Number of bytes written=1140406
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1351
		Map output materialized bytes=1519
		Input split bytes=145
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=1519
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=776994816
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1375
	File Output Format Counters 
		Bytes Written=1533
2016-07-12 17:51:24 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:51:24 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:51:24 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:51:24 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:51:24 JobSubmitter [INFO] number of splits:1
2016-07-12 17:51:24 JobSubmitter [INFO] Submitting tokens for job: job_local1203302646_0003
2016-07-12 17:51:24 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:51:24 Job [INFO] Running job: job_local1203302646_0003
2016-07-12 17:51:24 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:51:24 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:51:24 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:51:24 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:51:24 LocalJobRunner [INFO] Starting task: attempt_local1203302646_0003_m_000000_0
2016-07-12 17:51:24 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:51:24 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:51:24 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/part-r-00000:0+1513
2016-07-12 17:51:24 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:51:24 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:51:24 MapTask [INFO] soft limit at 83886080
2016-07-12 17:51:24 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:51:24 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:51:24 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:51:24 LocalJobRunner [INFO] 
2016-07-12 17:51:24 MapTask [INFO] Starting flush of map output
2016-07-12 17:51:24 MapTask [INFO] Spilling map output
2016-07-12 17:51:24 MapTask [INFO] bufstart = 0; bufend = 1513; bufvoid = 104857600
2016-07-12 17:51:24 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 17:51:24 MapTask [INFO] Finished spill 0
2016-07-12 17:51:24 Task [INFO] Task:attempt_local1203302646_0003_m_000000_0 is done. And is in the process of committing
2016-07-12 17:51:24 LocalJobRunner [INFO] map
2016-07-12 17:51:24 Task [INFO] Task 'attempt_local1203302646_0003_m_000000_0' done.
2016-07-12 17:51:24 LocalJobRunner [INFO] Finishing task: attempt_local1203302646_0003_m_000000_0
2016-07-12 17:51:24 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:51:24 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:51:24 LocalJobRunner [INFO] Starting task: attempt_local1203302646_0003_r_000000_0
2016-07-12 17:51:24 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:51:24 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:51:24 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2711c490
2016-07-12 17:51:24 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:51:24 EventFetcher [INFO] attempt_local1203302646_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:51:24 LocalFetcher [INFO] localfetcher#3 about to shuffle output of map attempt_local1203302646_0003_m_000000_0 decomp: 1677 len: 1681 to MEMORY
2016-07-12 17:51:24 InMemoryMapOutput [INFO] Read 1677 bytes from map-output for attempt_local1203302646_0003_m_000000_0
2016-07-12 17:51:24 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1677, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1677
2016-07-12 17:51:24 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:51:24 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:51:25 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:51:25 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:51:25 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 17:51:25 MergeManagerImpl [INFO] Merged 1 segments, 1677 bytes to disk to satisfy reduce memory limit
2016-07-12 17:51:25 MergeManagerImpl [INFO] Merging 1 files, 1681 bytes from disk
2016-07-12 17:51:25 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:51:25 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:51:25 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 17:51:25 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:51:25 Task [INFO] Task:attempt_local1203302646_0003_r_000000_0 is done. And is in the process of committing
2016-07-12 17:51:25 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:51:25 Task [INFO] Task attempt_local1203302646_0003_r_000000_0 is allowed to commit now
2016-07-12 17:51:25 FileOutputCommitter [INFO] Saved output of task 'attempt_local1203302646_0003_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/_temporary/0/task_local1203302646_0003_r_000000
2016-07-12 17:51:25 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:51:25 Task [INFO] Task 'attempt_local1203302646_0003_r_000000_0' done.
2016-07-12 17:51:25 LocalJobRunner [INFO] Finishing task: attempt_local1203302646_0003_r_000000_0
2016-07-12 17:51:25 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:51:25 Job [INFO] Job job_local1203302646_0003 running in uber mode : false
2016-07-12 17:51:25 Job [INFO]  map 100% reduce 100%
2016-07-12 17:51:25 Job [INFO] Job job_local1203302646_0003 completed successfully
2016-07-12 17:51:25 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=37134
		FILE: Number of bytes written=1714318
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1513
		Map output materialized bytes=1681
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=59
		Reduce shuffle bytes=1681
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=788529152
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1537
	File Output Format Counters 
		Bytes Written=2079
2016-07-12 17:51:26 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:51:26 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:51:26 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:51:26 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:51:26 JobSubmitter [INFO] number of splits:1
2016-07-12 17:51:26 JobSubmitter [INFO] Submitting tokens for job: job_local1927372309_0004
2016-07-12 17:51:26 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:51:26 Job [INFO] Running job: job_local1927372309_0004
2016-07-12 17:51:26 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:51:26 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:51:26 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:51:26 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:51:26 LocalJobRunner [INFO] Starting task: attempt_local1927372309_0004_m_000000_0
2016-07-12 17:51:26 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:51:26 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:51:26 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/part-r-00000:0+2051
2016-07-12 17:51:26 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:51:26 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:51:26 MapTask [INFO] soft limit at 83886080
2016-07-12 17:51:26 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:51:26 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:51:26 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:51:26 LocalJobRunner [INFO] 
2016-07-12 17:51:26 MapTask [INFO] Starting flush of map output
2016-07-12 17:51:26 MapTask [INFO] Spilling map output
2016-07-12 17:51:26 MapTask [INFO] bufstart = 0; bufend = 2051; bufvoid = 104857600
2016-07-12 17:51:26 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 17:51:26 MapTask [INFO] Finished spill 0
2016-07-12 17:51:26 Task [INFO] Task:attempt_local1927372309_0004_m_000000_0 is done. And is in the process of committing
2016-07-12 17:51:26 LocalJobRunner [INFO] map
2016-07-12 17:51:26 Task [INFO] Task 'attempt_local1927372309_0004_m_000000_0' done.
2016-07-12 17:51:26 LocalJobRunner [INFO] Finishing task: attempt_local1927372309_0004_m_000000_0
2016-07-12 17:51:26 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:51:26 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:51:26 LocalJobRunner [INFO] Starting task: attempt_local1927372309_0004_r_000000_0
2016-07-12 17:51:26 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:51:26 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:51:26 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4e6d27d6
2016-07-12 17:51:26 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:51:26 EventFetcher [INFO] attempt_local1927372309_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:51:26 LocalFetcher [INFO] localfetcher#4 about to shuffle output of map attempt_local1927372309_0004_m_000000_0 decomp: 2215 len: 2219 to MEMORY
2016-07-12 17:51:26 InMemoryMapOutput [INFO] Read 2215 bytes from map-output for attempt_local1927372309_0004_m_000000_0
2016-07-12 17:51:26 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 2215, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2215
2016-07-12 17:51:26 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:51:26 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:51:26 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:51:26 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:51:26 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 2204 bytes
2016-07-12 17:51:26 MergeManagerImpl [INFO] Merged 1 segments, 2215 bytes to disk to satisfy reduce memory limit
2016-07-12 17:51:26 MergeManagerImpl [INFO] Merging 1 files, 2219 bytes from disk
2016-07-12 17:51:26 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:51:26 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:51:26 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 2204 bytes
2016-07-12 17:51:26 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:51:26 Task [INFO] Task:attempt_local1927372309_0004_r_000000_0 is done. And is in the process of committing
2016-07-12 17:51:26 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:51:26 Task [INFO] Task attempt_local1927372309_0004_r_000000_0 is allowed to commit now
2016-07-12 17:51:26 FileOutputCommitter [INFO] Saved output of task 'attempt_local1927372309_0004_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/4-tf-idf-document/_temporary/0/task_local1927372309_0004_r_000000
2016-07-12 17:51:26 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:51:26 Task [INFO] Task 'attempt_local1927372309_0004_r_000000_0' done.
2016-07-12 17:51:26 LocalJobRunner [INFO] Finishing task: attempt_local1927372309_0004_r_000000_0
2016-07-12 17:51:26 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:51:27 Job [INFO] Job job_local1927372309_0004 running in uber mode : false
2016-07-12 17:51:27 Job [INFO]  map 100% reduce 100%
2016-07-12 17:51:27 Job [INFO] Job job_local1927372309_0004 completed successfully
2016-07-12 17:51:27 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=49560
		FILE: Number of bytes written=2291391
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=2051
		Map output materialized bytes=2219
		Input split bytes=142
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=2219
		Reduce input records=81
		Reduce output records=19
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=805306368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2083
	File Output Format Counters 
		Bytes Written=2828
2016-07-12 17:53:18 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 17:53:18 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 17:53:18 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 17:53:19 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:53:19 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:53:19 JobSubmitter [INFO] number of splits:1
2016-07-12 17:53:19 JobSubmitter [INFO] Submitting tokens for job: job_local1034149148_0001
2016-07-12 17:53:19 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:53:19 Job [INFO] Running job: job_local1034149148_0001
2016-07-12 17:53:19 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:53:19 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:53:19 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:53:19 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:53:19 LocalJobRunner [INFO] Starting task: attempt_local1034149148_0001_m_000000_0
2016-07-12 17:53:19 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:53:19 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:53:19 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 17:53:19 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:53:19 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:53:19 MapTask [INFO] soft limit at 83886080
2016-07-12 17:53:19 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:53:19 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:53:19 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:53:20 Job [INFO] Job job_local1034149148_0001 running in uber mode : false
2016-07-12 17:53:20 Job [INFO]  map 0% reduce 0%
2016-07-12 17:53:20 LocalJobRunner [INFO] 
2016-07-12 17:53:20 MapTask [INFO] Starting flush of map output
2016-07-12 17:53:20 MapTask [INFO] Spilling map output
2016-07-12 17:53:20 MapTask [INFO] bufstart = 0; bufend = 1545; bufvoid = 104857600
2016-07-12 17:53:20 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214068(104856272); length = 329/6553600
2016-07-12 17:53:20 MapTask [INFO] Finished spill 0
2016-07-12 17:53:20 Task [INFO] Task:attempt_local1034149148_0001_m_000000_0 is done. And is in the process of committing
2016-07-12 17:53:20 LocalJobRunner [INFO] map
2016-07-12 17:53:20 Task [INFO] Task 'attempt_local1034149148_0001_m_000000_0' done.
2016-07-12 17:53:20 LocalJobRunner [INFO] Finishing task: attempt_local1034149148_0001_m_000000_0
2016-07-12 17:53:20 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:53:20 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:53:20 LocalJobRunner [INFO] Starting task: attempt_local1034149148_0001_r_000000_0
2016-07-12 17:53:20 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:53:20 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:53:20 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3fb948e3
2016-07-12 17:53:20 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:53:20 EventFetcher [INFO] attempt_local1034149148_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:53:20 LocalFetcher [INFO] localfetcher#1 about to shuffle output of map attempt_local1034149148_0001_m_000000_0 decomp: 1713 len: 1717 to MEMORY
2016-07-12 17:53:20 InMemoryMapOutput [INFO] Read 1713 bytes from map-output for attempt_local1034149148_0001_m_000000_0
2016-07-12 17:53:20 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1713, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1713
2016-07-12 17:53:20 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:53:20 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:53:20 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:53:20 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:53:20 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:53:20 MergeManagerImpl [INFO] Merged 1 segments, 1713 bytes to disk to satisfy reduce memory limit
2016-07-12 17:53:20 MergeManagerImpl [INFO] Merging 1 files, 1717 bytes from disk
2016-07-12 17:53:20 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:53:20 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:53:20 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:53:20 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:53:20 deprecation [INFO] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-07-12 17:53:20 Task [INFO] Task:attempt_local1034149148_0001_r_000000_0 is done. And is in the process of committing
2016-07-12 17:53:20 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:53:20 Task [INFO] Task attempt_local1034149148_0001_r_000000_0 is allowed to commit now
2016-07-12 17:53:20 FileOutputCommitter [INFO] Saved output of task 'attempt_local1034149148_0001_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/_temporary/0/task_local1034149148_0001_r_000000
2016-07-12 17:53:20 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:53:20 Task [INFO] Task 'attempt_local1034149148_0001_r_000000_0' done.
2016-07-12 17:53:20 LocalJobRunner [INFO] Finishing task: attempt_local1034149148_0001_r_000000_0
2016-07-12 17:53:20 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:53:21 Job [INFO]  map 100% reduce 100%
2016-07-12 17:53:21 Job [INFO] Job job_local1034149148_0001 completed successfully
2016-07-12 17:53:21 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=17502
		FILE: Number of bytes written=576366
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=83
		Map output bytes=1545
		Map output materialized bytes=1717
		Input split bytes=144
		Combine input records=0
		Combine output records=0
		Reduce input groups=81
		Reduce shuffle bytes=1717
		Reduce input records=83
		Reduce output records=81
		Spilled Records=166
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=117
		Total committed heap usage (bytes)=848297984
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6818
	File Output Format Counters 
		Bytes Written=1371
2016-07-12 17:53:21 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:53:21 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:53:21 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:53:21 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:53:21 JobSubmitter [INFO] number of splits:1
2016-07-12 17:53:21 JobSubmitter [INFO] Submitting tokens for job: job_local613347082_0002
2016-07-12 17:53:21 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:53:21 Job [INFO] Running job: job_local613347082_0002
2016-07-12 17:53:21 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:53:21 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:53:21 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:53:21 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:53:21 LocalJobRunner [INFO] Starting task: attempt_local613347082_0002_m_000000_0
2016-07-12 17:53:21 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:53:21 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:53:21 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/part-r-00000:0+1351
2016-07-12 17:53:21 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:53:21 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:53:21 MapTask [INFO] soft limit at 83886080
2016-07-12 17:53:21 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:53:21 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:53:21 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:53:21 LocalJobRunner [INFO] 
2016-07-12 17:53:21 MapTask [INFO] Starting flush of map output
2016-07-12 17:53:21 MapTask [INFO] Spilling map output
2016-07-12 17:53:21 MapTask [INFO] bufstart = 0; bufend = 1351; bufvoid = 104857600
2016-07-12 17:53:21 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 17:53:21 MapTask [INFO] Finished spill 0
2016-07-12 17:53:21 Task [INFO] Task:attempt_local613347082_0002_m_000000_0 is done. And is in the process of committing
2016-07-12 17:53:21 LocalJobRunner [INFO] map
2016-07-12 17:53:21 Task [INFO] Task 'attempt_local613347082_0002_m_000000_0' done.
2016-07-12 17:53:21 LocalJobRunner [INFO] Finishing task: attempt_local613347082_0002_m_000000_0
2016-07-12 17:53:21 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:53:21 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:53:21 LocalJobRunner [INFO] Starting task: attempt_local613347082_0002_r_000000_0
2016-07-12 17:53:21 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:53:21 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:53:21 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7a9937a
2016-07-12 17:53:21 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:53:21 EventFetcher [INFO] attempt_local613347082_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:53:21 LocalFetcher [INFO] localfetcher#2 about to shuffle output of map attempt_local613347082_0002_m_000000_0 decomp: 1515 len: 1519 to MEMORY
2016-07-12 17:53:21 InMemoryMapOutput [INFO] Read 1515 bytes from map-output for attempt_local613347082_0002_m_000000_0
2016-07-12 17:53:21 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1515, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1515
2016-07-12 17:53:21 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:53:21 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:53:21 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:53:21 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:53:21 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 17:53:21 MergeManagerImpl [INFO] Merged 1 segments, 1515 bytes to disk to satisfy reduce memory limit
2016-07-12 17:53:21 MergeManagerImpl [INFO] Merging 1 files, 1519 bytes from disk
2016-07-12 17:53:21 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:53:21 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:53:21 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 17:53:21 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:53:21 Task [INFO] Task:attempt_local613347082_0002_r_000000_0 is done. And is in the process of committing
2016-07-12 17:53:21 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:53:21 Task [INFO] Task attempt_local613347082_0002_r_000000_0 is allowed to commit now
2016-07-12 17:53:21 FileOutputCommitter [INFO] Saved output of task 'attempt_local613347082_0002_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/_temporary/0/task_local613347082_0002_r_000000
2016-07-12 17:53:21 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:53:21 Task [INFO] Task 'attempt_local613347082_0002_r_000000_0' done.
2016-07-12 17:53:21 LocalJobRunner [INFO] Finishing task: attempt_local613347082_0002_r_000000_0
2016-07-12 17:53:21 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:53:22 Job [INFO] Job job_local613347082_0002 running in uber mode : false
2016-07-12 17:53:22 Job [INFO]  map 100% reduce 100%
2016-07-12 17:53:22 Job [INFO] Job job_local613347082_0002 completed successfully
2016-07-12 17:53:22 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=27190
		FILE: Number of bytes written=1146382
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1351
		Map output materialized bytes=1519
		Input split bytes=145
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=1519
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1065353216
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1375
	File Output Format Counters 
		Bytes Written=1533
2016-07-12 17:53:22 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:53:22 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:53:22 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:53:22 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:53:22 JobSubmitter [INFO] number of splits:1
2016-07-12 17:53:22 JobSubmitter [INFO] Submitting tokens for job: job_local1245805974_0003
2016-07-12 17:53:23 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:53:23 Job [INFO] Running job: job_local1245805974_0003
2016-07-12 17:53:23 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:53:23 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:53:23 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:53:23 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:53:23 LocalJobRunner [INFO] Starting task: attempt_local1245805974_0003_m_000000_0
2016-07-12 17:53:23 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:53:23 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:53:23 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/part-r-00000:0+1513
2016-07-12 17:53:23 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:53:23 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:53:23 MapTask [INFO] soft limit at 83886080
2016-07-12 17:53:23 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:53:23 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:53:23 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:53:23 LocalJobRunner [INFO] 
2016-07-12 17:53:23 MapTask [INFO] Starting flush of map output
2016-07-12 17:53:23 MapTask [INFO] Spilling map output
2016-07-12 17:53:23 MapTask [INFO] bufstart = 0; bufend = 1513; bufvoid = 104857600
2016-07-12 17:53:23 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 17:53:23 MapTask [INFO] Finished spill 0
2016-07-12 17:53:23 Task [INFO] Task:attempt_local1245805974_0003_m_000000_0 is done. And is in the process of committing
2016-07-12 17:53:23 LocalJobRunner [INFO] map
2016-07-12 17:53:23 Task [INFO] Task 'attempt_local1245805974_0003_m_000000_0' done.
2016-07-12 17:53:23 LocalJobRunner [INFO] Finishing task: attempt_local1245805974_0003_m_000000_0
2016-07-12 17:53:23 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:53:23 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:53:23 LocalJobRunner [INFO] Starting task: attempt_local1245805974_0003_r_000000_0
2016-07-12 17:53:23 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:53:23 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:53:23 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4e229729
2016-07-12 17:53:23 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:53:23 EventFetcher [INFO] attempt_local1245805974_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:53:23 LocalFetcher [INFO] localfetcher#3 about to shuffle output of map attempt_local1245805974_0003_m_000000_0 decomp: 1677 len: 1681 to MEMORY
2016-07-12 17:53:23 InMemoryMapOutput [INFO] Read 1677 bytes from map-output for attempt_local1245805974_0003_m_000000_0
2016-07-12 17:53:23 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1677, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1677
2016-07-12 17:53:23 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:53:23 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:53:23 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:53:23 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:53:23 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 17:53:23 MergeManagerImpl [INFO] Merged 1 segments, 1677 bytes to disk to satisfy reduce memory limit
2016-07-12 17:53:23 MergeManagerImpl [INFO] Merging 1 files, 1681 bytes from disk
2016-07-12 17:53:23 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:53:23 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:53:23 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 17:53:23 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:53:23 Task [INFO] Task:attempt_local1245805974_0003_r_000000_0 is done. And is in the process of committing
2016-07-12 17:53:23 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:53:23 Task [INFO] Task attempt_local1245805974_0003_r_000000_0 is allowed to commit now
2016-07-12 17:53:23 FileOutputCommitter [INFO] Saved output of task 'attempt_local1245805974_0003_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/_temporary/0/task_local1245805974_0003_r_000000
2016-07-12 17:53:23 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:53:23 Task [INFO] Task 'attempt_local1245805974_0003_r_000000_0' done.
2016-07-12 17:53:23 LocalJobRunner [INFO] Finishing task: attempt_local1245805974_0003_r_000000_0
2016-07-12 17:53:23 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:53:24 Job [INFO] Job job_local1245805974_0003 running in uber mode : false
2016-07-12 17:53:24 Job [INFO]  map 100% reduce 100%
2016-07-12 17:53:24 Job [INFO] Job job_local1245805974_0003 completed successfully
2016-07-12 17:53:24 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=37134
		FILE: Number of bytes written=1720294
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1513
		Map output materialized bytes=1681
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=59
		Reduce shuffle bytes=1681
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=870318080
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1537
	File Output Format Counters 
		Bytes Written=2079
2016-07-12 17:53:24 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:53:24 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:53:24 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:53:24 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:53:24 JobSubmitter [INFO] number of splits:1
2016-07-12 17:53:24 JobSubmitter [INFO] Submitting tokens for job: job_local901401917_0004
2016-07-12 17:53:25 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:53:25 Job [INFO] Running job: job_local901401917_0004
2016-07-12 17:53:25 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:53:25 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:53:25 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:53:25 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:53:25 LocalJobRunner [INFO] Starting task: attempt_local901401917_0004_m_000000_0
2016-07-12 17:53:25 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:53:25 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:53:25 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/part-r-00000:0+2051
2016-07-12 17:53:25 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:53:25 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:53:25 MapTask [INFO] soft limit at 83886080
2016-07-12 17:53:25 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:53:25 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:53:25 MapTask [WARN] Unable to initialize MapOutputCollector org.apache.hadoop.mapred.MapTask$MapOutputBuffer
java.lang.ClassCastException: class org.apache.avro.mapred.AvroKey
	at java.lang.Class.asSubclass(Class.java:3404)
	at org.apache.hadoop.mapred.JobConf.getOutputKeyComparator(JobConf.java:887)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:1004)
	at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)
	at org.apache.hadoop.mapred.MapTask.access$100(MapTask.java:81)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.<init>(MapTask.java:698)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:770)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-07-12 17:53:25 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:53:25 LocalJobRunner [WARN] job_local901401917_0004
java.lang.Exception: java.io.IOException: Initialization of all the collectors failed. Error in last collector was :class org.apache.avro.mapred.AvroKey
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Initialization of all the collectors failed. Error in last collector was :class org.apache.avro.mapred.AvroKey
	at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:415)
	at org.apache.hadoop.mapred.MapTask.access$100(MapTask.java:81)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.<init>(MapTask.java:698)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:770)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ClassCastException: class org.apache.avro.mapred.AvroKey
	at java.lang.Class.asSubclass(Class.java:3404)
	at org.apache.hadoop.mapred.JobConf.getOutputKeyComparator(JobConf.java:887)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:1004)
	at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)
	... 10 more
2016-07-12 17:53:26 Job [INFO] Job job_local901401917_0004 running in uber mode : false
2016-07-12 17:53:26 Job [INFO]  map 0% reduce 0%
2016-07-12 17:53:26 Job [INFO] Job job_local901401917_0004 failed with state FAILED due to: NA
2016-07-12 17:53:26 Job [INFO] Counters: 0
2016-07-12 17:58:07 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 17:58:07 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 17:58:07 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 17:58:08 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:58:08 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:58:08 JobSubmitter [INFO] number of splits:1
2016-07-12 17:58:08 JobSubmitter [INFO] Submitting tokens for job: job_local1308259296_0001
2016-07-12 17:58:08 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:58:08 Job [INFO] Running job: job_local1308259296_0001
2016-07-12 17:58:08 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:58:08 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:58:08 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:58:08 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:58:08 LocalJobRunner [INFO] Starting task: attempt_local1308259296_0001_m_000000_0
2016-07-12 17:58:08 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:58:08 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:58:08 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 17:58:08 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:58:08 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:58:08 MapTask [INFO] soft limit at 83886080
2016-07-12 17:58:08 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:58:08 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:58:08 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:58:09 Job [INFO] Job job_local1308259296_0001 running in uber mode : false
2016-07-12 17:58:09 Job [INFO]  map 0% reduce 0%
2016-07-12 17:58:09 LocalJobRunner [INFO] 
2016-07-12 17:58:09 MapTask [INFO] Starting flush of map output
2016-07-12 17:58:09 MapTask [INFO] Spilling map output
2016-07-12 17:58:09 MapTask [INFO] bufstart = 0; bufend = 1545; bufvoid = 104857600
2016-07-12 17:58:09 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214068(104856272); length = 329/6553600
2016-07-12 17:58:09 MapTask [INFO] Finished spill 0
2016-07-12 17:58:09 Task [INFO] Task:attempt_local1308259296_0001_m_000000_0 is done. And is in the process of committing
2016-07-12 17:58:09 LocalJobRunner [INFO] map
2016-07-12 17:58:09 Task [INFO] Task 'attempt_local1308259296_0001_m_000000_0' done.
2016-07-12 17:58:09 LocalJobRunner [INFO] Finishing task: attempt_local1308259296_0001_m_000000_0
2016-07-12 17:58:09 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:58:09 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:58:09 LocalJobRunner [INFO] Starting task: attempt_local1308259296_0001_r_000000_0
2016-07-12 17:58:09 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:58:09 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:58:09 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@463645d3
2016-07-12 17:58:09 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:58:09 EventFetcher [INFO] attempt_local1308259296_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:58:09 LocalFetcher [INFO] localfetcher#1 about to shuffle output of map attempt_local1308259296_0001_m_000000_0 decomp: 1713 len: 1717 to MEMORY
2016-07-12 17:58:09 InMemoryMapOutput [INFO] Read 1713 bytes from map-output for attempt_local1308259296_0001_m_000000_0
2016-07-12 17:58:09 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1713, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1713
2016-07-12 17:58:09 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:58:09 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:58:09 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:58:09 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:58:09 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:58:09 MergeManagerImpl [INFO] Merged 1 segments, 1713 bytes to disk to satisfy reduce memory limit
2016-07-12 17:58:09 MergeManagerImpl [INFO] Merging 1 files, 1717 bytes from disk
2016-07-12 17:58:09 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:58:09 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:58:09 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 17:58:09 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:58:09 deprecation [INFO] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-07-12 17:58:09 Task [INFO] Task:attempt_local1308259296_0001_r_000000_0 is done. And is in the process of committing
2016-07-12 17:58:09 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:58:09 Task [INFO] Task attempt_local1308259296_0001_r_000000_0 is allowed to commit now
2016-07-12 17:58:09 FileOutputCommitter [INFO] Saved output of task 'attempt_local1308259296_0001_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/_temporary/0/task_local1308259296_0001_r_000000
2016-07-12 17:58:09 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:58:09 Task [INFO] Task 'attempt_local1308259296_0001_r_000000_0' done.
2016-07-12 17:58:09 LocalJobRunner [INFO] Finishing task: attempt_local1308259296_0001_r_000000_0
2016-07-12 17:58:09 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:58:10 Job [INFO]  map 100% reduce 100%
2016-07-12 17:58:10 Job [INFO] Job job_local1308259296_0001 completed successfully
2016-07-12 17:58:10 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=17502
		FILE: Number of bytes written=576366
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=83
		Map output bytes=1545
		Map output materialized bytes=1717
		Input split bytes=144
		Combine input records=0
		Combine output records=0
		Reduce input groups=81
		Reduce shuffle bytes=1717
		Reduce input records=83
		Reduce output records=81
		Spilled Records=166
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=685768704
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6818
	File Output Format Counters 
		Bytes Written=1371
2016-07-12 17:58:10 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:58:10 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:58:10 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:58:10 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:58:10 JobSubmitter [INFO] number of splits:1
2016-07-12 17:58:10 JobSubmitter [INFO] Submitting tokens for job: job_local1935207201_0002
2016-07-12 17:58:10 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:58:10 Job [INFO] Running job: job_local1935207201_0002
2016-07-12 17:58:10 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:58:10 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:58:10 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:58:10 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:58:10 LocalJobRunner [INFO] Starting task: attempt_local1935207201_0002_m_000000_0
2016-07-12 17:58:10 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:58:10 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:58:10 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/part-r-00000:0+1351
2016-07-12 17:58:10 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:58:10 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:58:10 MapTask [INFO] soft limit at 83886080
2016-07-12 17:58:10 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:58:10 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:58:10 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:58:10 LocalJobRunner [INFO] 
2016-07-12 17:58:10 MapTask [INFO] Starting flush of map output
2016-07-12 17:58:10 MapTask [INFO] Spilling map output
2016-07-12 17:58:10 MapTask [INFO] bufstart = 0; bufend = 1351; bufvoid = 104857600
2016-07-12 17:58:10 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 17:58:10 MapTask [INFO] Finished spill 0
2016-07-12 17:58:10 Task [INFO] Task:attempt_local1935207201_0002_m_000000_0 is done. And is in the process of committing
2016-07-12 17:58:10 LocalJobRunner [INFO] map
2016-07-12 17:58:10 Task [INFO] Task 'attempt_local1935207201_0002_m_000000_0' done.
2016-07-12 17:58:10 LocalJobRunner [INFO] Finishing task: attempt_local1935207201_0002_m_000000_0
2016-07-12 17:58:10 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:58:10 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:58:10 LocalJobRunner [INFO] Starting task: attempt_local1935207201_0002_r_000000_0
2016-07-12 17:58:10 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:58:10 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:58:10 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3b1db405
2016-07-12 17:58:10 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:58:10 EventFetcher [INFO] attempt_local1935207201_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:58:10 LocalFetcher [INFO] localfetcher#2 about to shuffle output of map attempt_local1935207201_0002_m_000000_0 decomp: 1515 len: 1519 to MEMORY
2016-07-12 17:58:10 InMemoryMapOutput [INFO] Read 1515 bytes from map-output for attempt_local1935207201_0002_m_000000_0
2016-07-12 17:58:10 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1515, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1515
2016-07-12 17:58:10 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:58:10 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:58:10 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:58:10 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:58:10 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 17:58:10 MergeManagerImpl [INFO] Merged 1 segments, 1515 bytes to disk to satisfy reduce memory limit
2016-07-12 17:58:10 MergeManagerImpl [INFO] Merging 1 files, 1519 bytes from disk
2016-07-12 17:58:10 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:58:10 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:58:10 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 17:58:10 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:58:10 Task [INFO] Task:attempt_local1935207201_0002_r_000000_0 is done. And is in the process of committing
2016-07-12 17:58:10 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:58:10 Task [INFO] Task attempt_local1935207201_0002_r_000000_0 is allowed to commit now
2016-07-12 17:58:10 FileOutputCommitter [INFO] Saved output of task 'attempt_local1935207201_0002_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/_temporary/0/task_local1935207201_0002_r_000000
2016-07-12 17:58:10 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:58:10 Task [INFO] Task 'attempt_local1935207201_0002_r_000000_0' done.
2016-07-12 17:58:10 LocalJobRunner [INFO] Finishing task: attempt_local1935207201_0002_r_000000_0
2016-07-12 17:58:10 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:58:11 Job [INFO] Job job_local1935207201_0002 running in uber mode : false
2016-07-12 17:58:11 Job [INFO]  map 100% reduce 100%
2016-07-12 17:58:11 Job [INFO] Job job_local1935207201_0002 completed successfully
2016-07-12 17:58:11 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=27190
		FILE: Number of bytes written=1149374
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1351
		Map output materialized bytes=1519
		Input split bytes=145
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=1519
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=766509056
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1375
	File Output Format Counters 
		Bytes Written=1533
2016-07-12 17:58:11 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:58:11 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:58:11 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:58:11 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:58:11 JobSubmitter [INFO] number of splits:1
2016-07-12 17:58:12 JobSubmitter [INFO] Submitting tokens for job: job_local1601034187_0003
2016-07-12 17:58:12 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:58:12 Job [INFO] Running job: job_local1601034187_0003
2016-07-12 17:58:12 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:58:12 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:58:12 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:58:12 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:58:12 LocalJobRunner [INFO] Starting task: attempt_local1601034187_0003_m_000000_0
2016-07-12 17:58:12 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:58:12 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:58:12 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/part-r-00000:0+1513
2016-07-12 17:58:12 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:58:12 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:58:12 MapTask [INFO] soft limit at 83886080
2016-07-12 17:58:12 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:58:12 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:58:12 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:58:12 LocalJobRunner [INFO] 
2016-07-12 17:58:12 MapTask [INFO] Starting flush of map output
2016-07-12 17:58:12 MapTask [INFO] Spilling map output
2016-07-12 17:58:12 MapTask [INFO] bufstart = 0; bufend = 1513; bufvoid = 104857600
2016-07-12 17:58:12 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 17:58:12 MapTask [INFO] Finished spill 0
2016-07-12 17:58:12 Task [INFO] Task:attempt_local1601034187_0003_m_000000_0 is done. And is in the process of committing
2016-07-12 17:58:12 LocalJobRunner [INFO] map
2016-07-12 17:58:12 Task [INFO] Task 'attempt_local1601034187_0003_m_000000_0' done.
2016-07-12 17:58:12 LocalJobRunner [INFO] Finishing task: attempt_local1601034187_0003_m_000000_0
2016-07-12 17:58:12 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:58:12 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:58:12 LocalJobRunner [INFO] Starting task: attempt_local1601034187_0003_r_000000_0
2016-07-12 17:58:12 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:58:12 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:58:12 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@74a2f702
2016-07-12 17:58:12 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:58:12 EventFetcher [INFO] attempt_local1601034187_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:58:12 LocalFetcher [INFO] localfetcher#3 about to shuffle output of map attempt_local1601034187_0003_m_000000_0 decomp: 1677 len: 1681 to MEMORY
2016-07-12 17:58:12 InMemoryMapOutput [INFO] Read 1677 bytes from map-output for attempt_local1601034187_0003_m_000000_0
2016-07-12 17:58:12 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1677, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1677
2016-07-12 17:58:12 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:58:12 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:58:12 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:58:12 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:58:12 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 17:58:12 MergeManagerImpl [INFO] Merged 1 segments, 1677 bytes to disk to satisfy reduce memory limit
2016-07-12 17:58:12 MergeManagerImpl [INFO] Merging 1 files, 1681 bytes from disk
2016-07-12 17:58:12 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:58:12 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:58:12 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 17:58:12 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:58:12 Task [INFO] Task:attempt_local1601034187_0003_r_000000_0 is done. And is in the process of committing
2016-07-12 17:58:12 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:58:12 Task [INFO] Task attempt_local1601034187_0003_r_000000_0 is allowed to commit now
2016-07-12 17:58:12 FileOutputCommitter [INFO] Saved output of task 'attempt_local1601034187_0003_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/_temporary/0/task_local1601034187_0003_r_000000
2016-07-12 17:58:12 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:58:12 Task [INFO] Task 'attempt_local1601034187_0003_r_000000_0' done.
2016-07-12 17:58:12 LocalJobRunner [INFO] Finishing task: attempt_local1601034187_0003_r_000000_0
2016-07-12 17:58:12 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:58:13 Job [INFO] Job job_local1601034187_0003 running in uber mode : false
2016-07-12 17:58:13 Job [INFO]  map 100% reduce 100%
2016-07-12 17:58:13 Job [INFO] Job job_local1601034187_0003 completed successfully
2016-07-12 17:58:13 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=37134
		FILE: Number of bytes written=1723286
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1513
		Map output materialized bytes=1681
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=59
		Reduce shuffle bytes=1681
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=85
		Total committed heap usage (bytes)=792199168
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1537
	File Output Format Counters 
		Bytes Written=2079
2016-07-12 17:58:13 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 17:58:13 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 17:58:13 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 17:58:13 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 17:58:13 JobSubmitter [INFO] number of splits:1
2016-07-12 17:58:13 JobSubmitter [INFO] Submitting tokens for job: job_local158058641_0004
2016-07-12 17:58:13 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 17:58:13 Job [INFO] Running job: job_local158058641_0004
2016-07-12 17:58:13 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 17:58:13 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:58:13 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 17:58:13 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 17:58:13 LocalJobRunner [INFO] Starting task: attempt_local158058641_0004_m_000000_0
2016-07-12 17:58:13 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:58:13 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:58:13 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/part-r-00000:0+2051
2016-07-12 17:58:13 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 17:58:13 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 17:58:13 MapTask [INFO] soft limit at 83886080
2016-07-12 17:58:13 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 17:58:13 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 17:58:13 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 17:58:13 LocalJobRunner [INFO] 
2016-07-12 17:58:13 MapTask [INFO] Starting flush of map output
2016-07-12 17:58:13 MapTask [INFO] Spilling map output
2016-07-12 17:58:13 MapTask [INFO] bufstart = 0; bufend = 2051; bufvoid = 104857600
2016-07-12 17:58:13 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 17:58:13 MapTask [INFO] Finished spill 0
2016-07-12 17:58:13 Task [INFO] Task:attempt_local158058641_0004_m_000000_0 is done. And is in the process of committing
2016-07-12 17:58:13 LocalJobRunner [INFO] map
2016-07-12 17:58:13 Task [INFO] Task 'attempt_local158058641_0004_m_000000_0' done.
2016-07-12 17:58:13 LocalJobRunner [INFO] Finishing task: attempt_local158058641_0004_m_000000_0
2016-07-12 17:58:13 LocalJobRunner [INFO] map task executor complete.
2016-07-12 17:58:13 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 17:58:13 LocalJobRunner [INFO] Starting task: attempt_local158058641_0004_r_000000_0
2016-07-12 17:58:13 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 17:58:13 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 17:58:13 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7a42566a
2016-07-12 17:58:13 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 17:58:13 EventFetcher [INFO] attempt_local158058641_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 17:58:13 LocalFetcher [INFO] localfetcher#4 about to shuffle output of map attempt_local158058641_0004_m_000000_0 decomp: 2215 len: 2219 to MEMORY
2016-07-12 17:58:13 InMemoryMapOutput [INFO] Read 2215 bytes from map-output for attempt_local158058641_0004_m_000000_0
2016-07-12 17:58:13 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 2215, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2215
2016-07-12 17:58:13 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 17:58:13 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:58:13 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 17:58:13 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:58:13 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 2204 bytes
2016-07-12 17:58:13 MergeManagerImpl [INFO] Merged 1 segments, 2215 bytes to disk to satisfy reduce memory limit
2016-07-12 17:58:13 MergeManagerImpl [INFO] Merging 1 files, 2219 bytes from disk
2016-07-12 17:58:13 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 17:58:13 Merger [INFO] Merging 1 sorted segments
2016-07-12 17:58:13 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 2204 bytes
2016-07-12 17:58:13 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:58:13 Task [INFO] Task:attempt_local158058641_0004_r_000000_0 is done. And is in the process of committing
2016-07-12 17:58:13 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 17:58:13 Task [INFO] Task attempt_local158058641_0004_r_000000_0 is allowed to commit now
2016-07-12 17:58:13 FileOutputCommitter [INFO] Saved output of task 'attempt_local158058641_0004_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/4-tf-idf-document/_temporary/0/task_local158058641_0004_r_000000
2016-07-12 17:58:13 LocalJobRunner [INFO] reduce > reduce
2016-07-12 17:58:13 Task [INFO] Task 'attempt_local158058641_0004_r_000000_0' done.
2016-07-12 17:58:13 LocalJobRunner [INFO] Finishing task: attempt_local158058641_0004_r_000000_0
2016-07-12 17:58:13 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 17:58:14 Job [INFO] Job job_local158058641_0004 running in uber mode : false
2016-07-12 17:58:14 Job [INFO]  map 100% reduce 100%
2016-07-12 17:58:14 Job [INFO] Job job_local158058641_0004 completed successfully
2016-07-12 17:58:14 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=49560
		FILE: Number of bytes written=2297367
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=2051
		Map output materialized bytes=2219
		Input split bytes=142
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=2219
		Reduce input records=81
		Reduce output records=19
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=805306368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2083
	File Output Format Counters 
		Bytes Written=2828
2016-07-12 18:11:23 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 18:11:24 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 18:11:24 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 18:11:24 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 18:11:24 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 18:11:24 JobSubmitter [INFO] number of splits:1
2016-07-12 18:11:24 JobSubmitter [INFO] Submitting tokens for job: job_local1391502426_0001
2016-07-12 18:11:24 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 18:11:24 Job [INFO] Running job: job_local1391502426_0001
2016-07-12 18:11:24 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 18:11:24 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:11:24 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 18:11:24 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 18:11:24 LocalJobRunner [INFO] Starting task: attempt_local1391502426_0001_m_000000_0
2016-07-12 18:11:24 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:11:24 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:11:24 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 18:11:24 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 18:11:24 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 18:11:24 MapTask [INFO] soft limit at 83886080
2016-07-12 18:11:24 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 18:11:24 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 18:11:24 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 18:11:25 Job [INFO] Job job_local1391502426_0001 running in uber mode : false
2016-07-12 18:11:25 Job [INFO]  map 0% reduce 0%
2016-07-12 18:11:25 LocalJobRunner [INFO] 
2016-07-12 18:11:25 MapTask [INFO] Starting flush of map output
2016-07-12 18:11:25 MapTask [INFO] Spilling map output
2016-07-12 18:11:25 MapTask [INFO] bufstart = 0; bufend = 1545; bufvoid = 104857600
2016-07-12 18:11:25 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214068(104856272); length = 329/6553600
2016-07-12 18:11:25 MapTask [INFO] Finished spill 0
2016-07-12 18:11:25 Task [INFO] Task:attempt_local1391502426_0001_m_000000_0 is done. And is in the process of committing
2016-07-12 18:11:25 LocalJobRunner [INFO] map
2016-07-12 18:11:25 Task [INFO] Task 'attempt_local1391502426_0001_m_000000_0' done.
2016-07-12 18:11:25 LocalJobRunner [INFO] Finishing task: attempt_local1391502426_0001_m_000000_0
2016-07-12 18:11:25 LocalJobRunner [INFO] map task executor complete.
2016-07-12 18:11:25 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 18:11:25 LocalJobRunner [INFO] Starting task: attempt_local1391502426_0001_r_000000_0
2016-07-12 18:11:25 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:11:25 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:11:25 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@362ba72a
2016-07-12 18:11:25 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 18:11:25 EventFetcher [INFO] attempt_local1391502426_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 18:11:25 LocalFetcher [INFO] localfetcher#1 about to shuffle output of map attempt_local1391502426_0001_m_000000_0 decomp: 1713 len: 1717 to MEMORY
2016-07-12 18:11:25 InMemoryMapOutput [INFO] Read 1713 bytes from map-output for attempt_local1391502426_0001_m_000000_0
2016-07-12 18:11:25 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1713, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1713
2016-07-12 18:11:25 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 18:11:25 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:11:25 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 18:11:25 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:11:25 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 18:11:25 MergeManagerImpl [INFO] Merged 1 segments, 1713 bytes to disk to satisfy reduce memory limit
2016-07-12 18:11:25 MergeManagerImpl [INFO] Merging 1 files, 1717 bytes from disk
2016-07-12 18:11:25 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 18:11:25 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:11:25 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 18:11:25 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:11:25 deprecation [INFO] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-07-12 18:11:25 Task [INFO] Task:attempt_local1391502426_0001_r_000000_0 is done. And is in the process of committing
2016-07-12 18:11:25 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:11:25 Task [INFO] Task attempt_local1391502426_0001_r_000000_0 is allowed to commit now
2016-07-12 18:11:25 FileOutputCommitter [INFO] Saved output of task 'attempt_local1391502426_0001_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/_temporary/0/task_local1391502426_0001_r_000000
2016-07-12 18:11:25 LocalJobRunner [INFO] reduce > reduce
2016-07-12 18:11:25 Task [INFO] Task 'attempt_local1391502426_0001_r_000000_0' done.
2016-07-12 18:11:25 LocalJobRunner [INFO] Finishing task: attempt_local1391502426_0001_r_000000_0
2016-07-12 18:11:25 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 18:11:26 Job [INFO]  map 100% reduce 100%
2016-07-12 18:11:26 Job [INFO] Job job_local1391502426_0001 completed successfully
2016-07-12 18:11:26 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=17502
		FILE: Number of bytes written=576366
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=83
		Map output bytes=1545
		Map output materialized bytes=1717
		Input split bytes=144
		Combine input records=0
		Combine output records=0
		Reduce input groups=81
		Reduce shuffle bytes=1717
		Reduce input records=83
		Reduce output records=81
		Spilled Records=166
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=846200832
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6818
	File Output Format Counters 
		Bytes Written=1371
2016-07-12 18:11:26 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 18:11:26 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 18:11:26 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 18:11:26 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 18:11:26 JobSubmitter [INFO] number of splits:1
2016-07-12 18:11:26 JobSubmitter [INFO] Submitting tokens for job: job_local1621036812_0002
2016-07-12 18:11:26 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 18:11:26 Job [INFO] Running job: job_local1621036812_0002
2016-07-12 18:11:26 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 18:11:26 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:11:26 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 18:11:26 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 18:11:26 LocalJobRunner [INFO] Starting task: attempt_local1621036812_0002_m_000000_0
2016-07-12 18:11:26 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:11:26 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:11:26 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/part-r-00000:0+1351
2016-07-12 18:11:26 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 18:11:26 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 18:11:26 MapTask [INFO] soft limit at 83886080
2016-07-12 18:11:26 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 18:11:26 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 18:11:26 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 18:11:26 LocalJobRunner [INFO] 
2016-07-12 18:11:26 MapTask [INFO] Starting flush of map output
2016-07-12 18:11:26 MapTask [INFO] Spilling map output
2016-07-12 18:11:26 MapTask [INFO] bufstart = 0; bufend = 1351; bufvoid = 104857600
2016-07-12 18:11:26 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 18:11:26 MapTask [INFO] Finished spill 0
2016-07-12 18:11:26 Task [INFO] Task:attempt_local1621036812_0002_m_000000_0 is done. And is in the process of committing
2016-07-12 18:11:26 LocalJobRunner [INFO] map
2016-07-12 18:11:26 Task [INFO] Task 'attempt_local1621036812_0002_m_000000_0' done.
2016-07-12 18:11:26 LocalJobRunner [INFO] Finishing task: attempt_local1621036812_0002_m_000000_0
2016-07-12 18:11:26 LocalJobRunner [INFO] map task executor complete.
2016-07-12 18:11:26 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 18:11:26 LocalJobRunner [INFO] Starting task: attempt_local1621036812_0002_r_000000_0
2016-07-12 18:11:26 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:11:26 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:11:26 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3d7bcec5
2016-07-12 18:11:26 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 18:11:26 EventFetcher [INFO] attempt_local1621036812_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 18:11:26 LocalFetcher [INFO] localfetcher#2 about to shuffle output of map attempt_local1621036812_0002_m_000000_0 decomp: 1515 len: 1519 to MEMORY
2016-07-12 18:11:26 InMemoryMapOutput [INFO] Read 1515 bytes from map-output for attempt_local1621036812_0002_m_000000_0
2016-07-12 18:11:26 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1515, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1515
2016-07-12 18:11:26 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 18:11:26 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:11:26 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 18:11:26 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:11:26 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 18:11:26 MergeManagerImpl [INFO] Merged 1 segments, 1515 bytes to disk to satisfy reduce memory limit
2016-07-12 18:11:26 MergeManagerImpl [INFO] Merging 1 files, 1519 bytes from disk
2016-07-12 18:11:26 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 18:11:26 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:11:26 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 18:11:26 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:11:27 Task [INFO] Task:attempt_local1621036812_0002_r_000000_0 is done. And is in the process of committing
2016-07-12 18:11:27 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:11:27 Task [INFO] Task attempt_local1621036812_0002_r_000000_0 is allowed to commit now
2016-07-12 18:11:27 FileOutputCommitter [INFO] Saved output of task 'attempt_local1621036812_0002_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/_temporary/0/task_local1621036812_0002_r_000000
2016-07-12 18:11:27 LocalJobRunner [INFO] reduce > reduce
2016-07-12 18:11:27 Task [INFO] Task 'attempt_local1621036812_0002_r_000000_0' done.
2016-07-12 18:11:27 LocalJobRunner [INFO] Finishing task: attempt_local1621036812_0002_r_000000_0
2016-07-12 18:11:27 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 18:11:27 Job [INFO] Job job_local1621036812_0002 running in uber mode : false
2016-07-12 18:11:27 Job [INFO]  map 100% reduce 100%
2016-07-12 18:11:27 Job [INFO] Job job_local1621036812_0002 completed successfully
2016-07-12 18:11:27 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=27190
		FILE: Number of bytes written=1149374
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1351
		Map output materialized bytes=1519
		Input split bytes=145
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=1519
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1063256064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1375
	File Output Format Counters 
		Bytes Written=1533
2016-07-12 18:11:27 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 18:11:27 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 18:11:27 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 18:11:27 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 18:11:27 JobSubmitter [INFO] number of splits:1
2016-07-12 18:11:27 JobSubmitter [INFO] Submitting tokens for job: job_local1957341680_0003
2016-07-12 18:11:28 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 18:11:28 Job [INFO] Running job: job_local1957341680_0003
2016-07-12 18:11:28 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 18:11:28 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:11:28 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 18:11:28 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 18:11:28 LocalJobRunner [INFO] Starting task: attempt_local1957341680_0003_m_000000_0
2016-07-12 18:11:28 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:11:28 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:11:28 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/part-r-00000:0+1513
2016-07-12 18:11:28 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 18:11:28 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 18:11:28 MapTask [INFO] soft limit at 83886080
2016-07-12 18:11:28 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 18:11:28 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 18:11:28 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 18:11:28 LocalJobRunner [INFO] 
2016-07-12 18:11:28 MapTask [INFO] Starting flush of map output
2016-07-12 18:11:28 MapTask [INFO] Spilling map output
2016-07-12 18:11:28 MapTask [INFO] bufstart = 0; bufend = 1513; bufvoid = 104857600
2016-07-12 18:11:28 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 18:11:28 MapTask [INFO] Finished spill 0
2016-07-12 18:11:28 Task [INFO] Task:attempt_local1957341680_0003_m_000000_0 is done. And is in the process of committing
2016-07-12 18:11:28 LocalJobRunner [INFO] map
2016-07-12 18:11:28 Task [INFO] Task 'attempt_local1957341680_0003_m_000000_0' done.
2016-07-12 18:11:28 LocalJobRunner [INFO] Finishing task: attempt_local1957341680_0003_m_000000_0
2016-07-12 18:11:28 LocalJobRunner [INFO] map task executor complete.
2016-07-12 18:11:28 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 18:11:28 LocalJobRunner [INFO] Starting task: attempt_local1957341680_0003_r_000000_0
2016-07-12 18:11:28 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:11:28 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:11:28 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@461e80f6
2016-07-12 18:11:28 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 18:11:28 EventFetcher [INFO] attempt_local1957341680_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 18:11:28 LocalFetcher [INFO] localfetcher#3 about to shuffle output of map attempt_local1957341680_0003_m_000000_0 decomp: 1677 len: 1681 to MEMORY
2016-07-12 18:11:28 InMemoryMapOutput [INFO] Read 1677 bytes from map-output for attempt_local1957341680_0003_m_000000_0
2016-07-12 18:11:28 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1677, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1677
2016-07-12 18:11:28 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 18:11:28 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:11:28 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 18:11:28 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:11:28 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 18:11:28 MergeManagerImpl [INFO] Merged 1 segments, 1677 bytes to disk to satisfy reduce memory limit
2016-07-12 18:11:28 MergeManagerImpl [INFO] Merging 1 files, 1681 bytes from disk
2016-07-12 18:11:28 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 18:11:28 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:11:28 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 18:11:28 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:11:28 Task [INFO] Task:attempt_local1957341680_0003_r_000000_0 is done. And is in the process of committing
2016-07-12 18:11:28 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:11:28 Task [INFO] Task attempt_local1957341680_0003_r_000000_0 is allowed to commit now
2016-07-12 18:11:28 FileOutputCommitter [INFO] Saved output of task 'attempt_local1957341680_0003_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/_temporary/0/task_local1957341680_0003_r_000000
2016-07-12 18:11:28 LocalJobRunner [INFO] reduce > reduce
2016-07-12 18:11:28 Task [INFO] Task 'attempt_local1957341680_0003_r_000000_0' done.
2016-07-12 18:11:28 LocalJobRunner [INFO] Finishing task: attempt_local1957341680_0003_r_000000_0
2016-07-12 18:11:28 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 18:11:29 Job [INFO] Job job_local1957341680_0003 running in uber mode : false
2016-07-12 18:11:29 Job [INFO]  map 100% reduce 100%
2016-07-12 18:11:29 Job [INFO] Job job_local1957341680_0003 completed successfully
2016-07-12 18:11:29 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=37134
		FILE: Number of bytes written=1723286
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1513
		Map output materialized bytes=1681
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=59
		Reduce shuffle bytes=1681
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=868220928
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1537
	File Output Format Counters 
		Bytes Written=2079
2016-07-12 18:11:29 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 18:11:29 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 18:11:29 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 18:11:29 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 18:11:29 JobSubmitter [INFO] number of splits:1
2016-07-12 18:11:30 JobSubmitter [INFO] Submitting tokens for job: job_local1983930142_0004
2016-07-12 18:11:30 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 18:11:30 Job [INFO] Running job: job_local1983930142_0004
2016-07-12 18:11:30 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 18:11:30 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:11:30 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 18:11:30 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 18:11:30 LocalJobRunner [INFO] Starting task: attempt_local1983930142_0004_m_000000_0
2016-07-12 18:11:30 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:11:30 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:11:30 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/part-r-00000:0+2051
2016-07-12 18:11:30 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 18:11:30 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 18:11:30 MapTask [INFO] soft limit at 83886080
2016-07-12 18:11:30 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 18:11:30 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 18:11:30 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 18:11:30 LocalJobRunner [INFO] 
2016-07-12 18:11:30 MapTask [INFO] Starting flush of map output
2016-07-12 18:11:30 MapTask [INFO] Spilling map output
2016-07-12 18:11:30 MapTask [INFO] bufstart = 0; bufend = 2051; bufvoid = 104857600
2016-07-12 18:11:30 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 18:11:30 MapTask [INFO] Finished spill 0
2016-07-12 18:11:30 Task [INFO] Task:attempt_local1983930142_0004_m_000000_0 is done. And is in the process of committing
2016-07-12 18:11:30 LocalJobRunner [INFO] map
2016-07-12 18:11:30 Task [INFO] Task 'attempt_local1983930142_0004_m_000000_0' done.
2016-07-12 18:11:30 LocalJobRunner [INFO] Finishing task: attempt_local1983930142_0004_m_000000_0
2016-07-12 18:11:30 LocalJobRunner [INFO] map task executor complete.
2016-07-12 18:11:30 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 18:11:30 LocalJobRunner [INFO] Starting task: attempt_local1983930142_0004_r_000000_0
2016-07-12 18:11:30 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:11:30 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:11:30 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@548cab9e
2016-07-12 18:11:30 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 18:11:30 EventFetcher [INFO] attempt_local1983930142_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 18:11:30 LocalFetcher [INFO] localfetcher#4 about to shuffle output of map attempt_local1983930142_0004_m_000000_0 decomp: 2215 len: 2219 to MEMORY
2016-07-12 18:11:30 InMemoryMapOutput [INFO] Read 2215 bytes from map-output for attempt_local1983930142_0004_m_000000_0
2016-07-12 18:11:30 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 2215, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2215
2016-07-12 18:11:30 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 18:11:30 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:11:30 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 18:11:30 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:11:30 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 2204 bytes
2016-07-12 18:11:30 MergeManagerImpl [INFO] Merged 1 segments, 2215 bytes to disk to satisfy reduce memory limit
2016-07-12 18:11:30 MergeManagerImpl [INFO] Merging 1 files, 2219 bytes from disk
2016-07-12 18:11:30 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 18:11:30 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:11:30 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 2204 bytes
2016-07-12 18:11:30 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:11:30 Task [INFO] Task:attempt_local1983930142_0004_r_000000_0 is done. And is in the process of committing
2016-07-12 18:11:30 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:11:30 Task [INFO] Task attempt_local1983930142_0004_r_000000_0 is allowed to commit now
2016-07-12 18:11:30 FileOutputCommitter [INFO] Saved output of task 'attempt_local1983930142_0004_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/4-tf-idf-document/_temporary/0/task_local1983930142_0004_r_000000
2016-07-12 18:11:30 LocalJobRunner [INFO] reduce > reduce
2016-07-12 18:11:30 Task [INFO] Task 'attempt_local1983930142_0004_r_000000_0' done.
2016-07-12 18:11:30 LocalJobRunner [INFO] Finishing task: attempt_local1983930142_0004_r_000000_0
2016-07-12 18:11:30 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 18:11:31 Job [INFO] Job job_local1983930142_0004 running in uber mode : false
2016-07-12 18:11:31 Job [INFO]  map 100% reduce 100%
2016-07-12 18:11:31 Job [INFO] Job job_local1983930142_0004 completed successfully
2016-07-12 18:11:31 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=49560
		FILE: Number of bytes written=2299082
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=2051
		Map output materialized bytes=2219
		Input split bytes=142
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=2219
		Reduce input records=81
		Reduce output records=19
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=879755264
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2083
	File Output Format Counters 
		Bytes Written=1551
2016-07-12 18:13:25 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 18:13:25 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 18:13:25 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 18:13:25 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 18:13:25 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 18:13:25 JobSubmitter [INFO] number of splits:1
2016-07-12 18:13:26 JobSubmitter [INFO] Submitting tokens for job: job_local1033664982_0001
2016-07-12 18:13:26 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 18:13:26 Job [INFO] Running job: job_local1033664982_0001
2016-07-12 18:13:26 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 18:13:26 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:13:26 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 18:13:26 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 18:13:26 LocalJobRunner [INFO] Starting task: attempt_local1033664982_0001_m_000000_0
2016-07-12 18:13:26 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:13:26 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:13:26 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 18:13:26 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 18:13:26 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 18:13:26 MapTask [INFO] soft limit at 83886080
2016-07-12 18:13:26 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 18:13:26 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 18:13:26 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 18:13:27 Job [INFO] Job job_local1033664982_0001 running in uber mode : false
2016-07-12 18:13:27 Job [INFO]  map 0% reduce 0%
2016-07-12 18:13:27 LocalJobRunner [INFO] 
2016-07-12 18:13:27 MapTask [INFO] Starting flush of map output
2016-07-12 18:13:27 MapTask [INFO] Spilling map output
2016-07-12 18:13:27 MapTask [INFO] bufstart = 0; bufend = 1545; bufvoid = 104857600
2016-07-12 18:13:27 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214068(104856272); length = 329/6553600
2016-07-12 18:13:27 MapTask [INFO] Finished spill 0
2016-07-12 18:13:27 Task [INFO] Task:attempt_local1033664982_0001_m_000000_0 is done. And is in the process of committing
2016-07-12 18:13:27 LocalJobRunner [INFO] map
2016-07-12 18:13:27 Task [INFO] Task 'attempt_local1033664982_0001_m_000000_0' done.
2016-07-12 18:13:27 LocalJobRunner [INFO] Finishing task: attempt_local1033664982_0001_m_000000_0
2016-07-12 18:13:27 LocalJobRunner [INFO] map task executor complete.
2016-07-12 18:13:27 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 18:13:27 LocalJobRunner [INFO] Starting task: attempt_local1033664982_0001_r_000000_0
2016-07-12 18:13:27 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:13:27 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:13:27 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5e033565
2016-07-12 18:13:27 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 18:13:27 EventFetcher [INFO] attempt_local1033664982_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 18:13:27 LocalFetcher [INFO] localfetcher#1 about to shuffle output of map attempt_local1033664982_0001_m_000000_0 decomp: 1713 len: 1717 to MEMORY
2016-07-12 18:13:27 InMemoryMapOutput [INFO] Read 1713 bytes from map-output for attempt_local1033664982_0001_m_000000_0
2016-07-12 18:13:27 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1713, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1713
2016-07-12 18:13:27 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 18:13:27 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:13:27 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 18:13:27 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:13:27 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 18:13:27 MergeManagerImpl [INFO] Merged 1 segments, 1713 bytes to disk to satisfy reduce memory limit
2016-07-12 18:13:27 MergeManagerImpl [INFO] Merging 1 files, 1717 bytes from disk
2016-07-12 18:13:27 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 18:13:27 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:13:27 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 18:13:27 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:13:27 deprecation [INFO] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-07-12 18:13:27 Task [INFO] Task:attempt_local1033664982_0001_r_000000_0 is done. And is in the process of committing
2016-07-12 18:13:27 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:13:27 Task [INFO] Task attempt_local1033664982_0001_r_000000_0 is allowed to commit now
2016-07-12 18:13:27 FileOutputCommitter [INFO] Saved output of task 'attempt_local1033664982_0001_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/_temporary/0/task_local1033664982_0001_r_000000
2016-07-12 18:13:27 LocalJobRunner [INFO] reduce > reduce
2016-07-12 18:13:27 Task [INFO] Task 'attempt_local1033664982_0001_r_000000_0' done.
2016-07-12 18:13:27 LocalJobRunner [INFO] Finishing task: attempt_local1033664982_0001_r_000000_0
2016-07-12 18:13:27 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 18:13:28 Job [INFO]  map 100% reduce 100%
2016-07-12 18:13:28 Job [INFO] Job job_local1033664982_0001 completed successfully
2016-07-12 18:13:28 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=17502
		FILE: Number of bytes written=576366
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=83
		Map output bytes=1545
		Map output materialized bytes=1717
		Input split bytes=144
		Combine input records=0
		Combine output records=0
		Reduce input groups=81
		Reduce shuffle bytes=1717
		Reduce input records=83
		Reduce output records=81
		Spilled Records=166
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=144
		Total committed heap usage (bytes)=702545920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6818
	File Output Format Counters 
		Bytes Written=1371
2016-07-12 18:13:28 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 18:13:28 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 18:13:28 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 18:13:28 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 18:13:28 JobSubmitter [INFO] number of splits:1
2016-07-12 18:13:28 JobSubmitter [INFO] Submitting tokens for job: job_local45540535_0002
2016-07-12 18:13:28 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 18:13:28 Job [INFO] Running job: job_local45540535_0002
2016-07-12 18:13:28 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 18:13:28 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:13:28 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 18:13:28 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 18:13:28 LocalJobRunner [INFO] Starting task: attempt_local45540535_0002_m_000000_0
2016-07-12 18:13:28 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:13:28 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:13:28 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/part-r-00000:0+1351
2016-07-12 18:13:28 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 18:13:28 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 18:13:28 MapTask [INFO] soft limit at 83886080
2016-07-12 18:13:28 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 18:13:28 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 18:13:28 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 18:13:28 LocalJobRunner [INFO] 
2016-07-12 18:13:28 MapTask [INFO] Starting flush of map output
2016-07-12 18:13:28 MapTask [INFO] Spilling map output
2016-07-12 18:13:28 MapTask [INFO] bufstart = 0; bufend = 1351; bufvoid = 104857600
2016-07-12 18:13:28 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 18:13:28 MapTask [INFO] Finished spill 0
2016-07-12 18:13:28 Task [INFO] Task:attempt_local45540535_0002_m_000000_0 is done. And is in the process of committing
2016-07-12 18:13:28 LocalJobRunner [INFO] map
2016-07-12 18:13:28 Task [INFO] Task 'attempt_local45540535_0002_m_000000_0' done.
2016-07-12 18:13:28 LocalJobRunner [INFO] Finishing task: attempt_local45540535_0002_m_000000_0
2016-07-12 18:13:28 LocalJobRunner [INFO] map task executor complete.
2016-07-12 18:13:28 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 18:13:28 LocalJobRunner [INFO] Starting task: attempt_local45540535_0002_r_000000_0
2016-07-12 18:13:28 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:13:28 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:13:28 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@60c5a4be
2016-07-12 18:13:28 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 18:13:28 EventFetcher [INFO] attempt_local45540535_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 18:13:28 LocalFetcher [INFO] localfetcher#2 about to shuffle output of map attempt_local45540535_0002_m_000000_0 decomp: 1515 len: 1519 to MEMORY
2016-07-12 18:13:28 InMemoryMapOutput [INFO] Read 1515 bytes from map-output for attempt_local45540535_0002_m_000000_0
2016-07-12 18:13:28 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1515, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1515
2016-07-12 18:13:28 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 18:13:28 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:13:28 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 18:13:28 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:13:28 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 18:13:28 MergeManagerImpl [INFO] Merged 1 segments, 1515 bytes to disk to satisfy reduce memory limit
2016-07-12 18:13:28 MergeManagerImpl [INFO] Merging 1 files, 1519 bytes from disk
2016-07-12 18:13:28 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 18:13:28 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:13:28 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 18:13:28 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:13:28 Task [INFO] Task:attempt_local45540535_0002_r_000000_0 is done. And is in the process of committing
2016-07-12 18:13:28 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:13:28 Task [INFO] Task attempt_local45540535_0002_r_000000_0 is allowed to commit now
2016-07-12 18:13:28 FileOutputCommitter [INFO] Saved output of task 'attempt_local45540535_0002_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/_temporary/0/task_local45540535_0002_r_000000
2016-07-12 18:13:28 LocalJobRunner [INFO] reduce > reduce
2016-07-12 18:13:28 Task [INFO] Task 'attempt_local45540535_0002_r_000000_0' done.
2016-07-12 18:13:28 LocalJobRunner [INFO] Finishing task: attempt_local45540535_0002_r_000000_0
2016-07-12 18:13:28 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 18:13:29 Job [INFO] Job job_local45540535_0002 running in uber mode : false
2016-07-12 18:13:29 Job [INFO]  map 100% reduce 100%
2016-07-12 18:13:29 Job [INFO] Job job_local45540535_0002 completed successfully
2016-07-12 18:13:29 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=27190
		FILE: Number of bytes written=1143390
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1351
		Map output materialized bytes=1519
		Input split bytes=145
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=1519
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=792723456
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1375
	File Output Format Counters 
		Bytes Written=1533
2016-07-12 18:13:29 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 18:13:29 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 18:13:29 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 18:13:29 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 18:13:29 JobSubmitter [INFO] number of splits:1
2016-07-12 18:13:29 JobSubmitter [INFO] Submitting tokens for job: job_local1780211629_0003
2016-07-12 18:13:29 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 18:13:29 Job [INFO] Running job: job_local1780211629_0003
2016-07-12 18:13:29 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 18:13:29 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:13:29 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 18:13:29 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 18:13:29 LocalJobRunner [INFO] Starting task: attempt_local1780211629_0003_m_000000_0
2016-07-12 18:13:29 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:13:29 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:13:29 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/part-r-00000:0+1513
2016-07-12 18:13:29 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 18:13:29 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 18:13:29 MapTask [INFO] soft limit at 83886080
2016-07-12 18:13:29 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 18:13:29 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 18:13:29 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 18:13:29 LocalJobRunner [INFO] 
2016-07-12 18:13:29 MapTask [INFO] Starting flush of map output
2016-07-12 18:13:29 MapTask [INFO] Spilling map output
2016-07-12 18:13:29 MapTask [INFO] bufstart = 0; bufend = 1513; bufvoid = 104857600
2016-07-12 18:13:29 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 18:13:29 MapTask [INFO] Finished spill 0
2016-07-12 18:13:29 Task [INFO] Task:attempt_local1780211629_0003_m_000000_0 is done. And is in the process of committing
2016-07-12 18:13:29 LocalJobRunner [INFO] map
2016-07-12 18:13:29 Task [INFO] Task 'attempt_local1780211629_0003_m_000000_0' done.
2016-07-12 18:13:29 LocalJobRunner [INFO] Finishing task: attempt_local1780211629_0003_m_000000_0
2016-07-12 18:13:29 LocalJobRunner [INFO] map task executor complete.
2016-07-12 18:13:29 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 18:13:29 LocalJobRunner [INFO] Starting task: attempt_local1780211629_0003_r_000000_0
2016-07-12 18:13:29 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:13:29 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:13:29 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@34381f64
2016-07-12 18:13:29 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 18:13:29 EventFetcher [INFO] attempt_local1780211629_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 18:13:29 LocalFetcher [INFO] localfetcher#3 about to shuffle output of map attempt_local1780211629_0003_m_000000_0 decomp: 1677 len: 1681 to MEMORY
2016-07-12 18:13:29 InMemoryMapOutput [INFO] Read 1677 bytes from map-output for attempt_local1780211629_0003_m_000000_0
2016-07-12 18:13:29 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1677, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1677
2016-07-12 18:13:29 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 18:13:29 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:13:29 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 18:13:29 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:13:29 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 18:13:29 MergeManagerImpl [INFO] Merged 1 segments, 1677 bytes to disk to satisfy reduce memory limit
2016-07-12 18:13:29 MergeManagerImpl [INFO] Merging 1 files, 1681 bytes from disk
2016-07-12 18:13:29 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 18:13:29 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:13:29 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 18:13:29 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:13:29 Task [INFO] Task:attempt_local1780211629_0003_r_000000_0 is done. And is in the process of committing
2016-07-12 18:13:29 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:13:29 Task [INFO] Task attempt_local1780211629_0003_r_000000_0 is allowed to commit now
2016-07-12 18:13:29 FileOutputCommitter [INFO] Saved output of task 'attempt_local1780211629_0003_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/_temporary/0/task_local1780211629_0003_r_000000
2016-07-12 18:13:29 LocalJobRunner [INFO] reduce > reduce
2016-07-12 18:13:29 Task [INFO] Task 'attempt_local1780211629_0003_r_000000_0' done.
2016-07-12 18:13:29 LocalJobRunner [INFO] Finishing task: attempt_local1780211629_0003_r_000000_0
2016-07-12 18:13:29 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 18:13:30 Job [INFO] Job job_local1780211629_0003 running in uber mode : false
2016-07-12 18:13:30 Job [INFO]  map 100% reduce 100%
2016-07-12 18:13:30 Job [INFO] Job job_local1780211629_0003 completed successfully
2016-07-12 18:13:30 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=37134
		FILE: Number of bytes written=1717302
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1513
		Map output materialized bytes=1681
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=59
		Reduce shuffle bytes=1681
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=803209216
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1537
	File Output Format Counters 
		Bytes Written=2079
2016-07-12 18:13:30 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 18:13:30 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 18:13:30 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 18:13:30 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 18:13:31 JobSubmitter [INFO] number of splits:1
2016-07-12 18:13:31 JobSubmitter [INFO] Submitting tokens for job: job_local1000050779_0004
2016-07-12 18:13:31 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 18:13:31 Job [INFO] Running job: job_local1000050779_0004
2016-07-12 18:13:31 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 18:13:31 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:13:31 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 18:13:31 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 18:13:31 LocalJobRunner [INFO] Starting task: attempt_local1000050779_0004_m_000000_0
2016-07-12 18:13:31 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:13:31 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:13:31 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/part-r-00000:0+2051
2016-07-12 18:13:31 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 18:13:31 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 18:13:31 MapTask [INFO] soft limit at 83886080
2016-07-12 18:13:31 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 18:13:31 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 18:13:31 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 18:13:31 LocalJobRunner [INFO] 
2016-07-12 18:13:31 MapTask [INFO] Starting flush of map output
2016-07-12 18:13:31 MapTask [INFO] Spilling map output
2016-07-12 18:13:31 MapTask [INFO] bufstart = 0; bufend = 2051; bufvoid = 104857600
2016-07-12 18:13:31 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 18:13:31 MapTask [INFO] Finished spill 0
2016-07-12 18:13:31 Task [INFO] Task:attempt_local1000050779_0004_m_000000_0 is done. And is in the process of committing
2016-07-12 18:13:31 LocalJobRunner [INFO] map
2016-07-12 18:13:31 Task [INFO] Task 'attempt_local1000050779_0004_m_000000_0' done.
2016-07-12 18:13:31 LocalJobRunner [INFO] Finishing task: attempt_local1000050779_0004_m_000000_0
2016-07-12 18:13:31 LocalJobRunner [INFO] map task executor complete.
2016-07-12 18:13:31 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 18:13:31 LocalJobRunner [INFO] Starting task: attempt_local1000050779_0004_r_000000_0
2016-07-12 18:13:31 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:13:31 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:13:31 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4e6d27d6
2016-07-12 18:13:31 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 18:13:31 EventFetcher [INFO] attempt_local1000050779_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 18:13:31 LocalFetcher [INFO] localfetcher#4 about to shuffle output of map attempt_local1000050779_0004_m_000000_0 decomp: 2215 len: 2219 to MEMORY
2016-07-12 18:13:31 InMemoryMapOutput [INFO] Read 2215 bytes from map-output for attempt_local1000050779_0004_m_000000_0
2016-07-12 18:13:31 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 2215, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2215
2016-07-12 18:13:31 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 18:13:31 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:13:31 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 18:13:31 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:13:31 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 2204 bytes
2016-07-12 18:13:31 MergeManagerImpl [INFO] Merged 1 segments, 2215 bytes to disk to satisfy reduce memory limit
2016-07-12 18:13:31 MergeManagerImpl [INFO] Merging 1 files, 2219 bytes from disk
2016-07-12 18:13:31 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 18:13:31 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:13:31 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 2204 bytes
2016-07-12 18:13:31 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:13:31 Task [INFO] Task:attempt_local1000050779_0004_r_000000_0 is done. And is in the process of committing
2016-07-12 18:13:31 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:13:31 Task [INFO] Task attempt_local1000050779_0004_r_000000_0 is allowed to commit now
2016-07-12 18:13:31 FileOutputCommitter [INFO] Saved output of task 'attempt_local1000050779_0004_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/4-tf-idf-document/_temporary/0/task_local1000050779_0004_r_000000
2016-07-12 18:13:31 LocalJobRunner [INFO] reduce > reduce
2016-07-12 18:13:31 Task [INFO] Task 'attempt_local1000050779_0004_r_000000_0' done.
2016-07-12 18:13:31 LocalJobRunner [INFO] Finishing task: attempt_local1000050779_0004_r_000000_0
2016-07-12 18:13:31 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 18:13:32 Job [INFO] Job job_local1000050779_0004 running in uber mode : false
2016-07-12 18:13:32 Job [INFO]  map 100% reduce 100%
2016-07-12 18:13:32 Job [INFO] Job job_local1000050779_0004 completed successfully
2016-07-12 18:13:32 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=49560
		FILE: Number of bytes written=2293098
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=2051
		Map output materialized bytes=2219
		Input split bytes=142
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=2219
		Reduce input records=81
		Reduce output records=19
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=801112064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2083
	File Output Format Counters 
		Bytes Written=1551
2016-07-12 18:14:29 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 18:14:29 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 18:14:29 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 18:14:29 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 18:14:29 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 18:14:29 JobSubmitter [INFO] number of splits:1
2016-07-12 18:14:29 JobSubmitter [INFO] Submitting tokens for job: job_local1145324855_0001
2016-07-12 18:14:30 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 18:14:30 Job [INFO] Running job: job_local1145324855_0001
2016-07-12 18:14:30 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 18:14:30 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:14:30 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 18:14:30 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 18:14:30 LocalJobRunner [INFO] Starting task: attempt_local1145324855_0001_m_000000_0
2016-07-12 18:14:30 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:14:30 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:14:30 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 18:14:30 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 18:14:30 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 18:14:30 MapTask [INFO] soft limit at 83886080
2016-07-12 18:14:30 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 18:14:30 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 18:14:30 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 18:14:31 Job [INFO] Job job_local1145324855_0001 running in uber mode : false
2016-07-12 18:14:31 Job [INFO]  map 0% reduce 0%
2016-07-12 18:14:31 LocalJobRunner [INFO] 
2016-07-12 18:14:31 MapTask [INFO] Starting flush of map output
2016-07-12 18:14:31 MapTask [INFO] Spilling map output
2016-07-12 18:14:31 MapTask [INFO] bufstart = 0; bufend = 1545; bufvoid = 104857600
2016-07-12 18:14:31 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214068(104856272); length = 329/6553600
2016-07-12 18:14:31 MapTask [INFO] Finished spill 0
2016-07-12 18:14:31 Task [INFO] Task:attempt_local1145324855_0001_m_000000_0 is done. And is in the process of committing
2016-07-12 18:14:31 LocalJobRunner [INFO] map
2016-07-12 18:14:31 Task [INFO] Task 'attempt_local1145324855_0001_m_000000_0' done.
2016-07-12 18:14:31 LocalJobRunner [INFO] Finishing task: attempt_local1145324855_0001_m_000000_0
2016-07-12 18:14:31 LocalJobRunner [INFO] map task executor complete.
2016-07-12 18:14:31 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 18:14:31 LocalJobRunner [INFO] Starting task: attempt_local1145324855_0001_r_000000_0
2016-07-12 18:14:31 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:14:31 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:14:31 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@463645d3
2016-07-12 18:14:31 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 18:14:31 EventFetcher [INFO] attempt_local1145324855_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 18:14:31 LocalFetcher [INFO] localfetcher#1 about to shuffle output of map attempt_local1145324855_0001_m_000000_0 decomp: 1713 len: 1717 to MEMORY
2016-07-12 18:14:31 InMemoryMapOutput [INFO] Read 1713 bytes from map-output for attempt_local1145324855_0001_m_000000_0
2016-07-12 18:14:31 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1713, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1713
2016-07-12 18:14:31 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 18:14:31 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:14:31 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 18:14:31 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:14:31 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 18:14:31 MergeManagerImpl [INFO] Merged 1 segments, 1713 bytes to disk to satisfy reduce memory limit
2016-07-12 18:14:31 MergeManagerImpl [INFO] Merging 1 files, 1717 bytes from disk
2016-07-12 18:14:31 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 18:14:31 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:14:31 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 18:14:31 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:14:31 deprecation [INFO] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-07-12 18:14:31 Task [INFO] Task:attempt_local1145324855_0001_r_000000_0 is done. And is in the process of committing
2016-07-12 18:14:31 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:14:31 Task [INFO] Task attempt_local1145324855_0001_r_000000_0 is allowed to commit now
2016-07-12 18:14:31 FileOutputCommitter [INFO] Saved output of task 'attempt_local1145324855_0001_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/_temporary/0/task_local1145324855_0001_r_000000
2016-07-12 18:14:31 LocalJobRunner [INFO] reduce > reduce
2016-07-12 18:14:31 Task [INFO] Task 'attempt_local1145324855_0001_r_000000_0' done.
2016-07-12 18:14:31 LocalJobRunner [INFO] Finishing task: attempt_local1145324855_0001_r_000000_0
2016-07-12 18:14:31 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 18:14:32 Job [INFO]  map 100% reduce 100%
2016-07-12 18:14:32 Job [INFO] Job job_local1145324855_0001 completed successfully
2016-07-12 18:14:32 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=17502
		FILE: Number of bytes written=576366
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=83
		Map output bytes=1545
		Map output materialized bytes=1717
		Input split bytes=144
		Combine input records=0
		Combine output records=0
		Reduce input groups=81
		Reduce shuffle bytes=1717
		Reduce input records=83
		Reduce output records=81
		Spilled Records=166
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=116
		Total committed heap usage (bytes)=852492288
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6818
	File Output Format Counters 
		Bytes Written=1371
2016-07-12 18:14:32 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 18:14:32 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 18:14:32 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 18:14:32 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 18:14:32 JobSubmitter [INFO] number of splits:1
2016-07-12 18:14:32 JobSubmitter [INFO] Submitting tokens for job: job_local801078780_0002
2016-07-12 18:14:32 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 18:14:32 Job [INFO] Running job: job_local801078780_0002
2016-07-12 18:14:32 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 18:14:32 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:14:32 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 18:14:32 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 18:14:32 LocalJobRunner [INFO] Starting task: attempt_local801078780_0002_m_000000_0
2016-07-12 18:14:32 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:14:32 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:14:32 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/part-r-00000:0+1351
2016-07-12 18:14:32 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 18:14:32 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 18:14:32 MapTask [INFO] soft limit at 83886080
2016-07-12 18:14:32 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 18:14:32 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 18:14:32 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 18:14:32 LocalJobRunner [INFO] 
2016-07-12 18:14:32 MapTask [INFO] Starting flush of map output
2016-07-12 18:14:32 MapTask [INFO] Spilling map output
2016-07-12 18:14:32 MapTask [INFO] bufstart = 0; bufend = 1351; bufvoid = 104857600
2016-07-12 18:14:32 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 18:14:32 MapTask [INFO] Finished spill 0
2016-07-12 18:14:32 Task [INFO] Task:attempt_local801078780_0002_m_000000_0 is done. And is in the process of committing
2016-07-12 18:14:32 LocalJobRunner [INFO] map
2016-07-12 18:14:32 Task [INFO] Task 'attempt_local801078780_0002_m_000000_0' done.
2016-07-12 18:14:32 LocalJobRunner [INFO] Finishing task: attempt_local801078780_0002_m_000000_0
2016-07-12 18:14:32 LocalJobRunner [INFO] map task executor complete.
2016-07-12 18:14:32 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 18:14:32 LocalJobRunner [INFO] Starting task: attempt_local801078780_0002_r_000000_0
2016-07-12 18:14:32 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:14:32 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:14:32 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@60c5a4be
2016-07-12 18:14:32 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 18:14:32 EventFetcher [INFO] attempt_local801078780_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 18:14:32 LocalFetcher [INFO] localfetcher#2 about to shuffle output of map attempt_local801078780_0002_m_000000_0 decomp: 1515 len: 1519 to MEMORY
2016-07-12 18:14:32 InMemoryMapOutput [INFO] Read 1515 bytes from map-output for attempt_local801078780_0002_m_000000_0
2016-07-12 18:14:32 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1515, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1515
2016-07-12 18:14:32 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 18:14:32 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:14:32 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 18:14:32 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:14:32 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 18:14:32 MergeManagerImpl [INFO] Merged 1 segments, 1515 bytes to disk to satisfy reduce memory limit
2016-07-12 18:14:32 MergeManagerImpl [INFO] Merging 1 files, 1519 bytes from disk
2016-07-12 18:14:32 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 18:14:32 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:14:32 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 18:14:32 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:14:32 Task [INFO] Task:attempt_local801078780_0002_r_000000_0 is done. And is in the process of committing
2016-07-12 18:14:32 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:14:32 Task [INFO] Task attempt_local801078780_0002_r_000000_0 is allowed to commit now
2016-07-12 18:14:32 FileOutputCommitter [INFO] Saved output of task 'attempt_local801078780_0002_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/_temporary/0/task_local801078780_0002_r_000000
2016-07-12 18:14:32 LocalJobRunner [INFO] reduce > reduce
2016-07-12 18:14:32 Task [INFO] Task 'attempt_local801078780_0002_r_000000_0' done.
2016-07-12 18:14:32 LocalJobRunner [INFO] Finishing task: attempt_local801078780_0002_r_000000_0
2016-07-12 18:14:32 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 18:14:33 Job [INFO] Job job_local801078780_0002 running in uber mode : false
2016-07-12 18:14:33 Job [INFO]  map 100% reduce 100%
2016-07-12 18:14:33 Job [INFO] Job job_local801078780_0002 completed successfully
2016-07-12 18:14:33 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=27190
		FILE: Number of bytes written=1146382
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1351
		Map output materialized bytes=1519
		Input split bytes=145
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=1519
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1069547520
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1375
	File Output Format Counters 
		Bytes Written=1533
2016-07-12 18:14:33 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 18:14:33 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 18:14:33 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 18:14:33 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 18:14:33 JobSubmitter [INFO] number of splits:1
2016-07-12 18:14:33 JobSubmitter [INFO] Submitting tokens for job: job_local1000491437_0003
2016-07-12 18:14:34 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 18:14:34 Job [INFO] Running job: job_local1000491437_0003
2016-07-12 18:14:34 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 18:14:34 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:14:34 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 18:14:34 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 18:14:34 LocalJobRunner [INFO] Starting task: attempt_local1000491437_0003_m_000000_0
2016-07-12 18:14:34 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:14:34 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:14:34 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/part-r-00000:0+1513
2016-07-12 18:14:34 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 18:14:34 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 18:14:34 MapTask [INFO] soft limit at 83886080
2016-07-12 18:14:34 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 18:14:34 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 18:14:34 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 18:14:34 LocalJobRunner [INFO] 
2016-07-12 18:14:34 MapTask [INFO] Starting flush of map output
2016-07-12 18:14:34 MapTask [INFO] Spilling map output
2016-07-12 18:14:34 MapTask [INFO] bufstart = 0; bufend = 1513; bufvoid = 104857600
2016-07-12 18:14:34 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 18:14:34 MapTask [INFO] Finished spill 0
2016-07-12 18:14:34 Task [INFO] Task:attempt_local1000491437_0003_m_000000_0 is done. And is in the process of committing
2016-07-12 18:14:34 LocalJobRunner [INFO] map
2016-07-12 18:14:34 Task [INFO] Task 'attempt_local1000491437_0003_m_000000_0' done.
2016-07-12 18:14:34 LocalJobRunner [INFO] Finishing task: attempt_local1000491437_0003_m_000000_0
2016-07-12 18:14:34 LocalJobRunner [INFO] map task executor complete.
2016-07-12 18:14:34 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 18:14:34 LocalJobRunner [INFO] Starting task: attempt_local1000491437_0003_r_000000_0
2016-07-12 18:14:34 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:14:34 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:14:34 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2711c490
2016-07-12 18:14:34 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 18:14:34 EventFetcher [INFO] attempt_local1000491437_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 18:14:34 LocalFetcher [INFO] localfetcher#3 about to shuffle output of map attempt_local1000491437_0003_m_000000_0 decomp: 1677 len: 1681 to MEMORY
2016-07-12 18:14:34 InMemoryMapOutput [INFO] Read 1677 bytes from map-output for attempt_local1000491437_0003_m_000000_0
2016-07-12 18:14:34 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1677, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1677
2016-07-12 18:14:34 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 18:14:34 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:14:34 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 18:14:34 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:14:34 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 18:14:34 MergeManagerImpl [INFO] Merged 1 segments, 1677 bytes to disk to satisfy reduce memory limit
2016-07-12 18:14:34 MergeManagerImpl [INFO] Merging 1 files, 1681 bytes from disk
2016-07-12 18:14:34 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 18:14:34 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:14:34 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 18:14:34 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:14:34 Task [INFO] Task:attempt_local1000491437_0003_r_000000_0 is done. And is in the process of committing
2016-07-12 18:14:34 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:14:34 Task [INFO] Task attempt_local1000491437_0003_r_000000_0 is allowed to commit now
2016-07-12 18:14:34 FileOutputCommitter [INFO] Saved output of task 'attempt_local1000491437_0003_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/_temporary/0/task_local1000491437_0003_r_000000
2016-07-12 18:14:34 LocalJobRunner [INFO] reduce > reduce
2016-07-12 18:14:34 Task [INFO] Task 'attempt_local1000491437_0003_r_000000_0' done.
2016-07-12 18:14:34 LocalJobRunner [INFO] Finishing task: attempt_local1000491437_0003_r_000000_0
2016-07-12 18:14:34 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 18:14:35 Job [INFO] Job job_local1000491437_0003 running in uber mode : false
2016-07-12 18:14:35 Job [INFO]  map 100% reduce 100%
2016-07-12 18:14:35 Job [INFO] Job job_local1000491437_0003 completed successfully
2016-07-12 18:14:35 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=37134
		FILE: Number of bytes written=1720294
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1513
		Map output materialized bytes=1681
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=59
		Reduce shuffle bytes=1681
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=872415232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1537
	File Output Format Counters 
		Bytes Written=2079
2016-07-12 18:14:35 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 18:14:35 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 18:14:35 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 18:14:35 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 18:14:35 JobSubmitter [INFO] number of splits:1
2016-07-12 18:14:35 JobSubmitter [INFO] Submitting tokens for job: job_local1433292458_0004
2016-07-12 18:14:35 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 18:14:35 Job [INFO] Running job: job_local1433292458_0004
2016-07-12 18:14:35 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 18:14:35 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:14:35 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 18:14:35 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 18:14:35 LocalJobRunner [INFO] Starting task: attempt_local1433292458_0004_m_000000_0
2016-07-12 18:14:35 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:14:35 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:14:35 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/part-r-00000:0+2051
2016-07-12 18:14:35 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 18:14:35 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 18:14:35 MapTask [INFO] soft limit at 83886080
2016-07-12 18:14:35 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 18:14:35 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 18:14:35 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 18:14:35 LocalJobRunner [INFO] 
2016-07-12 18:14:35 MapTask [INFO] Starting flush of map output
2016-07-12 18:14:35 MapTask [INFO] Spilling map output
2016-07-12 18:14:35 MapTask [INFO] bufstart = 0; bufend = 2051; bufvoid = 104857600
2016-07-12 18:14:35 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 18:14:35 MapTask [INFO] Finished spill 0
2016-07-12 18:14:35 Task [INFO] Task:attempt_local1433292458_0004_m_000000_0 is done. And is in the process of committing
2016-07-12 18:14:35 LocalJobRunner [INFO] map
2016-07-12 18:14:35 Task [INFO] Task 'attempt_local1433292458_0004_m_000000_0' done.
2016-07-12 18:14:35 LocalJobRunner [INFO] Finishing task: attempt_local1433292458_0004_m_000000_0
2016-07-12 18:14:35 LocalJobRunner [INFO] map task executor complete.
2016-07-12 18:14:35 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 18:14:35 LocalJobRunner [INFO] Starting task: attempt_local1433292458_0004_r_000000_0
2016-07-12 18:14:35 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:14:35 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:14:35 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@72b0ff3d
2016-07-12 18:14:35 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 18:14:35 EventFetcher [INFO] attempt_local1433292458_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 18:14:35 LocalFetcher [INFO] localfetcher#4 about to shuffle output of map attempt_local1433292458_0004_m_000000_0 decomp: 2215 len: 2219 to MEMORY
2016-07-12 18:14:35 InMemoryMapOutput [INFO] Read 2215 bytes from map-output for attempt_local1433292458_0004_m_000000_0
2016-07-12 18:14:35 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 2215, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2215
2016-07-12 18:14:35 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 18:14:35 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:14:35 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 18:14:35 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:14:35 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 2204 bytes
2016-07-12 18:14:35 MergeManagerImpl [INFO] Merged 1 segments, 2215 bytes to disk to satisfy reduce memory limit
2016-07-12 18:14:35 MergeManagerImpl [INFO] Merging 1 files, 2219 bytes from disk
2016-07-12 18:14:35 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 18:14:35 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:14:35 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 2204 bytes
2016-07-12 18:14:35 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:14:35 Task [INFO] Task:attempt_local1433292458_0004_r_000000_0 is done. And is in the process of committing
2016-07-12 18:14:35 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:14:35 Task [INFO] Task attempt_local1433292458_0004_r_000000_0 is allowed to commit now
2016-07-12 18:14:35 FileOutputCommitter [INFO] Saved output of task 'attempt_local1433292458_0004_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/4-tf-idf-document/_temporary/0/task_local1433292458_0004_r_000000
2016-07-12 18:14:35 LocalJobRunner [INFO] reduce > reduce
2016-07-12 18:14:35 Task [INFO] Task 'attempt_local1433292458_0004_r_000000_0' done.
2016-07-12 18:14:35 LocalJobRunner [INFO] Finishing task: attempt_local1433292458_0004_r_000000_0
2016-07-12 18:14:35 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 18:14:36 Job [INFO] Job job_local1433292458_0004 running in uber mode : false
2016-07-12 18:14:36 Job [INFO]  map 100% reduce 100%
2016-07-12 18:14:36 Job [INFO] Job job_local1433292458_0004 completed successfully
2016-07-12 18:14:36 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=49560
		FILE: Number of bytes written=2296090
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=2051
		Map output materialized bytes=2219
		Input split bytes=142
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=2219
		Reduce input records=81
		Reduce output records=19
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=883949568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2083
	File Output Format Counters 
		Bytes Written=1551
2016-07-12 18:16:17 NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-07-12 18:16:17 deprecation [INFO] session.id is deprecated. Instead, use dfs.metrics.session-id
2016-07-12 18:16:17 JvmMetrics [INFO] Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-07-12 18:16:18 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 18:16:18 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 18:16:18 JobSubmitter [INFO] number of splits:1
2016-07-12 18:16:18 JobSubmitter [INFO] Submitting tokens for job: job_local810372497_0001
2016-07-12 18:16:18 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 18:16:18 Job [INFO] Running job: job_local810372497_0001
2016-07-12 18:16:18 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 18:16:18 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:16:18 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 18:16:18 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 18:16:18 LocalJobRunner [INFO] Starting task: attempt_local810372497_0001_m_000000_0
2016-07-12 18:16:18 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:16:18 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:16:18 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Avro Document/python/python.avro:0+3409
2016-07-12 18:16:18 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 18:16:18 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 18:16:18 MapTask [INFO] soft limit at 83886080
2016-07-12 18:16:18 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 18:16:18 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 18:16:18 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 18:16:19 Job [INFO] Job job_local810372497_0001 running in uber mode : false
2016-07-12 18:16:19 Job [INFO]  map 0% reduce 0%
2016-07-12 18:16:19 LocalJobRunner [INFO] 
2016-07-12 18:16:19 MapTask [INFO] Starting flush of map output
2016-07-12 18:16:19 MapTask [INFO] Spilling map output
2016-07-12 18:16:19 MapTask [INFO] bufstart = 0; bufend = 1545; bufvoid = 104857600
2016-07-12 18:16:19 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214068(104856272); length = 329/6553600
2016-07-12 18:16:19 MapTask [INFO] Finished spill 0
2016-07-12 18:16:19 Task [INFO] Task:attempt_local810372497_0001_m_000000_0 is done. And is in the process of committing
2016-07-12 18:16:19 LocalJobRunner [INFO] map
2016-07-12 18:16:19 Task [INFO] Task 'attempt_local810372497_0001_m_000000_0' done.
2016-07-12 18:16:19 LocalJobRunner [INFO] Finishing task: attempt_local810372497_0001_m_000000_0
2016-07-12 18:16:19 LocalJobRunner [INFO] map task executor complete.
2016-07-12 18:16:19 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 18:16:19 LocalJobRunner [INFO] Starting task: attempt_local810372497_0001_r_000000_0
2016-07-12 18:16:19 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:16:19 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:16:19 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@41c8e901
2016-07-12 18:16:19 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 18:16:19 EventFetcher [INFO] attempt_local810372497_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 18:16:19 LocalFetcher [INFO] localfetcher#1 about to shuffle output of map attempt_local810372497_0001_m_000000_0 decomp: 1713 len: 1717 to MEMORY
2016-07-12 18:16:19 InMemoryMapOutput [INFO] Read 1713 bytes from map-output for attempt_local810372497_0001_m_000000_0
2016-07-12 18:16:19 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1713, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1713
2016-07-12 18:16:19 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 18:16:19 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:16:19 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 18:16:19 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:16:19 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 18:16:19 MergeManagerImpl [INFO] Merged 1 segments, 1713 bytes to disk to satisfy reduce memory limit
2016-07-12 18:16:19 MergeManagerImpl [INFO] Merging 1 files, 1717 bytes from disk
2016-07-12 18:16:19 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 18:16:19 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:16:19 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1700 bytes
2016-07-12 18:16:19 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:16:19 deprecation [INFO] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-07-12 18:16:19 Task [INFO] Task:attempt_local810372497_0001_r_000000_0 is done. And is in the process of committing
2016-07-12 18:16:19 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:16:19 Task [INFO] Task attempt_local810372497_0001_r_000000_0 is allowed to commit now
2016-07-12 18:16:19 FileOutputCommitter [INFO] Saved output of task 'attempt_local810372497_0001_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/_temporary/0/task_local810372497_0001_r_000000
2016-07-12 18:16:19 LocalJobRunner [INFO] reduce > reduce
2016-07-12 18:16:19 Task [INFO] Task 'attempt_local810372497_0001_r_000000_0' done.
2016-07-12 18:16:19 LocalJobRunner [INFO] Finishing task: attempt_local810372497_0001_r_000000_0
2016-07-12 18:16:19 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 18:16:20 Job [INFO]  map 100% reduce 100%
2016-07-12 18:16:20 Job [INFO] Job job_local810372497_0001 completed successfully
2016-07-12 18:16:20 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=17502
		FILE: Number of bytes written=573354
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=83
		Map output bytes=1545
		Map output materialized bytes=1717
		Input split bytes=144
		Combine input records=0
		Combine output records=0
		Reduce input groups=81
		Reduce shuffle bytes=1717
		Reduce input records=83
		Reduce output records=81
		Spilled Records=166
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=106
		Total committed heap usage (bytes)=839909376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6818
	File Output Format Counters 
		Bytes Written=1371
2016-07-12 18:16:20 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 18:16:20 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 18:16:20 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 18:16:20 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 18:16:20 JobSubmitter [INFO] number of splits:1
2016-07-12 18:16:20 JobSubmitter [INFO] Submitting tokens for job: job_local105752354_0002
2016-07-12 18:16:20 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 18:16:20 Job [INFO] Running job: job_local105752354_0002
2016-07-12 18:16:20 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 18:16:20 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:16:20 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 18:16:20 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 18:16:20 LocalJobRunner [INFO] Starting task: attempt_local105752354_0002_m_000000_0
2016-07-12 18:16:20 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:16:20 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:16:20 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/1-word-freq/part-r-00000:0+1351
2016-07-12 18:16:20 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 18:16:20 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 18:16:20 MapTask [INFO] soft limit at 83886080
2016-07-12 18:16:20 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 18:16:20 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 18:16:20 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 18:16:20 LocalJobRunner [INFO] 
2016-07-12 18:16:20 MapTask [INFO] Starting flush of map output
2016-07-12 18:16:20 MapTask [INFO] Spilling map output
2016-07-12 18:16:20 MapTask [INFO] bufstart = 0; bufend = 1351; bufvoid = 104857600
2016-07-12 18:16:20 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 18:16:20 MapTask [INFO] Finished spill 0
2016-07-12 18:16:20 Task [INFO] Task:attempt_local105752354_0002_m_000000_0 is done. And is in the process of committing
2016-07-12 18:16:20 LocalJobRunner [INFO] map
2016-07-12 18:16:20 Task [INFO] Task 'attempt_local105752354_0002_m_000000_0' done.
2016-07-12 18:16:20 LocalJobRunner [INFO] Finishing task: attempt_local105752354_0002_m_000000_0
2016-07-12 18:16:20 LocalJobRunner [INFO] map task executor complete.
2016-07-12 18:16:20 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 18:16:20 LocalJobRunner [INFO] Starting task: attempt_local105752354_0002_r_000000_0
2016-07-12 18:16:20 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:16:20 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:16:20 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5dc5d195
2016-07-12 18:16:20 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 18:16:20 EventFetcher [INFO] attempt_local105752354_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 18:16:20 LocalFetcher [INFO] localfetcher#2 about to shuffle output of map attempt_local105752354_0002_m_000000_0 decomp: 1515 len: 1519 to MEMORY
2016-07-12 18:16:20 InMemoryMapOutput [INFO] Read 1515 bytes from map-output for attempt_local105752354_0002_m_000000_0
2016-07-12 18:16:20 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1515, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1515
2016-07-12 18:16:20 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 18:16:20 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:16:20 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 18:16:20 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:16:20 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 18:16:20 MergeManagerImpl [INFO] Merged 1 segments, 1515 bytes to disk to satisfy reduce memory limit
2016-07-12 18:16:20 MergeManagerImpl [INFO] Merging 1 files, 1519 bytes from disk
2016-07-12 18:16:20 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 18:16:20 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:16:20 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1504 bytes
2016-07-12 18:16:20 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:16:20 Task [INFO] Task:attempt_local105752354_0002_r_000000_0 is done. And is in the process of committing
2016-07-12 18:16:20 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:16:20 Task [INFO] Task attempt_local105752354_0002_r_000000_0 is allowed to commit now
2016-07-12 18:16:20 FileOutputCommitter [INFO] Saved output of task 'attempt_local105752354_0002_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/_temporary/0/task_local105752354_0002_r_000000
2016-07-12 18:16:20 LocalJobRunner [INFO] reduce > reduce
2016-07-12 18:16:20 Task [INFO] Task 'attempt_local105752354_0002_r_000000_0' done.
2016-07-12 18:16:20 LocalJobRunner [INFO] Finishing task: attempt_local105752354_0002_r_000000_0
2016-07-12 18:16:20 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 18:16:21 Job [INFO] Job job_local105752354_0002 running in uber mode : false
2016-07-12 18:16:21 Job [INFO]  map 100% reduce 100%
2016-07-12 18:16:21 Job [INFO] Job job_local105752354_0002 completed successfully
2016-07-12 18:16:21 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=27190
		FILE: Number of bytes written=1143370
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1351
		Map output materialized bytes=1519
		Input split bytes=145
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=1519
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1050673152
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1375
	File Output Format Counters 
		Bytes Written=1533
2016-07-12 18:16:21 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 18:16:21 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 18:16:21 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 18:16:21 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 18:16:21 JobSubmitter [INFO] number of splits:1
2016-07-12 18:16:22 JobSubmitter [INFO] Submitting tokens for job: job_local1770319888_0003
2016-07-12 18:16:22 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 18:16:22 Job [INFO] Running job: job_local1770319888_0003
2016-07-12 18:16:22 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 18:16:22 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:16:22 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 18:16:22 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 18:16:22 LocalJobRunner [INFO] Starting task: attempt_local1770319888_0003_m_000000_0
2016-07-12 18:16:22 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:16:22 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:16:22 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/2-word-counts/part-r-00000:0+1513
2016-07-12 18:16:22 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 18:16:22 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 18:16:22 MapTask [INFO] soft limit at 83886080
2016-07-12 18:16:22 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 18:16:22 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 18:16:22 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 18:16:22 LocalJobRunner [INFO] 
2016-07-12 18:16:22 MapTask [INFO] Starting flush of map output
2016-07-12 18:16:22 MapTask [INFO] Spilling map output
2016-07-12 18:16:22 MapTask [INFO] bufstart = 0; bufend = 1513; bufvoid = 104857600
2016-07-12 18:16:22 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 18:16:22 MapTask [INFO] Finished spill 0
2016-07-12 18:16:22 Task [INFO] Task:attempt_local1770319888_0003_m_000000_0 is done. And is in the process of committing
2016-07-12 18:16:22 LocalJobRunner [INFO] map
2016-07-12 18:16:22 Task [INFO] Task 'attempt_local1770319888_0003_m_000000_0' done.
2016-07-12 18:16:22 LocalJobRunner [INFO] Finishing task: attempt_local1770319888_0003_m_000000_0
2016-07-12 18:16:22 LocalJobRunner [INFO] map task executor complete.
2016-07-12 18:16:22 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 18:16:22 LocalJobRunner [INFO] Starting task: attempt_local1770319888_0003_r_000000_0
2016-07-12 18:16:22 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:16:22 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:16:22 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2bd03119
2016-07-12 18:16:22 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 18:16:22 EventFetcher [INFO] attempt_local1770319888_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 18:16:22 LocalFetcher [INFO] localfetcher#3 about to shuffle output of map attempt_local1770319888_0003_m_000000_0 decomp: 1677 len: 1681 to MEMORY
2016-07-12 18:16:22 InMemoryMapOutput [INFO] Read 1677 bytes from map-output for attempt_local1770319888_0003_m_000000_0
2016-07-12 18:16:22 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 1677, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1677
2016-07-12 18:16:22 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 18:16:22 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:16:22 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 18:16:22 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:16:22 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 18:16:22 MergeManagerImpl [INFO] Merged 1 segments, 1677 bytes to disk to satisfy reduce memory limit
2016-07-12 18:16:22 MergeManagerImpl [INFO] Merging 1 files, 1681 bytes from disk
2016-07-12 18:16:22 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 18:16:22 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:16:22 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 1673 bytes
2016-07-12 18:16:22 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:16:22 Task [INFO] Task:attempt_local1770319888_0003_r_000000_0 is done. And is in the process of committing
2016-07-12 18:16:22 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:16:22 Task [INFO] Task attempt_local1770319888_0003_r_000000_0 is allowed to commit now
2016-07-12 18:16:22 FileOutputCommitter [INFO] Saved output of task 'attempt_local1770319888_0003_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/_temporary/0/task_local1770319888_0003_r_000000
2016-07-12 18:16:22 LocalJobRunner [INFO] reduce > reduce
2016-07-12 18:16:22 Task [INFO] Task 'attempt_local1770319888_0003_r_000000_0' done.
2016-07-12 18:16:22 LocalJobRunner [INFO] Finishing task: attempt_local1770319888_0003_r_000000_0
2016-07-12 18:16:22 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 18:16:23 Job [INFO] Job job_local1770319888_0003 running in uber mode : false
2016-07-12 18:16:23 Job [INFO]  map 100% reduce 100%
2016-07-12 18:16:23 Job [INFO] Job job_local1770319888_0003 completed successfully
2016-07-12 18:16:23 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=37134
		FILE: Number of bytes written=1717282
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=1513
		Map output materialized bytes=1681
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=59
		Reduce shuffle bytes=1681
		Reduce input records=81
		Reduce output records=81
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=847249408
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1537
	File Output Format Counters 
		Bytes Written=2079
2016-07-12 18:16:23 JvmMetrics [INFO] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-07-12 18:16:23 JobResourceUploader [WARN] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-07-12 18:16:23 JobResourceUploader [WARN] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-07-12 18:16:23 FileInputFormat [INFO] Total input paths to process : 1
2016-07-12 18:16:23 JobSubmitter [INFO] number of splits:1
2016-07-12 18:16:23 JobSubmitter [INFO] Submitting tokens for job: job_local250747281_0004
2016-07-12 18:16:23 Job [INFO] The url to track the job: http://localhost:8080/
2016-07-12 18:16:23 Job [INFO] Running job: job_local250747281_0004
2016-07-12 18:16:23 LocalJobRunner [INFO] OutputCommitter set in config null
2016-07-12 18:16:23 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:16:23 LocalJobRunner [INFO] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-07-12 18:16:23 LocalJobRunner [INFO] Waiting for map tasks
2016-07-12 18:16:23 LocalJobRunner [INFO] Starting task: attempt_local250747281_0004_m_000000_0
2016-07-12 18:16:23 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:16:23 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:16:23 MapTask [INFO] Processing split: file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/3-tf-idf/part-r-00000:0+2051
2016-07-12 18:16:23 MapTask [INFO] (EQUATOR) 0 kvi 26214396(104857584)
2016-07-12 18:16:23 MapTask [INFO] mapreduce.task.io.sort.mb: 100
2016-07-12 18:16:23 MapTask [INFO] soft limit at 83886080
2016-07-12 18:16:23 MapTask [INFO] bufstart = 0; bufvoid = 104857600
2016-07-12 18:16:23 MapTask [INFO] kvstart = 26214396; length = 6553600
2016-07-12 18:16:23 MapTask [INFO] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-07-12 18:16:23 LocalJobRunner [INFO] 
2016-07-12 18:16:23 MapTask [INFO] Starting flush of map output
2016-07-12 18:16:23 MapTask [INFO] Spilling map output
2016-07-12 18:16:23 MapTask [INFO] bufstart = 0; bufend = 2051; bufvoid = 104857600
2016-07-12 18:16:23 MapTask [INFO] kvstart = 26214396(104857584); kvend = 26214076(104856304); length = 321/6553600
2016-07-12 18:16:23 MapTask [INFO] Finished spill 0
2016-07-12 18:16:23 Task [INFO] Task:attempt_local250747281_0004_m_000000_0 is done. And is in the process of committing
2016-07-12 18:16:23 LocalJobRunner [INFO] map
2016-07-12 18:16:23 Task [INFO] Task 'attempt_local250747281_0004_m_000000_0' done.
2016-07-12 18:16:23 LocalJobRunner [INFO] Finishing task: attempt_local250747281_0004_m_000000_0
2016-07-12 18:16:23 LocalJobRunner [INFO] map task executor complete.
2016-07-12 18:16:23 LocalJobRunner [INFO] Waiting for reduce tasks
2016-07-12 18:16:23 LocalJobRunner [INFO] Starting task: attempt_local250747281_0004_r_000000_0
2016-07-12 18:16:23 FileOutputCommitter [INFO] File Output Committer Algorithm version is 1
2016-07-12 18:16:23 Task [INFO]  Using ResourceCalculatorProcessTree : [ ]
2016-07-12 18:16:23 ReduceTask [INFO] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@51f7e48c
2016-07-12 18:16:23 MergeManagerImpl [INFO] MergerManager: memoryLimit=633077760, maxSingleShuffleLimit=158269440, mergeThreshold=417831328, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-07-12 18:16:23 EventFetcher [INFO] attempt_local250747281_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-07-12 18:16:23 LocalFetcher [INFO] localfetcher#4 about to shuffle output of map attempt_local250747281_0004_m_000000_0 decomp: 2215 len: 2219 to MEMORY
2016-07-12 18:16:23 InMemoryMapOutput [INFO] Read 2215 bytes from map-output for attempt_local250747281_0004_m_000000_0
2016-07-12 18:16:23 MergeManagerImpl [INFO] closeInMemoryFile -> map-output of size: 2215, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2215
2016-07-12 18:16:23 EventFetcher [INFO] EventFetcher is interrupted.. Returning
2016-07-12 18:16:23 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:16:23 MergeManagerImpl [INFO] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-07-12 18:16:23 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:16:23 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 2204 bytes
2016-07-12 18:16:23 MergeManagerImpl [INFO] Merged 1 segments, 2215 bytes to disk to satisfy reduce memory limit
2016-07-12 18:16:23 MergeManagerImpl [INFO] Merging 1 files, 2219 bytes from disk
2016-07-12 18:16:23 MergeManagerImpl [INFO] Merging 0 segments, 0 bytes from memory into reduce
2016-07-12 18:16:23 Merger [INFO] Merging 1 sorted segments
2016-07-12 18:16:23 Merger [INFO] Down to the last merge-pass, with 1 segments left of total size: 2204 bytes
2016-07-12 18:16:23 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:16:23 Task [INFO] Task:attempt_local250747281_0004_r_000000_0 is done. And is in the process of committing
2016-07-12 18:16:23 LocalJobRunner [INFO] 1 / 1 copied.
2016-07-12 18:16:23 Task [INFO] Task attempt_local250747281_0004_r_000000_0 is allowed to commit now
2016-07-12 18:16:23 FileOutputCommitter [INFO] Saved output of task 'attempt_local250747281_0004_r_000000_0' to file:/home/michele/NetBeansProjects/E-CO-2/etc/Training/4-tf-idf-document/_temporary/0/task_local250747281_0004_r_000000
2016-07-12 18:16:23 LocalJobRunner [INFO] reduce > reduce
2016-07-12 18:16:23 Task [INFO] Task 'attempt_local250747281_0004_r_000000_0' done.
2016-07-12 18:16:23 LocalJobRunner [INFO] Finishing task: attempt_local250747281_0004_r_000000_0
2016-07-12 18:16:23 LocalJobRunner [INFO] reduce task executor complete.
2016-07-12 18:16:24 Job [INFO] Job job_local250747281_0004 running in uber mode : false
2016-07-12 18:16:24 Job [INFO]  map 100% reduce 100%
2016-07-12 18:16:24 Job [INFO] Job job_local250747281_0004 completed successfully
2016-07-12 18:16:24 Job [INFO] Counters: 30
	File System Counters
		FILE: Number of bytes read=49560
		FILE: Number of bytes written=2290086
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=81
		Map output records=81
		Map output bytes=2051
		Map output materialized bytes=2219
		Input split bytes=142
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=2219
		Reduce input records=81
		Reduce output records=19
		Spilled Records=162
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=859832320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2083
	File Output Format Counters 
		Bytes Written=1551
